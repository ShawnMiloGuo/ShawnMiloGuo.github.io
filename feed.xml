<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://shawnmiloguo.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://shawnmiloguo.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-19T08:43:41+00:00</updated><id>https://shawnmiloguo.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://shawnmiloguo.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[<p>May 14, 2024[[read-time]] min read We’re introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants. In December, we launched our first natively multimodal model Gemini 1.0 in three sizes: Ultra, Pro and Nano. Just a few months later we released 1.5 Pro, with enhanced performance and a breakthrough long context window of 1 million tokens.Developers and enterprise customers have been putting 1.5 Pro to use in incredible ways and finding its long context window, multimodal reasoning capabilities and impressive overall performance incredibly useful.We know from user feedback that some applications need lower latency and a lower cost to serve. This inspired us to keep innovating, so today, we’re introducing Gemini 1.5 Flash: a model that’s lighter-weight than 1.5 Pro, and designed to be fast and efficient to serve at scale.Both 1.5 Pro and 1.5 Flash are available in public preview with a 1 million token context window in Google AI Studio and Vertex AI. And now, 1.5 Pro is also available with a 2 million token context window via waitlist to developers using the API and to Google Cloud customers.We’re also introducing updates across the Gemini family of models, announcing our next generation of open models, Gemma 2, and sharing progress on the future of AI assistants, with Project Astra.Context lengths of leading foundation models compared with Gemini 1.5’s 2 million token capability1.5 Flash is the newest addition to the Gemini model family and the fastest Gemini model served in the API. It’s optimized for high-volume, high-frequency tasks at scale, is more cost-efficient to serve and features our breakthrough long context window.While it’s a lighter weight model than 1.5 Pro, it’s highly capable of multimodal reasoning across vast amounts of information and delivers impressive quality for its size.The new Gemini 1.5 Flash model is optimized for speed and efficiency, is highly capable of multimodal reasoning and features our breakthrough long context window.1.5 Flash excels at summarization, chat applications, image and video captioning, data extraction from long documents and tables, and more. This is because it’s been trained by 1.5 Pro through a process called “distillation,” where the most essential knowledge and skills from a larger model are transferred to a smaller, more efficient model.Read more about 1.5 Flash in our updated Gemini 1.5 technical report, on the Gemini technology page, and learn about 1.5 Flash’s availability and pricing.Over the last few months, we’ve significantly improved 1.5 Pro, our best model for general performance across a wide range of tasks.Beyond extending its context window to 2 million tokens, we’ve enhanced its code generation, logical reasoning and planning, multi-turn conversation, and audio and image understanding through data and algorithmic advances. We see strong improvements on public and internal benchmarks for each of these tasks.1.5 Pro can now follow increasingly complex and nuanced instructions, including ones that specify product-level behavior involving role, format and style. We’ve improved control over the model’s responses for specific use cases, like crafting the persona and response style of a chat agent or automating workflows through multiple function calls. And we’ve enabled users to steer model behavior by setting system instructions.We added audio understanding in the Gemini API and Google AI Studio, so 1.5 Pro can now reason across image and audio for videos uploaded in Google AI Studio. And we’re now integrating 1.5 Pro into Google products, including Gemini Advanced and in Workspace apps.Read more about 1.5 Pro in our updated Gemini 1.5 technical report and on the Gemini technology page.Gemini Nano is expanding beyond text-only inputs to include images as well. Starting with Pixel, applications using Gemini Nano with Multimodality will be able to understand the world the way people do — not just through text, but also through sight, sound and spoken language.Read more about Gemini 1.0 Nano on Android.Today, we’re also sharing a series of updates to Gemma, our family of open models built from the same research and technology used to create the Gemini models.We’re announcing Gemma 2, our next generation of open models for responsible AI innovation. Gemma 2 has a new architecture designed for breakthrough performance and efficiency, and will be available in new sizes.The Gemma family is also expanding with PaliGemma, our first vision-language model inspired by PaLI-3. And we’ve upgraded our Responsible Generative AI Toolkit with LLM Comparator for evaluating the quality of model responses.Read more on the Developer blog.As part of Google DeepMind’s mission to build AI responsibly to benefit humanity, we’ve always wanted to develop universal AI agents that can be helpful in everyday life. That’s why today, we’re sharing our progress in building the future of AI assistants with Project Astra (advanced seeing and talking responsive agent).To be truly useful, an agent needs to understand and respond to the complex and dynamic world just like people do — and take in and remember what it sees and hears to understand context and take action. It also needs to be proactive, teachable and personal, so users can talk to it naturally and without lag or delay.While we’ve made incredible progress developing AI systems that can understand multimodal information, getting response time down to something conversational is a difficult engineering challenge. Over the past few years, we’ve been working to improve how our models perceive, reason and converse to make the pace and quality of interaction feel more natural.Building on Gemini, we’ve developed prototype agents that can process information faster by continuously encoding video frames, combining the video and speech input into a timeline of events, and caching this information for efficient recall.By leveraging our leading speech models, we also enhanced how they sound, giving the agents a wider range of intonations. These agents can better understand the context they’re being used in, and respond quickly, in conversation.With technology like this, it’s easy to envision a future where people could have an expert AI assistant by their side, through a phone or glasses. And some of these capabilities are coming to Google products, like the Gemini app and web experience, later this year.We’ve made incredible progress so far with our family of Gemini models, and we’re always striving to advance the state-of-the-art even further. By investing in a relentless production line of innovation, we’re able to explore new ideas at the frontier, while also unlocking the possibility of new and exciting Gemini use cases.Learn more about Gemini and its capabilities. Your information will be used in accordance with Google’s privacy policy.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      Done. Just one step more.
    
      Check your inbox to confirm your subscription.
    You are already subscribed to our newsletter.
    You can also subscribe with a
    different email address
    
    .
    
  Let’s stay in touch. Get the latest news from Google in your inbox.
          Follow Us
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">面向地表温度跨尺度融合的动态神经网络</title><link href="https://shawnmiloguo.github.io/blog/2024/IUSTFM/" rel="alternate" type="text/html" title="面向地表温度跨尺度融合的动态神经网络"/><published>2024-02-10T00:00:00+00:00</published><updated>2024-02-10T00:00:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2024/IUSTFM</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2024/IUSTFM/"><![CDATA[<p>来自卫星热传感器的陆地表面温度（LST）数据捕捉了地球表面能量分布在空间和时间上的详细变化。这些数据在蒸散观测和城市热建模等应用中发挥着重要作用[1-3]。然而，由于卫星轨道和传感器设计的限制，热波段的空间分辨率和时间分辨率之间通常存在权衡。日常传感器只能提供较低空间分辨率的数据，如分辨率为 1 公里的 MODIS LST。精细分辨率（100 或更低）的传感器通常受限于其扫描带宽度和轨道高度，只能提供数天内的数据，如大地遥感卫星系列平台的八天内数据（结合Landsat-7 、8和 9）。因此，在提升可用卫星资源方面，合并多个卫星传感器的数据是获得高时空分辨率观测数据的关键挑战之一，这将进一步惠及地表能量建模和精准农业等许多综合应用。</p> <h3 id="原文链接">原文链接</h3> <p>Guo, S., Li, M., Li, Y., Chen, J., Zhang, H. K., Sun, L., Wang, J., Wang, R., &amp; Yang, Y. (2024). The Improved U-STFM : A Deep Learning-Based Nonlinear Spatial-Temporal Fusion Model for Land Surface Temperature Downscaling. Remote Sensing, 16(322), 1–28.</p> <h3 id="研究背景">研究背景</h3> <p>来自卫星热传感器的陆地表面温度（LST）数据捕捉了地球表面能量分布在空间和时间上的详细变化。这些数据在蒸散观测和城市热建模等应用中发挥着重要作用[1-3]。然而，由于卫星轨道和传感器设计的限制，热波段的空间分辨率和时间分辨率之间通常存在权衡。日常传感器只能提供较低空间分辨率的数据，如分辨率为 1 公里的 MODIS LST。精细分辨率（100 或更低）的传感器通常受限于其扫描带宽度和轨道高度，只能提供数天内的数据，如大地遥感卫星系列平台的八天内数据（结合Landsat-7 、8和 9）。因此，在提升可用卫星资源方面，合并多个卫星传感器的数据是获得高时空分辨率观测数据的关键挑战之一，这将进一步惠及地表能量建模和精准农业等许多综合应用[3]。</p> <p>为了克服这一限制，最近在计算机视觉和遥感领域开发了许多超分辨率或融合模型，以生成具有精细空间分辨率的每日LST观测数据。这些模型可分为三类：(1)基于学习的；(2)基于回归的；(3)基于时空融合的。</p> <p>基于学习的模型主要是从计算机视觉的角度出发，假设粗像素和细像素之间的关系可以用点扩散函数（PSF）来描述，PSF 代表了低分辨率像素与高分辨率像素的混合过程[4]。PSF与尺度相关，但保持时空一致性，可通过学习系统建模。2015年之前，PSF 主要使用图像重建（RE）模型构建，如基于核的方法[5]、解卷积模型[6]、稀疏编码[7-9]和基于SVM的方法[10]。随着深度学习技术在语义分割和成像领域的长足进步，深度网络首次被引入到超分辨率问题中，利用 SRCNN [11]和SRGAN [12]捕捉PSF。后来，这些技术增强了遥感领域的模型，包括基于 CNN 的模型： STFDCNN[13]、DCSTFN[14]、stfNet[15]、EDCSTFN[16]和 HSRNet[17]；以及基于GAN：ISRGAN [18]、STFGAN [19]、CycleGAN-STF [20]和GAN-STFM [21]。基于学习的模型的优势在于，一旦用足够的样本对其进行了训练，预测的准确性和效率都能得到保证。然而，考虑到每日LST的空间和时间变化都很快，通用PSF可能无法根据有限的样本准确捕捉低分辨率遥感图像的混合情况。此外，如果没有物理原理的指导，基于深度学习的模型所学习到的特征和权重通常很难被人类理解，这就限制了在出现不可靠预测时的错误追踪。</p> <p>基于学习的模型侧重于仅从粗略和精细图像中学习两者之间的关系，与之相反，第二类模型包括基于回归的模型。这些模型所依据的假设是，传感器探测到的热波段值可通过几个辅助生物物理参数（如地表反射比、土地利用、土地覆被类型、植被指数和模拟模型的其他输出）来建模[22]。辐射表面温度分解模型（DisTrad）[23] 和热图像锐化模型（TsHARP）[24] 是最早基于植被指数-辐射表面温度关系（基于 VI 的模型）对粗 LST 进行降尺度处理的两个模型。这种关系已在全球和局部尺度上进行了评估[25]。许多基于非线性机器学习的方法被用来捕捉这种关系，如随机森林回归[26]、随机森林区域到点克里金法[27]和高斯滤波法[22]。在植被指数和坡度数据的基础上，利用累积分布函数（CDF）匹配和多分辨率卡尔曼滤波（MKF），对高水平被动微波（PMW）LST 数据进行降尺度处理，以填补 MODIS LST 观测数据的空白，从而生成全天候 LST 数据[28]。除卫星辅助数据外，地表模型还可与 MODIS 和 Landsat LST 集成，生成无间隙 LST，用于昼夜动态研究[29]。然而，基于回归的模型假定 LST 与 LST 预测因子之间的关系是位置不变的，这可能不适用于在区域尺度上应用本地预训练关系。此外，这些模型的性能取决于辅助数据的空间分辨率和准确性。</p> <p>基于时空融合的模型（STFM）基于地表动态的时空连续性特征，利用时间序列卫星数据捕捉粗像素和细像素在空间和时间上的关系[30]。它们为合并来自多个传感器的数据提供了一种很有前途的方法，而无需考虑计算机视觉领域中大多数基于学习的模型中缩减比例问题的限制。由于两种分辨率的观测数据都是由不同卫星持续更新的，因此融合后的高分辨率时空数据可以捕捉地表的动态变化，如物候和土地覆盖的变化[31-32]。在过去十年中，基于这两个基本概念开发了几种 STFM。首先，基于加权过程对图像进行融合，该过程假定目标时间点处粗像素和细像素之间的残差可通过线性加权函数与之前时间点处可用的粗-细像素对的残差数量进行估算。这些粗-细像素对搜索可以基于给定空间和时间搜索窗口的光谱和时间相似性。因此，这些模型被归类为基于加权的模型，如 STARFM [33-34]、STAARCH [35]、ESTARFM [36] 和 Fit-FC [37]。其次，图像融合是基于一个解混过程，该过程假定粗像素变化信号（通常是时间序列中的变化比率或残差）可以根据几个具有派生覆盖的内成员进行解混，然后通过加权函数将这些内成员添加到精细分辨率图像中。典型的模型包括 MMT [38]、STDFA [39]、ESTDFM [40]、U-STFM [41]、STRUM [42]、OB-STVIUM [43] 和 ISTDFA [44]。在这些模型中，内含物或同质变化区域（HCR）的数量是任何基于解混模型的标准参数之一。近年来，许多模型结合了这两种基本思想（加权和解混），在克服基于加权模型的地表变化建模局限性方面取得了巨大成功。它们适用于捕捉物候和土地覆被等变化。典型模型包括 FSDAF [45]、FSDAF 2.0 [46]、TC-Umixing [47]、RASDF [48] 和 VSDF [49]。</p> <p>在考虑对陆地表面温度（LST）进行降尺度时，必须认识到陆地表面温度的昼夜动态变化受到不同方位角和天顶角的动态太阳辐射以及风速和地表湿度等因素的影响。这种高度动态的时空特征对传统的基于时空融合的模式提出了三个重大挑战（详细分析见第2.1节）。首先，热信号的混合过程具有非线性。例如，在粗像素中，信号可能由子像素热点或冷点主导，而这些热点或冷点与分数覆盖无关。因此，当前的线性系统可能不适合LST的时空解混[50]。其次，在当前的线性解混系统中，过多的内涵物或分部覆盖率较小的HCR会导致解混函数成为一个假问题，无法提供正确的解。第三，当前的加权函数容易受到噪声的影响，导致由于输入数据的微小误差而对最终 LST的预测不可靠。其根本原因在于理论加权函数对数据噪声的容忍度较低。</p> <p>针对当前时空融合模型（STFM）的三个局限性，本研究引入了一种增强型 U-STFM模型，该模型结合了深度学习组件，用于陆地表面温度（LST）的非线性降尺度。具体来说，我们加入了两个深度学习组件，即DyNet和RatioNet，以取代原有的解混函数和加权函数。我们选择U-STFM作为基线模型，该模型最初侧重于降尺度MODIS表面反射率[41]，后来通过降尺度MODIS海洋叶绿素浓度产品[51]将其应用扩展到预测动态参数。在本研究中，我们在中国深圳对该模型进行了测试和比较，深圳是一个因经济增长而导致土地覆被快速变化的地区。</p> <p>本研究的主要目标如下：</p> <ol> <li> <p>开发一个深度学习组件（DyNet），用于在U-STFM框架内对LST进行非线性解混。</p> </li> <li> <p>利用深度学习组件（RatioNet）捕获的数据分布，提高加权函数的抗噪能力。</p> </li> <li> <p>扩展地表反射率降尺度的原始U-STFM模型，以适应时间变异性更高的传感器，从而能够生成 30 米尺度的日LST产品。</p> </li> </ol> <h3 id="数据源及研究区">数据源及研究区</h3> <h4 id="研究区域">研究区域</h4> <p>随着城市化的快速发展，城市热岛效应对城市及周边地区的生态环境产生了重大影响。城市热岛效应是指城市温度高于周边农村地区的现象。造成这种温差的主要原因是人类活动和城市基础设施，如建筑物、人行道和交通系统，它们比自然景观更有效地吸收和保留热量。随着城市继续快速发展和城市化，城市热岛效应变得更加明显。这种现象会导致各种环境和生态后果。例如，它会影响当地气候、空气质量、能源消耗，甚至人类健康。因此，了解和缓解城市热岛效应对于创建可持续发展的宜居城市至关重要，而这在很大程度上依赖于高时空分辨率的地表温度监测数据。</p> <p>粤港澳大湾区（GBA）是中国正在经历快速城市化的地区。在粤港澳大湾区内，东莞市和深圳市作为主要的城市中心，随着国家经济的快速发展，在土地利用和城市发展方面发生了重大变化。大面积的荒地和林地被改造成城市区域，导致地表温度空间模式的快速变化。</p> <p>本研究选择了粤港澳大湾区的一部分作为研究区域，面积约为 1843 平方公里（介于东经 113°49′13″- 114°16′10″ 和北纬 22°37′17″-22°59′48″之间），如图 1所示。所选区域地形复杂，土地覆被类型多样，为评估时空融合模型（STFM）处理土地覆被快速变化的能力提供了一个综合场景。</p> <p><img src="/SIAT-GeoScience/assets/images/9e11ba276356636f47d57f7c73567298.png" alt=""/></p> <p>图1研究区域</p> <h4 id="数据集">数据集</h4> <p>与大地遥感卫星 7 号的地表温度产品相比，MODIS Terra的日间地表温度产品被用于从 1000 米降到 30 米。在本研究中，两颗卫星在同一日期的地表温度（LST）的微小差异被视为系统误差，可以忽略不同日期之间巨大的地表温度差异。MODIS LST产品（MOD11A1.006）和Landsat7 ETM + LST 产品（Landsat 7 ETM Plus Collection 2 Level-2）来自USGS Earth Explorer（https://earthexplorer.usgs.gov（2022 年 4 月 12 日访问））。经USGS处理后，ETM + LST 的空间分辨率为30米，重访频率为16天。由于ETM + SLC在2003年5月31日后失效，加上研究区域常年阴雨，本研究选择了2000年9月至2003 年5月期间云量阈值小于1%的数据，收集了8对有效的Landsat7 LST和MODIS LST图像。详情见表 1。</p> <p>表1研究区域使用的大地遥感卫星 7 LST 和 MODIS LST 产品列表</p> <p><img src="/SIAT-GeoScience/assets/images/573bd8295b3e13ff1f6ad5c47228e05e.png" alt="A screenshot of a data table Description automatically generated"/></p> <h3 id="模型方法介绍">模型方法介绍</h3> <h4 id="原始u-stfm">原始U-STFM</h4> <p>在本研究中，我们选择U-STFM作为基线模型。U-STFM模型最早是由Huang和Zhang于 2014 年针对地表反射率数据提出的。该模型是一种典型的基于解混的STFM模型，包含线性解混函数和加权函数。关于U-STFM的详细解释可参见原论文[41]。我们在此对U-STFM进行简要介绍。</p> <h4 id="原始-u-stfm-的问题">原始 U-STFM 的问题</h4> <p>在本研究中，我们主要关注与原始 U-STFM 相关的两个关键问题。第一个问题与原始解混函数的线性不稳定性有关，第二个问题与原始加权函数的误差敏感性有关。</p> <p>解混函数在时空数据融合模型中起着至关重要的作用。最初的解混函数基于线性解混理论，该理论假定粗像素的能量可表示为精细分辨率像素的线性组合，并按其覆盖率分数加权。如图 1 所示，通过线性解混函数，我们可以在 MODIS 层面上分配多个变化率，并利用覆盖分数矩阵来确定 HCR 层面上的时间变化率。当图像数量超过未知值数量时，该函数就可以求解。通常情况下，由于本研究区域的 MODIS 像素数量明显多于 HCR 数量，因此可以满足这一条件。但是，如图 2所示，当 HCR 数量增加时，覆盖率矩阵（红色突出显示）变得稀疏，导致线性系统的不稳定性增加。</p> <p><img src="/SIAT-GeoScience/assets/images/68894bb616920340925f5a2d5afbba83.png" alt="A diagram of a graph Description automatically generated"/></p> <p>图 2解混函数的局限性。红色区域代表HCR，黑色方块代表MODIS像素。左图中的绿色区域表示HCR跨多个MODIS像素的情况，右图中的绿色区域表示HCR只被一个MODIS像素覆盖的情况，这是使覆盖派系矩阵更加稀疏的结果。</p> <p>通过将目标日期之前和之后的精细图像与HCR层面的 LST变化率合成，预测出精细分辨率图像。然而，如图 3所示，这种加权函数的问题在于，当包含误差时，LST预测误差会表现出不同的敏感度。更具体地说，在红色区域内，即使是微小的变化也会导致LST预测结果的巨大差异。该区域内的误差容限相对较小。</p> <p><img src="/SIAT-GeoScience/assets/images/1d8645bbf7861a891c7b1b60bd5b7fdb.png" alt="A picture containing text, line, screenshot, font Description automatically generated"/></p> <p>图 3原始加权函数的问题：红色区域代表误差敏感度较高的区域；蓝色区域代表敏感度较低的区域。</p> <h4 id="非线性-u-stfm">非线性 U-STFM</h4> <p>非线性U-STFM继承了U-STFM模型的尺度不变性，是一种基于解混的 STFM模型，假定MODIS和Landsat时间序列中的热信号变化比相同。因此，在尺度不变性假设下，MODIS时间序列中捕获的变化率可应用于Landsat序列。</p> <p>根据这一想法，我们设计了两个多层感知器（DyNet和RatioNet），在解混和加权过程中形成数据驱动的非线性预测。如图 4所示，预测目标日期的 30 米级陆地表面温度（LST）时，需要将前一日期，目标日期和后续日期的MODIS LST数据组织成三个日期对。随后，可以计算MODIS LST数据集中不同日期之间的LST差值。此外，还可以计算MODIS每个像素的变化率，并将其作为DyNet 模型的输入。DyNet的输出提供了每个HCR的变化率，这反过来又成为RatioNet的输入，从而获得目标日期LST的最终预测结果。</p> <p><img src="/SIAT-GeoScience/assets/images/fabe82d6a87cb399bc544da29473e8eb.png" alt="A diagram of a diagram Description automatically generated"/></p> <p>图 4非线性 U-STFM 的基本思想</p> <p>与最初的 U-STFM 不同，非线性 U-STFM 是一种数据驱动模型，使用适当的数据集进行训练。本研究的工作流程如图 5所示。主要分为四个步骤。第 1 步：确定同质变化区域（HCR）。HCR被确定为具有相似LST变化趋势并可共享相似变化率的区域，以便进行下一步工作。利用时间序列高分辨率Landsat数据建立特征空间，以识别HCR，并建立用于训练的数据集。步骤2：训练DyNet 和 RatioNet。这一步的主要任务是训练模型，以捕捉MODIS与子像素HCR之间变化率的非线性关系。训练完成后，非线性U-STFM模型将用于预测基于时间序列MODIS和Landsat数据的更高分辨率LST产品。第四步，我们将非线性模型与原始U-STFM模型以及两种常用降尺度模型STARFM和ESTARFM进行了比较，评估了非线性模型的性能。</p> <p><img src="/SIAT-GeoScience/assets/images/75d7436d6df5c88a7a4cf5f037fb6ddb.png" alt="A diagram of a training model Description automatically generated"/></p> <p>图 5整体技术流程</p> <p>在统一的太阳辐射和蒸发条件下，相似的地表材料或土地覆被类型随着时间的推移呈现出相似的热模式。表现出相似变化规律的区域被确定为同质变化区域。每个同质变化区域都有相似的变化率，可作为解混过程的指标。在 U-STFM模型中，HCR是由分割过程定义的。考虑到模型的跨时间泛化，我们根据聚类方法定义了HCR。具体来说，我们使用k-means聚类法来定义用于预测的 HCR。本研究对不同数量的类进行了比较。</p> <h4 id="非线性解混模型dynet">非线性解混模型（DyNet）</h4> <p>考虑到热信号的辐射效应，UTFM使用的传统线性解混模型并不合适，因为热点（HCR）可能会根据 MODIS信号的温度对其产生更大的影响。HCR与 MODIS信号之间的关系似乎是非线性的。</p> <p>为了克服解混函数不稳定的问题，我们根据历史数据集引入了动态多层感知器（DyNet）来捕捉这种非线性关系。工作流程如图 6所示。</p> <p>DyNet的训练数据集是利用Landsat和MODIS LST历史产品计算得出的。DyNet的输入是MODIS LS在三个日期的时间变化率， 分别代表前一个日期、目标日期和后一个日期。DyNet 的输出是 HCR 水平的时间变化率 ，即 30 米水平的平均值。和的计算遵循公式 (2)。</p> <p><img src="/SIAT-GeoScience/assets/images/2c22140b2134fb9bb2321c08be7d4e8c.png" alt="A diagram of a model Description automatically generated"/></p> <p>图 6使用 DyNet 训练解混模型的工作流程</p> <p>DyNet有两个动态层作为输入层和输出层，还有五个隐藏层，每层有 128 个神经元。所有七个层都是全连接的，以捕捉非线性关系。整个结构可解释为与一组 MODIS像素（本研究中为 2000 个）进行解混，其中， 表示由聚类或分割算法定义的 HCR 数量。DyNet的训练过程基于小批量随机梯度下降法。如图 7所示，输入层中的神经元代表用于解决非线性解混问题的 MODIS 像素总数。例如，如果选择 2000 个MODIS像素进行解混，就会有 2000 个神经元。DyNet对输入层的数量没有具体要求，因为这些 MODIS 像素可以覆盖所有同质变化区域（HCR）。为避免潜在的 “姿态不佳问题”，建议使用足够多的 MODIS 像素，以确保覆盖所有HCR。这一数量可作为模型的超参数。我们根据该地区 4000 多个MODIS像素的总数，随机抽取了一半的MODIS像素（2000 个），以确保覆盖所有HCR。输出层中的神经元代表HCR的变化率。由于每个批次只包含特定的MODIS像素和HCR，因此输入层和输出层仅由该特定批次中的MODIS像素和HCR激活。不属于当前批次的神经元会被剔除。因此，输入和输出层在训练过程中会发生动态变化。由于每个批次都给出了部分预测值，因此最终预测值是通过使用每个HCR的中值计算将每个批次的多个预测值组合起来得到的。中值用于减轻离群预测的影响，因为它们对平均值的影响更大。均方误差 (MSE) 被用作训练时的损失函数。在将模型从一个区域应用到另一个区域时，如果各区域采用相同的聚类或分割规则，则模型可以重复使用，无需重新训练。</p> <p><img src="/SIAT-GeoScience/assets/images/3f39b1025161ad03c59e49ab03b3df3f.png" alt="Diagram Description automatically generated"/></p> <p>图 7 DyNet 训练过程</p> <h4 id="非线性加权模型rationet">非线性加权模型（RatioNet）</h4> <p>使用真实数据训练的多层感知器模型可以有效捕捉数据分布，并构建一个潜在特征空间，从而根据特征相似性进行准确预测。该模型解决了 U-STFM 原始加权函数中存在的误差敏感性问题。建立稳定的特征空间是训练人工模型的重要前提。然而，原始加权函数根据 ()处 LST 和（ ()）处 LST 的大小呈现出两种不同的图形。要训练 RatioNet，数据必须经过三个步骤的转换过程，才能将这些发散图转换为稳定的特征空间。更多详情可参见图 8。</p> <p><img src="/SIAT-GeoScience/assets/images/2cb8b942bd4990cb281bd29345931668.png" alt="A diagram of mathematical equations Description automatically generated"/></p> <p>图 8 RatioNet 训练前的数据预处理</p> <p>RatioNet的结构和训练过程如图 9所示。</p> <p><img src="/SIAT-GeoScience/assets/images/ff9cccb10e5fafdbe6cf25043d727448.png" alt="A diagram of a training process Description automatically generated"/></p> <p>图 9 RatioNet的训练过程</p> <h4 id="利用非线性-u-stfm-预测每日高分辨率-lst">利用非线性 U-STFM 预测每日高分辨率 LST</h4> <p>在预测阶段，从时间序列MODIS LST产品中整理出目标日期的多个三日期对。在每个日期对中，计算MODIS时间变化率 作为DyNet的输入。DyNet将预测 结果作为其输出。然后，根据第 3.3.2 节中提到的数据转换方法，将 转换为作为RatioNet的输入。RatioNet提供了对 的预测，然后根据 计算出精细分辨率下的最终结构LST。根据这一过程，每个三日期对都能提供目标日期的LST预测值。像素级计算的中值提供了最终的LST预测值。预测过程如图 10所示。</p> <p><img src="/SIAT-GeoScience/assets/images/f20b037a11c1c48e2e9452ed440871b8.png" alt="A diagram of a product Description automatically generated"/></p> <p>图 10非线性 U-STFM 预测工作流程</p> <h3 id="评估">评估</h3> <p>在本研究中，采用定性和定量评估方法对模式预报地表温度的效果进行了评估。每次预报都使用空间分辨率为 30 米的陆地卫星地表温度数据作为地面实况。在八个日期中共有六个可信日期。每天对不同的三日期组合组进行评估；例如，2001 年 11 月 20 日就有 12 个三日期组合组。通过对比和检查预期的和实际的 LST 图像对可视化的影响，对模型融合进行了定性评估。在定量评估中，使用了峰值信噪比（PSNR）、相关系数（CC）、均方根误差（RMSE）和平均绝对误差（MAE）。PSNR 是全参考图像的图像质量评价指标。CC值的有效范围介于（-1，1）之间；值越接近 1，表明融合结果越好。更好的预测与更高的PSNR 值、更低的RMSE值和MAE值相关。所有定量评价指标均使用scikit-learn模块中的函数计算。</p> <h3 id="试验结果及讨论">试验结果及讨论</h3> <h4 id="dynet-和-rationet-的训练过程">DyNet 和 RatioNet 的训练过程</h4> <p>使用小批量随机梯度下降算法，可以轻松训练DyNet和RatioNet。图 11显示了训练过程中 500 个历时的损失变化。对于DyNet，测试损失值在 100 个历时后趋于平缓，没有出现过拟合的迹象。测试损失高于训练损失，这表明基本解混过程的难度很大。这可能与训练的批量大小有关。DyNet使用两个动态层来预测每个HCR的变化率，因此建议使用较大的批量。每个批次的平均值被计算为损失。批量越大，就会有越多的MODIS像素参与形成解混过程，损失值也就越接近使用整个验证数据集计算出的地面真实损失。RatioNet的损失图是平滑的，表明根据第4.3.2节所述的数据转换改变特征空间后，网络的学习过程更加容易。</p> <p><img src="/SIAT-GeoScience/assets/images/ab10543b537efb05b2d69d408034494e.tiff" alt=""/></p> <p>图 11训练和测试过程中的损失值变化</p> <h4 id="云雾遮挡下的-lst-预测">云雾遮挡下的 LST 预测</h4> <p>云层效应是 LST 产品噪音的主要来源。云层温度明显低于地面温度。在我们的数据集中，2000 年 11 月 1 日的数据部分被云层覆盖。因此，我们对模型预测包含噪声（本例中为云层）的日期的 LST 性能进行了评估。</p> <p>图 12显示了使用DyNet模型预测的每个同质变化区域(HCR)的变化率。在预测 2000 年 11 月 1 日的陆地表面温度时，共考虑了六组三个日期的组合。该图展示了DyNet模型在不同目标日期的一致表现，同时保持了统一的参数。值得注意的是，每个HCR的实际变化率范围可以包含任何数字，因为没有特定的范围被定义为基本事实。在预测过程中，整个图像被剪切成 256 × 256 像素的大小，作为模型的输入。每个批次对该特定批次所涵盖的HCR的变化率进行预测。因此，方框图代表了每个HCR的多个预测值，这些预测值的中值被用作最终的变化率。计算均方根误差（RMSE）是为了评估变化率预测值与地面实况值之间的差异。考虑到不同目标日期的变化率存在差异，DyNet模型的总体性能令人满意。<img src="/SIAT-GeoScience/assets/images/e5aacb907e24b19729f2590bf71ee494.tiff" alt="A group of graphs showing different sizes and shapes Description automatically generated with medium confidence"/></p> <p>图 12 DyNet对各HCR变化率的预测：红色叉号代表地面实况，不同海滩多次预测的中值被用作各HCR变化率的最终预测值</p> <p>表 2和图 13列出了每个三日期组对 2000年11月1日LST的最终预测结果。预测误差主要有两个原因。首先，它源于DyNet模型预测每个HCR变化率的准确性。例如，在20000914-20001101-20010917 案例中，DyNet预测的均方根误差(RMSE)达到最高值1.579。因此，LST对这一特定日期三元组预测的最终均方根误差达到了3.875。其次，预测误差受基线长度的影响，基线长度表示前一个日期和后一个日期之间的LST差值。如图 3所示，基线长度越小，压缩的数据空间就越接近数值，从而导致RatioNet模型的预测误差越大。例如，考虑 20000914-20001101-20021107 的情况。DyNet 预测的 RMSE 相对较小，为 0.864。但是，该案例的基线长度为 3.015，表 RatioNet的预测不确定性更高。</p> <p>表 2基于非线性U-STFM（DyNet+RatioNet）对每对日期的 30 米海平面LST预测</p> <p><img src="/SIAT-GeoScience/assets/images/a8e8176ac508e2b864ff0c0b0d6dff90.png" alt="A table with numbers and symbols Description automatically generated"/></p> <p>在实际的应用过程中，DyNet和RatioNet因基线较短而积累的误差可以通过像素级中值组合得到缓解。图 13显示，1:1中值组合图能有效过滤掉不准确的预测，从而提高准确率。</p> <p><img src="/SIAT-GeoScience/assets/images/a16bfb0b4fe41d99bcab0917d20b0ae7.png" alt="A group of graphs showing different colored lines Description automatically generated with medium confidence"/></p> <p><img src="/SIAT-GeoScience/assets/images/b94ec4ed4221f1403ff564cf371ac871.png" alt="A graph showing a graph Description automatically generated with medium confidence"/></p> <p>图 13用不同的三个日期对预测2000年11月1日LST的 1:1 图（左）和最终组合预测结果（像素级的中值）</p> <p>如图 14c中红圈所示，2000年11月1日大地遥感卫星观测到的实际陆地表面温度受云层的部分影响。然而，图 14a所示的MODIS数据没有捕捉到这部分云层信号，导致图 14b所示的非线性U-STFM模型预测中没有云层指示。由于云覆盖区域的LST值是根据被云覆盖的相同HCR内的变化率填充的，因此在 1:1 图（图 14d）和 RMSE 图像（图 14d）中也可以观察到云效应的影响。</p> <p><img src="/SIAT-GeoScience/assets/images/a2e8d9c96621d8b9183c60843df2b3d0.png" alt="A screenshot of a computer generated image Description automatically generated"/></p> <p>图 14根据多个三重日期组合得出的最终预测结果（2000年11月1日）。(a) 2000 年11月1日的原始MODIS LST；(b)我们的模型预测；(c) Landsat LST；(d)我们的模型预测与Landsat LST之间的1:1图；(e)我们的模型预测与Landsat LST之间的均方根误差图。图15中的（1）-（3）为子区域</p> <p>为了评估模型检测微妙信号的能力，我们选择了热点和冷点作为参考点。图 15显示，模型成功捕捉到了热点，即区域1和区域2中的红点。此外，模型还准确识别出了区域3冷屋顶上太阳能电池板的存在。</p> <p><img src="/SIAT-GeoScience/assets/images/25691a03c7b876eaf0039564c8321155.tiff" alt="A screenshot of a map Description automatically generated"/></p> <p>图 15 局部区域预测情况</p> <h4 id="土地覆盖变化后的-lst-预测">土地覆盖变化后的 LST 预测</h4> <p>在3.1.6.2节中，我们主要展示了在目标日期存在云层影响的情况下的预测性能。在本节中，我们将评估模型在目标日期之前出现陆地表面温度变化时的性能。为了模拟这些陆地表面温度变化，我们在本节中使用云层作为陆地覆盖变化的替代物。</p> <p>2000年11月1日大地遥感卫星观测到的LST有部分云层覆盖。我们假设这些被云层覆盖的区域代表了土地覆被的变化。为了评估这些变化对后续模式预测的影响，我们进行了测试。在本节中，我们将2001年9月17日的LST预测作为目标日期，以研究2000年11月1日的观测结果如何影响2001年9月17日的预测。</p> <p>图 16显示了2001年9月17日的预测结果。如 RMSE 图（图 16e）所示，模式捕捉到了2000年11月1日发生的LST变化，并反映在 2001 年9月17日的预测结果中。如果去掉2000年11月1日的数据，预测结果没有任何变化（图 17）。当我们从时间序列中删除 2000 年 11 月 1 日的数据时，均方根误差要大得多。这是因为就 2001年 9月17日的预测而言，如果去掉2000年 11 月1日的数据，就去掉了最终中位值组合中50%的日期三胞胎，这也增加了模型的不确定性。</p> <p><img src="/SIAT-GeoScience/assets/images/1404a438ed8bfe795a4bebbac26c7431.tiff" alt="A collage of images of different types of landrats Description automatically generated"/></p> <p>图 16 2001年9月17日的预测。(a）原始MODIS LST；（b）我们的模型预测；（c）Landsat LST；（d）我们的模型预测和Landsat LST之间的 1:1 图；（e）我们的模型预测和Landsat LST之间的均方根误差图</p> <p><img src="/SIAT-GeoScience/assets/images/24b56337a17387d2eb9b31aa73c713e5.tiff" alt="A screenshot of a computer screen Description automatically generated"/></p> <p>图 17 有无2000年11月 1日数据的 2001年9月17日预测对比。红圈标出部分为云层干扰部分</p> <h4 id="多日期预测的模型通用性">多日期预测的模型通用性</h4> <p>还对模型在不同时间段的通用能力进行了评估。最初的 U-STFM 方法是为每个目标日期开发单独的解混模型，与此不同，非线性U-STFM采用了一致的解混模型，与日期无关。图 18展示了多个日期预测的1:1图。这六天LST预测的总体均方根误差（RMSE）保持在2.1 k以下，表明统一解混模型（DyNet）和加权模型（RatioNet）在不同日期的成功泛化。</p> <p><img src="/SIAT-GeoScience/assets/images/dda36293f8a9fbb49da6a1d7e21c3bd9.tiff" alt="A group of graphs showing different colors Description automatically generated with medium confidence"/></p> <p>图 18 多日期预测的 1:1 图</p> <h4 id="不同-hcr-水平下模型的性能">不同 HCR 水平下模型的性能</h4> <p>如前所述，非线性 U-STFM 模型面临的挑战之一是线性解混函数在处理大量 HCR 时的局限性。为了评估该模型在不同 HCR 水平（HCR-45、HCR-145 和 HCR-245）下的性能，我们将其与使用线性解混函数的原始 U-STFM 进行了比较。</p> <p>图 19和图 20分别显示了2000年11月1日和2001年9月17日的模型比较结果。1:1 图说明了 U-STFM和非线性 U-STFM 模型的中值组合结果。方框图显示了三个不同数据三元组的均方根误差 (RMSE) 值范围。</p> <p>在 2000 年 11 月 1 日（图 19），当使用非线性 U-STFM 模型时，随着 HCR 数量的增加，RMSE 方框图明显下降。然而，原始 U-STFM 模型并没有出现类似的下降。</p> <p>同样，对于 2001 年 9 月 17 日，均方根误差也随着 HCR 数量的增加而减小。然而，原来的 U-STFM 模型显示出估算不足，均方根误差很高。</p> <p><img src="/SIAT-GeoScience/assets/images/b852caf8c25106068bb09a807aa40b5c.tiff" alt="A graph of different colored lines Description automatically generated with medium confidence"/></p> <p>图 19 2000 年 11 月 1 日在多个 HCR 设置下与U-STFM的比较；(a) 45 HCRs 组的结果；(b) 145 HCRs组的结果；(c) 245 HCRs组的结果；(d) 45、145和245 HCRs组的RMSE方框图</p> <p><img src="/SIAT-GeoScience/assets/images/5d52561323a0f1c4746462fba40b5a7d.tiff" alt="A graph of a diagram Description automatically generated with medium confidence"/></p> <p>图 20 2001年9月17日与U-STFM在多HCR设置下的比较。(a) 45 HCRs组的结果；(b) 145 HCRs 组的结果；(c) 245 HCRs组的结果；(d) 45、145和245 HCRs组的均方根误差方框图</p> <h4 id="rationet-性能">RatioNet 性能</h4> <p>RatioNet 的目标是利用数据分布和样本相似性来减轻噪声效应，而不是依赖理论加权方程。为了评估RatioNet的性能，我们引入了高斯随机噪声，以降低DyNet预测的信噪比 (SNR)，特别是每个HCR的变化率预测。我们对两种设置进行了比较：一种是使用带有理论加权方程的DyNet模型，另一种是使用带有RatioNet的DyNet。</p> <p>1:1 图表示两个模型的中值组合结果。在 SNR50 和 SNR30 的情况下，RatioNet 的优势并不特别明显，因为中值组合本身就能起到噪声滤波器的作用，即使在低噪声水平下也能提高预测精度。然而，随着 SNR 进一步降低，包含 RatioNet 的模型表现出更优越的性能（图 21）。</p> <p><img src="/SIAT-GeoScience/assets/images/7241bf1f87b0c02479cf9de3b6142ff7.tiff" alt="A graph of different colored lines Description automatically generated with medium confidence"/></p> <p>图 21 2000 年 11 月 1 日使用不同信噪比进行的预测</p> <p>方框图说明了 RatioNet 在没有中值组合过程时的性能。它清楚地表明，RatioNet 可以大大降低每个日期三重预测的均方根误差 (RMSE)，尤其是在信噪比较低时（图 22）。</p> <p><img src="/SIAT-GeoScience/assets/images/978ab197ece8e5d31b8f0bffce4eda96.tiff" alt="A group of blue and orange boxes Description automatically generated"/></p> <p>图 22不同信噪比的预测方框图</p> <h4 id="与-starfmestarfm-和原始-u-stfm-比较">与 STARFM、ESTARFM 和原始 U-STFM 比较</h4> <p>与 STARFM、ESTARFM 和原始 U-STFM 相比，非线性 U-STFM 性能更优，表现出更高的峰值信噪比 (PNSR) 值和更低的均方根误差 (RMSE) 值。详细结果见表 3。图 23 所示的均方根误差图显示，没有任何特定土地覆被类型的均方根误差值明显更高。这表明该模型并没有偏向特定的土地覆被类型。此外，图 23还表明，非线性 U-STFM 有能力自动填补因目标日期 MODIS 数据缺失而造成的云差距。这是通过采用聚类算法定义 HCR 实现的。此外，还可利用属于同一 HCR 类别的其他 MODIS 像素来估算云区下的变化率。</p> <p>表 3非线性 U-STFM 与 STARFM、ESTARFM 和原始 U-STFM 的比较，粗体值代表每组中表现最好的模型</p> <p><img src="/SIAT-GeoScience/assets/images/62d5dbf63081da3942f8c7ad37150603.png" alt="A table with numbers and text Description automatically generated"/></p> <p>2001年9月17日STARFM、ESTARFM和U-STFM的RMSE值差异很大，这可能是由于2000年11月1日的云层效应造成的。由于用于预测 2001年9 月17日的三个日期对中有一半包含2000年11月1日的图像，这对 STARFM、ESTARFM 和 U-STFM 的加权函数影响很大。另一个影响因素可能是每个模型所使用的处理单元。STARFM 和 ESTARFM 在像素级别上运行，考虑周围的相似像素。相比之下，UTFM 采用的是由分割算法定义的更大处理单元，从而产生局部区域。非线性 U-STFM 的处理单元最大，由集群定义，有助于减少预测的不确定性。</p> <table> <thead> <tr> <th><img src="/SIAT-GeoScience/assets/images/c02d29c921116840be95d216102938ed.tiff" alt="A collage of images of different colors Description automatically generated"/></th> </tr> </thead> <tbody> <tr> <td><img src="/SIAT-GeoScience/assets/images/0e444d5ccffaf8007df6af2a3c78997b.tiff" alt="A collage of images of snow Description automatically generated"/></td> </tr> <tr> <td><img src="/SIAT-GeoScience/assets/images/c73245fdd852c3bda0e0817d05b268f5.tiff" alt="A collage of images of blue and white spots Description automatically generated"/> 图 23与 STARFM、ESTARFM 和 U-STFM 预测 RMSE 的比较</td> </tr> </tbody> </table> <h3 id="讨论">讨论</h3> <h4 id="hcr-和像素级变化率之间的截断误差">HCR 和像素级变化率之间的截断误差</h4> <p>U-STFM 的基本要素是变化率，理想情况下，它应能准确预测象素级的变化率。这样就可以根据目标日期前后的陆地表面温度值，精确预测该日期的高分辨率陆地表面温度（LST）。然而，由于问题的不确定性，预测像素级的变化率本身就具有挑战性。未知的 30 米空间分辨率 Landsat 像素数量始终大于已知的 MODIS 像素数量。为了应对这一挑战，采用了内元提取方法来减少未知数的数量。通过将待确定的内含物数量减少到低于已知 MODIS 像素数量，就可以利用解混函数预测每个内含物的值。在 U-STFM 模型中，这些内含物被称为光谱解混的高变化率（HCR）内含物。不过，需要注意的是，每个 HCR 的变化率并不一定与该 HCR 中像素的变化率一致。因此，这些不同层次的分析之间存在截断误差。</p> <p>图 24显示了在高变化率 (HCR) 和像素水平上观察到的变化率之间的截断误差。平均值接近于零且差异范围较小的窄分布表明，HCR 中的预测变化率可以有效代表该 HCR 中大多数像素的变化率。理想情况下，分布的平均值为零，差值范围为零，表明 HCR 的变化率预测值与这些 HCR 中像素的实际变化率完全相同。</p> <p>观察图 24，我们可以发现，不同日期对（不同行）和不同数量 HCR（不同列）的截断误差均值始终接近于零。这表明 DyNet 模型对 HCR 变化率的预测是无偏的。此外，在比较不同的 HCR 数量（如 HCR-45、HCR-145 和 HCR-245）时，我们发现分布的平均值随着 HCR 数量的增加而降低。这表明，较小的 HCR 能更准确地反映像素级的实际变化率。因此，为了进一步减少截断误差，未来的研究可能需要一种更精确的末级成员提取方法。</p> <p><img src="/SIAT-GeoScience/assets/images/5e3aae00b887b7e26da3bc332f704cd8.tiff" alt="A screenshot of a graph Description automatically generated"/></p> <p>图 24 HCR 级变化率与像素级变化率之间的截断误差</p> <h4 id="基线长度效应">基线长度效应</h4> <p>加权函数预测的不确定性受到一个因素的影响，即和的陆地表面温度之间的相似性。 在本研究中，我们采用干涉合成孔径雷达（InSAR）领域使用的定义，将这种相似性称为“基线长度”。基线长度越短，加权函数的不确定性越大。图 25显示，基线长度越短，加权函数图越接近渐进线。</p> <p><img src="/SIAT-GeoScience/assets/images/5f63693fec2fe215d47bc78583ef6a3f.png" alt="A diagram of a graph Description automatically generated with medium confidence"/></p> <p>图 25 加权函数的理论图</p> <p>在像素级，当考虑到的情况时，如果变化率(α) 小于-1，即使α 的微小变化也会导致 LST 预测的显著变化。因此，在这种情况下，变化率对 LST 的预测就变得不可靠了。</p> <p>对 20000914-20001101-20021107 年期间的预测就是基线长度较短所造成影响的一个实际例子。表 2和图 13用不同的三个日期对预测2000年11月1日LST的 1:1 图（左）和最终组合预测结果（像素级的中值）显示，20000914 年和 20021107 年的 LST 平均基线长度为 3.015，标准偏差为 1.660。这表明这两个日期的 LST 相似度很高。在这种特殊情况下，尽管 DyNet 模型的预测误差仅为 0.864（如图 12所示），但加权函数未能提供准确的预测结果（均方根误差：3.937）。基线长度较短的问题主要源于 U-STFM 所选加权函数的理论限制。正如前面所分析的，要想获得更高的 LST 预测精度，选择基线长度较长的分歧 LST 对至关重要。</p> <p>因此，在本研究中，我们发现前日期和后日期之间的时间范围往往超过一年。这可能是由于云层覆盖和权重函数的固有局限性等因素造成的。如果前 LST 值和后 LST 值之间的时间范围较小，则每个像素获得相似 LST 值的可能性较高。在这种情况下，最终预测结果的不确定性可能会增加。因此，该模型不适合在前后观测日期范围过于接近的情况下进行预测，因为它可能会导致小基线问题。</p> <h3 id="结论">结论</h3> <p>陆地表面温度（LST）在各种地理物理过程模拟模型中起着至关重要的作用。近年来，将来自多个卫星平台的高空间分辨率和时间分辨率 LST 数据结合起来的方法受到了广泛关注。为实现这一目标，时空图像融合模型已成为一种有前途的降尺度方法。以往的研究已经证明了基于解混的融合模型（如 U-STFM）通过从时间序列数据中提取特征来捕捉土地覆被变化的有效性。这些模型在降尺度陆地表面反射率和海洋颜色产品等应用中取得了显著成功。然而，在提高原始线性解混函数和小解混内含物理论加权函数的准确性方面仍然存在挑战，特别是在处理 LST 快速变化和降尺度过程中的抗噪声能力时。</p> <p>为了应对这些挑战，我们引入了一种名为非线性 U-STFM 的 U-STFM 升级版本，其中包含一个深度学习模型。原有的解混频和加权函数被两个深度学习组件所取代： DyNet 和 RatioNet。采用了动态层和特征空间转换技术，即使在数据集相对较小的情况下，也能促进这些网络的训练。</p> <p>在研究中，我们选择了粤港澳大湾区的一部分作为研究区域，面积约为 1843 平方公里。利用 Landsat-7 和 Landsat LST 30 m 产品将 MODIS 每日数据的分辨率从 1000 m 降到 30 m。</p> <p>训练过程结束后，结果表明，统一解混网络（DyNet）能有效解混不同目标时间的 MODIS 像素，并随着高变化率（HCR）内含物数量的增加而降低均方根误差（RMSE）新的加权网络（RatioNet）成功地降低了解混过程中存在噪声时的均方根误差。与理论加权函数相比，RatioNet 加入了更多来自真实数据分布和样本相似性的特征，从而增强了模型的鲁棒性。我们还评估了非线性 U-STFM 在受云层影响的日期和 LST 变化方面的整体性能。在对照实验中，新模型的表现优于 STARFM、ESTARFM 和原始 U-STFM 等经典方法，获得了最高的准确率。</p> <p>与大多数将特征提取和建模作为黑盒子结合起来的端到端深度学习网络不同，本研究中开发的模型将网络与原始的 STFM 模型集成在一起，从而便于解释。此外，预训练网络可以提高预测速度，使其适用于在线实时应用。为了拓展这项研究，使用来自多个地区的不同数据源训练新开发的模型并随后评估其在全球范围内的泛化能力将大有裨益。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[来自卫星热传感器的陆地表面温度（LST）数据捕捉了地球表面能量分布在空间和时间上的详细变化。这些数据在蒸散观测和城市热建模等应用中发挥着重要作用[1-3]。然而，由于卫星轨道和传感器设计的限制，热波段的空间分辨率和时间分辨率之间通常存在权衡。日常传感器只能提供较低空间分辨率的数据，如分辨率为 1 公里的 MODIS LST。精细分辨率（100 或更低）的传感器通常受限于其扫描带宽度和轨道高度，只能提供数天内的数据，如大地遥感卫星系列平台的八天内数据（结合Landsat-7 、8和 9）。因此，在提升可用卫星资源方面，合并多个卫星传感器的数据是获得高时空分辨率观测数据的关键挑战之一，这将进一步惠及地表能量建模和精准农业等许多综合应用。]]></summary></entry><entry><title type="html">基于解混策略的时空融合模型稳定性分析—以地表温度为例</title><link href="https://shawnmiloguo.github.io/blog/2023/USTFM-LST/" rel="alternate" type="text/html" title="基于解混策略的时空融合模型稳定性分析—以地表温度为例"/><published>2023-02-16T00:00:00+00:00</published><updated>2023-02-16T00:00:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2023/USTFM-LST</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2023/USTFM-LST/"><![CDATA[<p>地表温度（Land Surface Temperature，LST）在地球表面与大气能量交换过程中有着重要的作用。然而受传感器性能的制约，利用单一的星载热红外传感器无法反演出同时具有高时间和高空间分辨率的地表温度，从而限制地表温度数据的应用。时空融合模型是解决这一问题的有效途径。目前，基于解混的时空融合模型稳定性的影响因素存在不确定性。针对此问题本文从同质变化单元（homogeneous change regions，HCRs）分类方式、解混次数以及HCRs数量三方面来分析模型稳定性。因此，本文以MODIS LST和Landsat7 LST数据为研究对象，基于解混的时空反射融合模型（Unmixing-based Spatio-Temporal reflectance Fusion Model，U-STFM）来分析解混策略对模型稳定性影响，并对比STARFM与ESTARFM两种经典的时空融合模型。结果表明，在模型HCRs划分方式上，对比多尺度分割算法和Kmeans算法，ISODATA算法更能有效的刻画出LST在时空变化中的HCRs，其基于ISODATA算法时模型PNSR中值46.9K，CC为0.94，RMSE为1.8K，MAE中值为1.08K；在模型解混次数上，对比模型直接对MODIS影像变化趋势比率解混、分别对俩组MODIS差分影像解混以及分别对三期MODIS单期影像解混，解混一次时模型更稳定，基于解混1次时模型PNSR中值为42.00K，CC为0.94，RMSE为3.18K，MAE中值为2.18K；在模型HCRs类别数量上，从类别10到类别295，随着HCRs数量增加模型预测效果越好，在类别104时趋于稳定，其基于HCRs类别数104时模型PNSR中值43.11K，CC为0.93，RMSE为2.81K，MAE中值为2.17K；最后通过对比经典模型，验证了基于上述解混策略时模型在融合生成高时空分辨率LST影像效果的有效性。</p> <h1 id="原文链接">原文链接</h1> <p><a href="https://www.mdpi.com/2072-4292/15/4/901">https://www.mdpi.com/2072-4292/15/4/901</a></p> <h1 id="背景及科学问题">背景及科学问题</h1> <p>地表温度（Land Surface Temperature，LST）是地表能量和水平衡中的一个重要成分，提供了从局部到全球表面平衡状态的时空变化信息^[1]^。现如今，地表温度被广泛应用于蒸散发估算、城市热岛监测、局部气候变化、植被监测、农业监测以及森林火灾监测等^[2–5]^。然而，由于地表热辐射的能量相对较低以及卫星传感器受限于成本和硬件技术，目前单一的卫星传感器获取的遥感数据存在“时空的矛盾”，即获取的地表温度难以同时满足高空间分辨率和高时间分辨率^[6,7]^，这极大程度限制了地表温度的应用需求。</p> <p>针对如何获取高时空LST这一问题，众多学者提出不同LST降尺度方法，按照算法理论分为基于尺度因子的降尺度方法和基于时空融合的降尺度方法。其中时空融合方法更能有效降低模型对辅助数据的依懒性，且低成本、便捷高效地实现地表温度的降尺度^[8]^，按照实现原理又可以分为基于权重函数的方法、基于学习的方法、基于解混的方法。</p> <p>基于权重函数的方法是假定地表反射率的时间变化在空间尺度上的一致性，通过权重函数组合所有输入影像的信息来预测目标影像高空间分辨率的像素值。Gao等人^[9]^最早提出时空自适应反射融合模型（Spatial and Temporal Adaptive Reflectance Fusion Model，STARFM），该模型假定粗分辨率影像中的像素为纯净像元，引入移动窗口和相似像元的概念，从光谱差异性、时间差异性以及空间距离来计算权重。对于复杂地貌中土地类型发生变化的区域，STARFM方法无法准确预测出未知时相真实的地物类型，导致融合结果产生较大误差。针对STARFM方法不足，Hilker等^[10]^提出了一种新的时空自适应反射率变化检测算法（Spatial Temporal Adaptive Algorithm for Mapping Reflectance Change，STAARCH），使用缨帽变换检测反射率变化，提高从低分辨率影像上检测出土地覆盖时空变化的能力。但STAARCH 中的变化检测仅适用于植被地表，因此Zhu等^[11]^提出的增强型时空自适应反射融合模型（Enhanced Spatial and Temporal Adaptive Reference Fusion Model，ESTARFM），引入转换系数和线性光谱解混理论，用光谱相关系数来代替空间距离，保留更多的空间细节的同时提高了在复杂地貌中的预测精度。针对ESTARFM 方法预测有形状变化的地物覆被随时间变化的准确性，Zhao等^[12]^人提出了鲁棒自适应时空融合模型（Robust Adaptive Spatial and Temporal Fusion Model ，RASTFM），由基于非局部线性回归的加权平均模块和基于非局部线性回归的图像超分辨率模块组成，分别用于预测地表非形状变化（包括物候变化和没有形状变化的土地覆盖变化）和形状变化（具有形状变化的土地覆盖变化）。STARFM系列模型参数简单，计算效率高，但在地物覆盖复杂、不同时相地物类型变化的预测仍具有局限性。</p> <p>基于学习的方法通过机器学习算法用非线性的方式对高、低分辨率影像对建模，预测出高时空分辨率影像。Huang等^[13]^提出基于稀疏表示的时空反射融合模型（SParse-Representation-Based SpatioTemporal Reflectance Fusion Model，SPSTFM），利用字典对学习建立低空间分辨率影像和高空间分辨率影像的对应反射率变化关系，并通过时间加权预测目标高分辨率影像。针对字典对中扰动问题，Wu等^[14]^提出误差约束正则化的半耦合字典学习（Error-Bound-Regularized Semi-Coupled Dictionary Learning，EBSCDL），利用误差约束的正则化方法解决字典扰动，构建优化的半耦合字典解决低空间分辨率影像和高分辨率影像之间差异性，提高融合精度。然而上述基于稀疏表示的融合方法需要人为设计字典基元，在算法实现过程中，字典学习、稀疏编码和影像重建等步骤是分离的，提升算法的不稳定性和复杂性。对此，Song等^[15]^提出深度卷积神经网络时空融合模型（Spatiotemporal Fusion Method Based on Deep Convolutional Neural Networks，STFDCNN），结合卷积神经网络、非线性映射模型设计了一个双重卷积神经网络，实现了自动提取影像特征并提高预测精度， 有效解决稀疏表示方法类的缺陷。基于学习的方法可以捕获到更多的地表空间细节，适用于异质区域等，但该类方法过度依赖训练样本和模型参数，具有较高的时间复杂性。</p> <p>基于解混的方法很好的弥补上述方法的不足，该类方法基于线性光谱混合理论，从高空间分辨率影像中提取地物类别和丰度来分解低空间分辨率的像元获得类别的光谱值^[16]^。其实现过程一般包括端元选取、丰度计算、解混等内容。 此类算法最早由Zhukov等^[17]^提出，该方法假设同类地物反射率相等，在移动窗口内解混低空间分辨率影像反射率，然后将解混结果分配给未知时相的高空间分辨率影像。 但该方法解混过程中会存在严重误差，且算法中的假设对于现实中地物类型随时间变化区域是不成立的。对此，Zurita-Milla等^[18]^在线性解混过程中引入约束条件，用来处理解混结果的负值和异常值问题；Wu等^[19]^提出时空数据融合模型（Spatial Temporal Data Fusion Approach，STDFA），基于各类地物覆盖时相变化总是相同的假设，引入时间变化信息，提高预测结果准确性；针对STDFA算法没有考虑到影像端元反射率的空间异质性，Zhang等^[20]^基于STDFA算法，结合多尺度分割算法和 ISODATA算法生成分类图，并利用移动窗口方法对低空间分辨率影像解混，最后引入时间权重概念预测未知时相影像；为了提升在地物类型变化区域模型预测准确度，Huang等^[21]^提出基于解混的时空反射融合模型（Unmixing-based Spatio-Temporal reflectance Fusion Model，U-STFM），该模型假设地物像元反射率在同质变化单元（homogeneous change regions，HCRs）上变化率相等，利用多尺度分割算法得到的超像素进行解混，从而提高了不同时相遥感影像在地表类型空间变化的融合效果。该类算法计算量小、可操作性强，提高了对于地物类型随时间变化的遥感影像融合精度，常用于反射率数据中。对于时间变化波动性强、光谱特征不丰富的LST数据，使权重函数类方法的参数更加敏感，也影响学习类方法训练量的有效性，导致这俩种方法总体融合效果较低。而基于解混的方法对于时刻发生变化的LST，在LST变化趋势相同的区域上结合不同传感器变化趋势比相等的假设，提高了不同时相LST的融合效果。</p> <p>由于温度解混的复杂性和病态矩阵解混的准确性，解混模型稳定性受到很大程度的影响，其主要体现在以下三个方面：首先是HCRs分类方式对模型稳定性影响，由于不同空间分辨率像素之间的温度变化具有差异性，影响从高分辨率影像提取HCRs的准确性。HCRs分类方式主要有聚类方法和面向对象分类方法，面向对象分类方法是以影像分割后的对象为分类单元来提取影像光谱信息、纹理信息以及几何信息，聚类方法是将空间内数据按照某种相似度聚集为不同类别；其次是解混次数对模型稳定性影响，解混类方法常采用最小二乘算法来求解线性混合方程组，是一个病态矩阵求解问题，解混次数的叠加也对模型的稳定性有一定的影响。最后是HCRs数量对模型稳定性影响，HCRs数量越多越能细致刻画地表变化，同时也增加了方程解的不确定性。因此，本文从HCRs分类方式、解混次数以及HCRs数量三方面来分析解混解混策略对模型稳定性影响。</p> <p>本文以粤港澳大湾区部分区域为研究区，选取Landsat7 LST产品和MODIS LST产品，基于U-STFM算法从HCRs的分类方式、解混次数以及HCRs的数量三方面分析对模型稳定性的影响，然后将改进后的方法与经典的STARFM、ESTARFM时空融合方法对比，验证该方法在LST数据中预测的有效性和稳定性。</p> <h1 id="研究方法介绍">研究方法介绍</h1> <p>具体实验设计如图2所示：</p> <p><img src="/SIAT-GeoScience/assets/2023-02-16图片1.png" alt="image.png" class="rounded"/></p> <p>图 1 实验流程</p> <p>本文采用Landsat7 LST和MODIS LST数据从HCRs分类方式、解混次数以及HCRs数量三方面来分析解混模型的稳定性，并将改进后的模型与经典模型对比LST融合后的精度。在U-STFM方法上，首先采用ISODATA算法[26]、K-Means算法[27]以及多尺度分割算法[28]分别获取HCRs分类图，选取2001年11月20日为预测日期，排列组合共12组实验日期对，通过对比基于HCRs不同分类方式得到的融合结果分析其对模型稳定性的影响；其次基于空间像元分解的时空融合方法原理[17]，在分析HCRs分类方式结果的基础上，控制变量HCRs的类别数，分别对MODIS单期影像、MODIS差分影像、MODIS影像变化趋势比率进行解混，选取表1中的8个预测日期排列组合共169组影像，通过对比基于解混次数得到的融合结果分析其对模型稳定性的影响；然后在上述分析的结果基础上，同样选取表1中的8个预测日期排列组合共169组影像，通过对比不同HCRs数量得到的融合结果分析其对模型稳定性的影响。最后选取最佳解混策略后的模型与两个经典模型对比分析，测试该模型在LST数据融合效果。其文中各模型融合结果绝对误差分布图和各模型影像对比图均来源于20000914-20011120-20011222日期组。</p> <h2 id="u-stfm时空融合方法">U-STFM时空融合方法</h2> <p>本次实验选取解混方法中最具有代表性的U-STFM算法，将预测日期当天（tp）的MODIS LST数据以及前后两期（t0 、 te）的MODIS LST、Landsat7 LST数据作为该模型的输入，以预测目标日期Landsat7 LST数据。该模型基于线性光谱混合模型，忽略不同传感器数据之间的误差，其低空间分辨率像素等于HCRs光谱值与其覆盖率（fractional）的线性组合。解混过程计算如下： <img src="/SIAT-GeoScience/assets/2023-02-16公式 图二.png" alt="image.png" class="rounded"/></p> <h2 id="精度评价">精度评价</h2> <p>本文采用定性和定量评价指标来评价模型预测地表温度的效果。通过对比分析预测影像和真实影像可视化效果，实现对模型融合精度的定性评估。其中定量评价采用峰值信噪比PSNR（Peak Signal to Noise Ratio）、相关系数CC（Correlation Coefficient）、均方根误差RMSE（Root-Mean-Square Error）以及平均绝对误差MAE（Mean Absolute Error）。PSNR是一种全参考的影像质量评价指标，PSNR越高表示影像融合效果越好；CC、RMSE以及MAE表示预测影像和参考影像之间的相关性和差异性，CC值有效范围在区间[-1,1]之间，越接近1表示融合结果越好，而RMSE、MAE值越小代表融合影像质量越高。上述定量评价指标均通过调用scikit-learn模块对应的评价指标函数来实现。</p> <h1 id="试验结果">试验结果</h1> <h2 id="hcrs分类方式对模型稳定性影响">HCRs分类方式对模型稳定性影响</h2> <p>HCRs选取是解混模型第一步，其划分的准确性对模型融合效果至关重要。因此本文选取多尺度分割算法、K-means算法以及ISODATA算法来划分HCRs，其中多尺度分割算法是一种自下而上的区域合并技术，通过识别遥感影像的光谱、形状等特征差异，从空间上划分出不同的区域；k-mean是基于距离划分的聚类算法[29]，以数据对象之间距离作为相似度准则，通过迭代更新将数据划分为不同的簇；ISODATA是动态聚类分析算法，在K-means算法的基础上，增加“合并”和“分裂”操作，预先设定聚类中心和聚类数，通过定义相似度准则函数将全部样本调整完后再重新计算样本均值作为新的聚类中心[30]。</p> <p>图3所示分别为HCRs三种分类方法得出的融合结果的定量评价结果。可以看出，ISODATA算法相对于K-means算法和多尺度分割算法更能准确划分HCRs，更适合捕捉地物时间序列上的LST变化，其融合结果具有较高的PNSR以及较低的RMSE和MAE；三种分类算法融合结果CC均在85%以上，基于多尺度分割算法的预测影像与参考影像相关性最高，聚类算法对HCRs划分受数据源质量的影响较大。图4所示为基于三种HCRs分类算法的融合结果与参考影像进行差值处理并取绝对值，以更直观的方式来分析不同分类算法对模型精度的影像。从空间分布来看，基于三种HCRs分类算法的融合结果的绝对误差大部分分布在5K以内；其中基于ISODATA算法（图4（c））融合结果的绝对误差普遍小于2K，表现出较好的结果。 总体来看，对于时刻变化的地表温度数据，ISODATA算法更能有效的刻画出LST在时空变化中的HCRs，因此最终选取其作为HCRs的分类方式。 <img src="/SIAT-GeoScience/assets/2023-02-16图34png.png" alt="image.png" class="rounded"/></p> <h2 id="解混次数对模型稳定性影响">解混次数对模型稳定性影响</h2> <p>解混方程是解混类模型的核心组成部分，而HCRs、丰度以及MODIS像元组成的解混矩阵是一种病态矩阵，其解受异常值影响较大。因此本节将探讨解混次数的累加对模型稳定性的影响，采用ISODATA算法划分HCRs基础上将最小二乘算法求解线性光谱解混应用到影像跨尺度融合的不同位置，选取RMSE指标定量分析对融合结果精度的影响，结果如图5所示。图中解混1次是指直接对MODIS影像变化趋势比率进行解混，解混2次是指分别对俩组MODIS差分影像解混，解混3次是指分别对三期MODIS单期影像解混。从各评价指标箱线图可以明显看出解混3次时模型融合效果明显低于其他两种解混次数；基于解混1次和基于解混2次的模型融合效果相似，从箱线图中值来看，基于解混1次模型融合结果的CC和RMSE较高、MAE和PNSR较低，但整体上基于解混1次模型融合结果偏差较小，更稳定。这是因为随着解混方程次数的累加其解的奇异值也会随之增加，而解混2次前MODIS影像做了差分处理，削弱了奇异值的数量，因此会和解混1次时的效果相似。图6为基于上述三种解混策略得到的融合影像与参考影像的绝对误差分布图，可以看出解混1次和解混2次时模型预测误差大部分都在在5k以下，其中2k-5k解混2次时模型预测误差分布相对较多，而解混3次时模型预测误差大部分分布在5k-20k，模型误差较大。上述结果进一步揭示了解混算法使用次数越多，模型误差越大，也反映出基于最小二乘的解混算法的不稳定性。 <img src="/SIAT-GeoScience/assets/2023-02-16图56png.png" alt="image.png" class="rounded"/></p> <h2 id="hcrs类别个数对模型稳定性影响">HCRs类别个数对模型稳定性影响</h2> <p>理论上来讲HCRs划分越细就会获得越多的细节，但当HCRs数量大于MODIS像元数量时，会导致解混方程解不稳定，而HCRs数量也会影响方程组解的准确性，因此选取适当HCRs数量对模型的性能至关重要。本节在采用ISODATA算法划分HCRs和解混1次的基础上，探讨HCRs类别数对融合结果的影响。图7所示为169组模型在不同HCRs类别数上的预测影像评价指标中位数散点图，可以看出图中MAE与HCRs类别数量有很强的相关性，随着HCRs类别数量增加MAE呈现下降趋势；PSNR与RMSE在HCRs类别数为104以内时分别呈现上升、下降趋势，之后逐渐趋于稳定；CC值均在0.92以上，在 HCRs类别数为100以内时值相对较高，之后有下降趋势。图5为选取基于HCRs类别10、类别104和类别207时模型融合LST结果绝对误差的可视化结果，可以看出基于这三种类别的融合影像与参考影像的绝对误差普遍分布在5K以内，其中绝对误差在2K-5K分布最多的为基于HCRs10类模型，基于 HCRs104类模型以及HCRs207类模型总体分布较相似，前者较集中。总体上来看当HCRs类别数量在104时模型融合效果较好。 <img src="/SIAT-GeoScience/assets/2023-02-16图78png.png" alt="image.png" class="rounded"/></p> <h2 id="44-对比其他模型">4.4 对比其他模型</h2> <p>基于上述实验结果，先对Landsat7 LST数据采用ISODATA算法进行聚类，调参后得到HCRs104类分类图，之后直接对MODIS影像变化趋势比率进行解混，然后基于HCRs时间变化率一致性假设预测出未知高空间分辨率地表温度。为了将原模型HCRs划分方式区分开，我们将其记为iso_USTFM。图9是iso_USTFM（图9（c））与两个经典的融合模型STARFM、ESTARFM预测生成的LST分布图（图9（a）、图9（b））以及参考影像Landsat7 LST分布图（图9（d）），图中红色表示高温地物，由房屋、公路等非植被区域控制；绿色表示低温地物，由草地、森林等植被区域控制。从图中可以看出，由iso_USTFM预测生成的LST分布图与Landsat7的LST产品分布图最为接近，且展现更多的纹理信息，但在城镇区错误的预测出LST高温值，而ESTARFM却相反，将与植被区域接近的非植被区域错误的预测为低温值；STARFM预测的LST与Landsat7的LST产品误差最大，LST分布出现大量与现实不符的低温和高温极值。图10为三种模型预测生成的LST与Landsat7的LST产品的散点图，从数据分布来看，三组的数据点都接近对角线，其中（图10（a））有大量的异常值，而（图10（c））相关性最高。从评价指标来看iso_USTFM预测出的LST与Landsat7的LST产品决定系数为0.874，RMSE为1.0948K，均优于STARFM、ESTARFM预测生成的LST，融合效果较好。综上可以得出，iso_USTFM方法与STARFM方法、ESTARFM方法预测生成的地表温度相比，预测效果最好。 <img src="/SIAT-GeoScience/assets/2023-02-16图9,10png.png" alt="image.png" class="rounded"/></p> <h1 id="核心结论">核心结论</h1> <p>本文从HCRs分类方式、解混次数以及HCRs数量三方面来分析解混解混策略对模型稳定性影响，首先将USTFM方法应用到生成高时空分辨率LST中，并基于LST特性分析模型中解混策略，然后应用iso_USTFM方法融合Landsat7 LST产品和MODIS LST产品生成具有MODIS时间分辨率的30m空间分辨LST影像，最后与经典的时空融合模型STARFM以及ESTARFM对比预测出的LST影像效果，得出以下结论：</p> <p>（1）ISODATA聚类算法相对于多尺度分割算法与Kmeans算法更能有效的刻画出LST在时空变化中的HCRs。</p> <p>（2）解混算法使用次数越少，模型预测误差越小也越稳定。</p> <p>（3）随着HCRs类别数量增加模型预测效果越好，在类别104时趋于稳定。</p> <p>（4）对于地表温度的融合，iso_USTFM算法融合预测影像纹理清晰、精度高，比STARFM算法和ESTARFM算法更适合预测LST。</p> <p>此外，该解混类的融合方法受限于遥感影像自身分辨率的限制，当两个传感器影像空间分辨率差距很大的时候，无法详细预测出高分辨率影像像元中的空间细节。iso_USTFM中HCRs占比是通过其在MODIS像元中所占面积确定的，这种简单的线性解混可能不能有效的刻画出LST的变化，且其解混是基于最小二乘算法实现的，算法受异常值的影响较大，使模型出现解不准的情况。因此，接下来考虑结合非线性的解混策略和深度学习的方法优化模型，提升模型稳定性和鲁棒性。</p> <p>‍</p>]]></content><author><name></name></author><summary type="html"><![CDATA[地表温度（Land Surface Temperature，LST）在地球表面与大气能量交换过程中有着重要的作用。然而受传感器性能的制约，利用单一的星载热红外传感器无法反演出同时具有高时间和高空间分辨率的地表温度，从而限制地表温度数据的应用。时空融合模型是解决这一问题的有效途径。目前，基于解混的时空融合模型稳定性的影响因素存在不确定性。针对此问题本文从同质变化单元（homogeneous change regions，HCRs）分类方式、解混次数以及HCRs数量三方面来分析模型稳定性。因此，本文以MODIS LST和Landsat7 LST数据为研究对象，基于解混的时空反射融合模型（Unmixing-based Spatio-Temporal reflectance Fusion Model，U-STFM）来分析解混策略对模型稳定性影响，并对比STARFM与ESTARFM两种经典的时空融合模型。结果表明，在模型HCRs划分方式上，对比多尺度分割算法和Kmeans算法，ISODATA算法更能有效的刻画出LST在时空变化中的HCRs，其基于ISODATA算法时模型PNSR中值46.9K，CC为0.94，RMSE为1.8K，MAE中值为1.08K；在模型解混次数上，对比模型直接对MODIS影像变化趋势比率解混、分别对俩组MODIS差分影像解混以及分别对三期MODIS单期影像解混，解混一次时模型更稳定，基于解混1次时模型PNSR中值为42.00K，CC为0.94，RMSE为3.18K，MAE中值为2.18K；在模型HCRs类别数量上，从类别10到类别295，随着HCRs数量增加模型预测效果越好，在类别104时趋于稳定，其基于HCRs类别数104时模型PNSR中值43.11K，CC为0.93，RMSE为2.81K，MAE中值为2.17K；最后通过对比经典模型，验证了基于上述解混策略时模型在融合生成高时空分辨率LST影像效果的有效性。]]></summary></entry><entry><title type="html">使用级联多级检测器的多分辨率遥感图像的高质量目标检测</title><link href="https://shawnmiloguo.github.io/blog/2022/HQODMRSI-CMD/" rel="alternate" type="text/html" title="使用级联多级检测器的多分辨率遥感图像的高质量目标检测"/><published>2022-04-27T00:00:00+00:00</published><updated>2022-04-27T00:00:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2022/HQODMRSI-CMD</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2022/HQODMRSI-CMD/"><![CDATA[<p>基于深度学习的物体检测器在精度和自动化程度方面大大改善了遥感图像中最先进的物体检测。然而，物体尺度的巨大变化使得在多分辨率的遥感图像中很难实现高质量的检测，而质量是由训练中使用的交叉联合（IoU）阈值定义的。此外，跨多分辨率图像的正负样本之间的不平衡也使检测精度恶化。最近，人们发现，基于级联的区域卷积神经网络（R-CNN）通过引入级联的三级结构，使用逐步提高的IoU阈值，有可能实现更高的检测质量。然而，当加入第四级时，级联R-CNN的性能下降了。我们调查了原因，发现ROI特征和分类器之间的不匹配可能是造成性能下降的原因。在此，我们提出了一个级联R-CNN++结构来解决这个问题，并将三段式结构扩展到多段式结构，供一般使用。具体来说，对于级联分类，我们提出了一种新的分类器和兴趣区域（RoI）特征的集合策略，以提高推理时的分类精度。在定位方面，我们修改了边界盒回归器的损失函数，以获得零附近更高的灵敏度。在DOTA数据集上的实验表明，Cascade R-CNN++在精度和检测质量方面优于Cascade R-CNN。我们对多分辨率遥感图像进行了进一步分析，以验证模型在不同物体尺度上的可迁移性。</p> <h1 id="原文链接">原文链接</h1> <p><a href="https://www.mdpi.com/2072-4292/14/9/2091">https://www.mdpi.com/2072-4292/14/9/2091</a></p> <h1 id="背景及科学问题">背景及科学问题</h1> <p>遥感图像中的物体检测在一些民用和军事应用中发挥着重要作用，如城市规划、地理信息系统更新和搜救行动。与传统方法（基于模板匹配的方法[1,2]、基于知识的方法[3,4]等）相比，基于深度学习的方法通过将人工特征设计的负担迁移到底层学习系统，从原始数据中自动提取特征，使其具有更强大的特征表示能力，以提取更高语义水平的特征图。凭借这一优势，基于深度学习的检测方法在计算机视觉和遥感界都取得了巨大成功[5,6]。</p> <p>与自然场景图像不同，遥感图像在不同的观测条件下具有更大的尺度变化和更多的特征复杂性，这就要求物体检测器具有更高的泛化能力。最近，基于DNN的检测方法从计算机视觉领域被引入到遥感领域，并在多类物体检测上取得了优异的成绩。遥感图像深度学习物体检测的许多基本问题得到了解决，如缺乏足够的训练样本[7,8]，小物体检测的性能差[9,10,11]，以及卫星图像中物体的旋转特性[12,13]。撰写于2020年的全面回顾可以在文章[5]中找到。</p> <p>尽管如此，多分辨率遥感图像中物体尺度的巨大变化仍然给物体检测器带来巨大挑战。最近，一些研究从不同方面探讨了解决这一问题的可能性，可以归纳为三类。(1) 不同层次的特征融合：在这一类别中，许多融合模型都是为了提取多尺度的特征层次，以提高模型在小物体和大物体上的性能。有代表性的研究包括跨尺度特征融合（CSFF）[14]、基于双特征金字塔网络（FPN）的偏振注意机制模块[15]、特征融合架构（FFA）[16]、多片特征金字塔网络[17]和Quad-FPN[18]。(2) 改进区域建议网络以生成更合适的锚点：这些模型解决了多尺度图像中锚点尺寸和物体尺寸的不匹配问题，如自适应长宽比锚点(SARA)[19]，多尺度空间注意区域建议网络[20]，以及尺寸折叠操作(SF)[21]。(3) 建立平行网络来检测不同尺度的物体：其中一个代表性的工作是多专家检测网络（MEDNet）[22]。</p> <p>上述方法主要集中在不同尺度的物体之间的特征提取和特征匹配。除此之外，正负样本的不平衡也是模型无法检测不同尺度物体的另一个原因[23]。与小物体相比，大物体更容易被识别为正样本，而且精度更高。当把由高分辨率图像预训练的模型应用于低分辨率图像时，大多数大物体会变成小物体，导致阳性样本太少，无法有效训练模型。</p> <p>在基于锚点的检测器中，通常使用一个交叉-联合（IoU）阈值来区分阳性/阴性样本，这也定义了检测质量[24]。选择一个合适的阈值是检测质量和精度之间的妥协，因为较低的IoU阈值会带来更多潜在的物体区域建议，但会有更多的噪声样本，这导致了不可靠的检测结果。然而，在训练中使用高的IoU阈值会导致阳性样本太少，从而导致模型过拟合。</p> <p>为了达到高精度，IoU阈值必须与检测器假说的质量密切相关[25]。级联R-CNN[25]，作为两阶段基于锚的检测器的扩展，使用三阶段的级联结构来解决上述问题，训练样本的IoU（即假设的质量）可以通过级联的边界盒回归来逐步提高。这种级联结构依次提高阳性训练样本的数量和质量，以减少过拟合问题。在自然场景图像的实验中，级联结构在检测不同尺度的物体时取得了更好的精度。然而，在级联R-CNN的原始结构中，级联组件的最大数量为3个。当增加第四级时，整体检测性能就会下降[25]。这就限制了级联检测器的扩展，以实现更好的检测性能。</p> <p>在本文中，我们研究了增加更多级联阶段时性能下降的原因。我们发现，在推理时，级联R-CNN中的原始集合策略在分类器和兴趣区域（RoI）向量之间引入了不匹配，降低了分类精度。</p> <p>为了克服这一局限性，我们提出了一种新的级联分类的集合策略，即采取同一阶段产生的RoI特征进行分类，而不是统一使用最后阶段的特征。最终的分类结果是通过整合所有阶段的分类器输出得到的。此外，边界盒回归[26]的损失函数被修改以提高灵敏度，使级联回归器随着阶段数的增加而进一步收敛。修改后的级联结构在本文中被表示为级联R-CNN++。</p> <p>本研究的主要贡献有以下几点。(1）我们研究了级联检测器在增加更多阶段时性能下降的原因；（2）我们提出了一种新的集合策略，以尽量减少推理时分类器和输入RoI之间的不匹配，并提高分类精度；（3）我们提出了一个修改的边界盒回归的损失函数，使边界盒回归在建立更多阶段时进一步收敛。所提出的Cascade R-CNN++方法可以在遥感数据集DOTA上实现最先进的检测性能[27,28]。它可以在大多数需要基于区域建议的方法的情况下实施。在多分辨率遥感图像的实验中，所提出的方法在检测质量和精度上都优于级联R-CNN。</p> <h1 id="研究方法介绍级联r-cnn">研究方法介绍：级联R-CNN++</h1> <p>级联R-CNN[25]使用三级级联检测器来逐步改善训练样本的IoU分布。通过级联回归，可以实现更高的物体定位精度。然而，当增加第四级时，AP、AP50、AP60、AP70和AP80的指标都会下降，只有AP90略有增加。在此，我们研究了性能下降的原因。</p> <p>在本文中，我们通过修改Cascade R-CNN来提出Cascade R-CNN++方法。首先，我们为分类器和推理时的RoI特征提出了一个新的集合策略。其次，我们提出了一个改进的损失函数，用于边界箱回归，以实现零附近的高灵敏度，这使得更多阶段的加入能够进一步收敛。图3显示了所提出的级联R-CNN++的一个五阶段的例子。区域建议的生成采用了RPN。</p> <h2 id="新的分类组合策略">新的分类组合策略</h2> <p>正如在[25]中所定义的，一个分类器被表示为一个函数h(xi)它将一个特征向量xi归入m+1个类中的一个，其中0为背景，其余每个值代表一个类。一个分类器的输出是一个m+1维向量，其最大值表示边界框中的物体所属的类别。分类器是通过最小化交叉熵损失Rcls来训练的。</p> <h2 id="边界盒回归的修正损失函数">边界盒回归的修正损失函数</h2> <p>在每个阶段，边界盒回归器被用来通过最小化真实边界盒和候选边界盒之间的偏移量来逐渐使候选提案接近真实标签位置。一个输入建议p可以通过以下方式转化为预测的真实标签框g。推导公式表示如下： <img src="/SIAT-GeoScience/assets/2022-04-27 公式.png" alt="image.png" class="rounded"/> 其中p=(px,py,pw,ph)表示输入建议的位置，g=(gx,gy,gw,gh)是预测的真实标签箱。Δ=(tx/cx,ty/cy,tw/cw,th/ch)代表距离向量，即由边界盒回归器进行的微小调整。是影响距离向量大小的权重，权重cx、cy、cw、ch最初设定为（10，10，5，5），并随着阶段的增加而逐渐增加。由于边界盒回归器对偏移向量Δ进行了微调，这些值通常是非常小的。因此，归一化被执行为Δ[25,35,36,41].对于一个图像补丁xj，级联R-CNN[25]中使用的边界盒回归的损失函数可以表示为Rloc，其中Rloc是边界盒回归的交叉熵损失，j是一个候选方案的索引，Nloc是候选提案的数量，Lloc表示S1平滑L1函数[24]。</p> <p>其中f(xj,pj)是边界盒回归函数，pj=(pjx,pjy,pjw,pjh)是第j个是第j个候选方案，有四个坐标，即中心位置（pjx,pjy)，以及盒子的宽度和高度（pjw,pjy）.gj代表预测的真实标签框，以同样的方式指定（gj=(gjx,gjy,gjw,gjh)). 此后，除非需要，我们忽略上标j为简单起见。</p> <p>为了使更多阶段的级联回归能够进一步收敛，我们改进了边界盒回归的损失函数，以实现零附近的高灵敏度。</p> <p>其中sgn是符号函数，指数4/3的条款（tk/ck）4/3，和k∈{x,y,w,h}。是为了增加非线性并保持灵敏度和损失梯度之间的权衡。输入(tx,ty,tw,th)与边界箱输出偏移量（gx-px,gy-py,gw/pw,gh/ph）绘制成图。对于不同权重的原始和修改后的损失函数ci，i∈{x,y,w,h}。不同阶段（图4和图5）。修改后的损失函数在零点附近的曲线更平滑，表明当候选边界盒和真实标签之间的偏移接近零时，回归器的步长更小（即灵敏度更高）。这一修改使得级联边界盒回归器随着阶段的增加而进一步收敛。 <img src="/SIAT-GeoScience/assets/2022-04-27 图4-图5.png" alt="image.png" class="rounded"/> <img src="/SIAT-GeoScience/assets/2022-04-27 图6.png" alt="image.png" class="rounded"/> 图6说明了在损失函数中采取不同指数值的效果。我们可以看到，较大的指数值对应于损失函数在零附近的较高灵敏度，但收敛速度较慢。指数项为4/3是灵敏度和收敛速度之间的权衡。该值是经过多次实验后选择的经验值。</p> <h1 id="试验结果">试验结果</h1> <p><img src="/SIAT-GeoScience/assets/2022-04-27 表2-表5.png" alt="image.png" class="rounded"/></p> <h2 id="阶段性的比较">阶段性的比较</h2> <p>在DOTA数据集上，我们比较了三级、四级和五级级联R-CNN++的检测性能，它们都以ResNet-50为骨干。结果见表2，其中AP表示平均精度，AP50、AP75和AP90分别表示使用0.5、0.75和0.9的IoU阈值的检测精度。APS、APM和APL分别表示小型、中型和大型物体的检测精度。</p> <p>如表2所示，整体检测精度随着阶段的增加而提高，以FPS（每秒帧数）衡量的推理速度没有明显下降。</p> <h2 id="建议修改的消融实验">建议修改的消融实验</h2> <p>通过使用ResNet-50骨干网进行消融实验，进一步分析了Cascade R-CNN++的检测性能。结果显示在表3中。采用新的集合策略和修改后的边界盒回归损失函数的级联检测器取得了最好的精度，在AP90中也有明显的改善。</p> <h2 id="与最先进的检测器的比较">与最先进的检测器的比较</h2> <p>在DOTA-v1.5数据集上，提议的Cascade R-CNN++的性能与最先进的两级/多级检测器进行了比较，详见表4。用*表示的条目使用了包括多尺度训练/推理和SoftNMS在内的增强措施，如[43,45]。</p> <p>如表4所示，与Faster R-CNN、FPN、RetinaNet和原始Cascade R-CNN相比，提议的Cascade R-CN++在所有指标上都取得了更高的精度。在AP90上的改进最为明显，其次是对中型和小型物体的检测精度（即APM和APS）。这些结果证明，所提出的方法是有效的，并且优于最先进的检测器，特别是在高质量检测方面。在实验中，我们还实现了具有多尺度训练/推理和softNMS的Cascade R-CNN++，在表4中用Cascade R-CNN++ *表示。通过这些改进，Cascade R-CNN++超过了Cascade R-CNN 4.6分。值得注意的是，最近的其他研究从不同的角度（如特征金字塔）探讨了改进措施，表明这些改进措施的累积效应可以进一步提高多阶段检测器在遥感物体检测、实例分割、关键点检测等领域的性能。</p> <p>在另一个遥感数据集NWPU VHR-10上也进行了比较（表5）。训练以0.01的学习率开始，在30 k和40 k的迭代中分别降低到0.001和0.0001，并在50 k的迭代中完成。其他实施设置与DOTA-v1.5上的实验相同。</p> <p>从表5中我们可以看出，所提出的Cascade R-CNN++在NWPU VHR-10数据集上产生了最好的性能，特别是在AP75和AP90所显示的高质量检测上。小物体的检测精度比原来的Cascade R-CNN方法提高了4.8%。</p> <h2 id="模型在多分辨率遥感图像上的可迁移性">模型在多分辨率遥感图像上的可迁移性</h2> <p>进一步的分析是为了比较所提出的模型和原来的Cascade R-CNN在多分辨率遥感图像中的可迁移性。遥感数据集DOTA-v1.5中的图像按不同的系数（如2、3和4）进行了放大。由原始分辨率图像训练的探测模型直接用于推理，以模拟用有限的数据变异性训练的探测器被用于探测不同分辨率图像中的物体的大多数情况。如前所述，DOTA-v1.5数据集包含16类物体，如飞机、船舶、储罐、大型车辆、小型车辆等。这里我们以飞机和港口的检测为例。图7（单物体）和图8（多物体）显示了在多分辨率图像上实现的物体检测性能。 <img src="/SIAT-GeoScience/assets/2022-04-27 图7" alt="image.png" class="rounded"/> <img src="/SIAT-GeoScience/assets/2022-04-27 图8" alt="image.png" class="rounded"/> 从图7可以看出，在单物体和大物体检测中，Cascade R-CNN++获得的IoUs略好于Cascade R-CNN。在多物体检测中（图8），Cascade R-CNN的性能随着升级因子的增加而迅速下降，而Cascade R-CNN++在不同分辨率的图像中表现出更好的迁移能力。特别是对于小物体的检测，如图8c,g中的白色椭圆所示，当图像被放大3倍时，Cascade R-CNN++可以检测到大部分的小物体，而Cascade R-CNN则漏掉了大部分的小物体。当图像被放大四倍时，如图8d,h，两个检测模型都漏检了一些小物体。在飞机的检测中（图8d），我们注意到Cascade R-CNN几乎漏掉了所有的小飞机，而Cascade R-CNN++仍然可以检测到几个小飞机。</p> <p>我们对DOTA-v1.5中所有测试图像上的16类物体进行了上述实验，使用了1、3/2、2、5/2、3、24/7和4的上标比例。图9显示了边界盒回归后获得的IU的博弈图。3/2的升尺度比率是指图像被升尺度2倍，降尺度3倍的情况。这与其他比率相同。 <img src="/SIAT-GeoScience/assets/2022-04-27 图9" alt="image.png" class="rounded"/> 从图9中我们可以看出，对于按不同比例放大的遥感图像，Cascade R-CNN++比Cascade R-CNN获得了更高的IoU。随着放大比例的增加，Cascade R-CNN++获得的IoU分布的改善变得更加明显。这些结果表明，在多分辨率遥感图像中，Cascade R-CNN++比Cascade R-CNN获得了更高的检测质量。</p> <h1 id="结论">结论</h1> <p>在本研究中，我们提出了Cascade R-CNN++作为一种改进的级联结构，以实现多分辨率遥感图像的高质量物体检测。新模型克服了原有级联R-CNN的扩展问题，在推理时采用了新的集合策略进行分类，从而消除了分类器和RoI特征之间的不匹配。此外，我们修改了边界盒回归的损失函数，以实现零附近更高的灵敏度，这使得随着级联阶段的增加，可以进一步收敛。使用DOTA-v1.5和NWPU VHR-10数据集验证了所提方法的有效性。级联R-CNN++可以随着阶段的增加而达到更高的精度，并且在高质量检测方面取得了明显的改善（例如AP90）。我们对检测质量进行了进一步分析，以验证模型在多分辨率遥感图像中的可迁移性。与Cascade R-CNN相比，所提出的Cascade R-CNN++在多分辨率图像中检测不同类别的物体时取得了更高的IoU值。随着图像分辨率的降低，这一趋势变得更加明显。</p> <p>由于遥感训练数据集的可变性有限，深度学习模型在多分辨率图像之间的可迁移性对于遥感物体检测至关重要。”训练一次，应用于多尺度 “是最终目标。本文提出的级联结构和损失函数可以帮助模型提高跨多分辨率图像的可迁移性。它们是独立的组成部分，可以进一步应用于另一个多阶段模型。在未来，我们将探索级联结构在其他任务中的应用，如实例分割和关键点检测。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[基于深度学习的物体检测器在精度和自动化程度方面大大改善了遥感图像中最先进的物体检测。然而，物体尺度的巨大变化使得在多分辨率的遥感图像中很难实现高质量的检测，而质量是由训练中使用的交叉联合（IoU）阈值定义的。此外，跨多分辨率图像的正负样本之间的不平衡也使检测精度恶化。最近，人们发现，基于级联的区域卷积神经网络（R-CNN）通过引入级联的三级结构，使用逐步提高的IoU阈值，有可能实现更高的检测质量。然而，当加入第四级时，级联R-CNN的性能下降了。我们调查了原因，发现ROI特征和分类器之间的不匹配可能是造成性能下降的原因。在此，我们提出了一个级联R-CNN++结构来解决这个问题，并将三段式结构扩展到多段式结构，供一般使用。具体来说，对于级联分类，我们提出了一种新的分类器和兴趣区域（RoI）特征的集合策略，以提高推理时的分类精度。在定位方面，我们修改了边界盒回归器的损失函数，以获得零附近更高的灵敏度。在DOTA数据集上的实验表明，Cascade R-CNN++在精度和检测质量方面优于Cascade R-CNN。我们对多分辨率遥感图像进行了进一步分析，以验证模型在不同物体尺度上的可迁移性。 原文链接 https://www.mdpi.com/2072-4292/14/9/2091 背景及科学问题 遥感图像中的物体检测在一些民用和军事应用中发挥着重要作用，如城市规划、地理信息系统更新和搜救行动。与传统方法（基于模板匹配的方法[1,2]、基于知识的方法[3,4]等）相比，基于深度学习的方法通过将人工特征设计的负担迁移到底层学习系统，从原始数据中自动提取特征，使其具有更强大的特征表示能力，以提取更高语义水平的特征图。凭借这一优势，基于深度学习的检测方法在计算机视觉和遥感界都取得了巨大成功[5,6]。 与自然场景图像不同，遥感图像在不同的观测条件下具有更大的尺度变化和更多的特征复杂性，这就要求物体检测器具有更高的泛化能力。最近，基于DNN的检测方法从计算机视觉领域被引入到遥感领域，并在多类物体检测上取得了优异的成绩。遥感图像深度学习物体检测的许多基本问题得到了解决，如缺乏足够的训练样本[7,8]，小物体检测的性能差[9,10,11]，以及卫星图像中物体的旋转特性[12,13]。撰写于2020年的全面回顾可以在文章[5]中找到。 尽管如此，多分辨率遥感图像中物体尺度的巨大变化仍然给物体检测器带来巨大挑战。最近，一些研究从不同方面探讨了解决这一问题的可能性，可以归纳为三类。(1) 不同层次的特征融合：在这一类别中，许多融合模型都是为了提取多尺度的特征层次，以提高模型在小物体和大物体上的性能。有代表性的研究包括跨尺度特征融合（CSFF）[14]、基于双特征金字塔网络（FPN）的偏振注意机制模块[15]、特征融合架构（FFA）[16]、多片特征金字塔网络[17]和Quad-FPN[18]。(2) 改进区域建议网络以生成更合适的锚点：这些模型解决了多尺度图像中锚点尺寸和物体尺寸的不匹配问题，如自适应长宽比锚点(SARA)[19]，多尺度空间注意区域建议网络[20]，以及尺寸折叠操作(SF)[21]。(3) 建立平行网络来检测不同尺度的物体：其中一个代表性的工作是多专家检测网络（MEDNet）[22]。 上述方法主要集中在不同尺度的物体之间的特征提取和特征匹配。除此之外，正负样本的不平衡也是模型无法检测不同尺度物体的另一个原因[23]。与小物体相比，大物体更容易被识别为正样本，而且精度更高。当把由高分辨率图像预训练的模型应用于低分辨率图像时，大多数大物体会变成小物体，导致阳性样本太少，无法有效训练模型。 在基于锚点的检测器中，通常使用一个交叉-联合（IoU）阈值来区分阳性/阴性样本，这也定义了检测质量[24]。选择一个合适的阈值是检测质量和精度之间的妥协，因为较低的IoU阈值会带来更多潜在的物体区域建议，但会有更多的噪声样本，这导致了不可靠的检测结果。然而，在训练中使用高的IoU阈值会导致阳性样本太少，从而导致模型过拟合。 为了达到高精度，IoU阈值必须与检测器假说的质量密切相关[25]。级联R-CNN[25]，作为两阶段基于锚的检测器的扩展，使用三阶段的级联结构来解决上述问题，训练样本的IoU（即假设的质量）可以通过级联的边界盒回归来逐步提高。这种级联结构依次提高阳性训练样本的数量和质量，以减少过拟合问题。在自然场景图像的实验中，级联结构在检测不同尺度的物体时取得了更好的精度。然而，在级联R-CNN的原始结构中，级联组件的最大数量为3个。当增加第四级时，整体检测性能就会下降[25]。这就限制了级联检测器的扩展，以实现更好的检测性能。 在本文中，我们研究了增加更多级联阶段时性能下降的原因。我们发现，在推理时，级联R-CNN中的原始集合策略在分类器和兴趣区域（RoI）向量之间引入了不匹配，降低了分类精度。 为了克服这一局限性，我们提出了一种新的级联分类的集合策略，即采取同一阶段产生的RoI特征进行分类，而不是统一使用最后阶段的特征。最终的分类结果是通过整合所有阶段的分类器输出得到的。此外，边界盒回归[26]的损失函数被修改以提高灵敏度，使级联回归器随着阶段数的增加而进一步收敛。修改后的级联结构在本文中被表示为级联R-CNN++。 本研究的主要贡献有以下几点。(1）我们研究了级联检测器在增加更多阶段时性能下降的原因；（2）我们提出了一种新的集合策略，以尽量减少推理时分类器和输入RoI之间的不匹配，并提高分类精度；（3）我们提出了一个修改的边界盒回归的损失函数，使边界盒回归在建立更多阶段时进一步收敛。所提出的Cascade R-CNN++方法可以在遥感数据集DOTA上实现最先进的检测性能[27,28]。它可以在大多数需要基于区域建议的方法的情况下实施。在多分辨率遥感图像的实验中，所提出的方法在检测质量和精度上都优于级联R-CNN。 研究方法介绍：级联R-CNN++ 级联R-CNN[25]使用三级级联检测器来逐步改善训练样本的IoU分布。通过级联回归，可以实现更高的物体定位精度。然而，当增加第四级时，AP、AP50、AP60、AP70和AP80的指标都会下降，只有AP90略有增加。在此，我们研究了性能下降的原因。 在本文中，我们通过修改Cascade R-CNN来提出Cascade R-CNN++方法。首先，我们为分类器和推理时的RoI特征提出了一个新的集合策略。其次，我们提出了一个改进的损失函数，用于边界箱回归，以实现零附近的高灵敏度，这使得更多阶段的加入能够进一步收敛。图3显示了所提出的级联R-CNN++的一个五阶段的例子。区域建议的生成采用了RPN。 新的分类组合策略 正如在[25]中所定义的，一个分类器被表示为一个函数h(xi)它将一个特征向量xi归入m+1个类中的一个，其中0为背景，其余每个值代表一个类。一个分类器的输出是一个m+1维向量，其最大值表示边界框中的物体所属的类别。分类器是通过最小化交叉熵损失Rcls来训练的。 边界盒回归的修正损失函数 在每个阶段，边界盒回归器被用来通过最小化真实边界盒和候选边界盒之间的偏移量来逐渐使候选提案接近真实标签位置。一个输入建议p可以通过以下方式转化为预测的真实标签框g。推导公式表示如下： 其中p=(px,py,pw,ph)表示输入建议的位置，g=(gx,gy,gw,gh)是预测的真实标签箱。Δ=(tx/cx,ty/cy,tw/cw,th/ch)代表距离向量，即由边界盒回归器进行的微小调整。是影响距离向量大小的权重，权重cx、cy、cw、ch最初设定为（10，10，5，5），并随着阶段的增加而逐渐增加。由于边界盒回归器对偏移向量Δ进行了微调，这些值通常是非常小的。因此，归一化被执行为Δ[25,35,36,41].对于一个图像补丁xj，级联R-CNN[25]中使用的边界盒回归的损失函数可以表示为Rloc，其中Rloc是边界盒回归的交叉熵损失，j是一个候选方案的索引，Nloc是候选提案的数量，Lloc表示S1平滑L1函数[24]。 其中f(xj,pj)是边界盒回归函数，pj=(pjx,pjy,pjw,pjh)是第j个是第j个候选方案，有四个坐标，即中心位置（pjx,pjy)，以及盒子的宽度和高度（pjw,pjy）.gj代表预测的真实标签框，以同样的方式指定（gj=(gjx,gjy,gjw,gjh)). 此后，除非需要，我们忽略上标j为简单起见。 为了使更多阶段的级联回归能够进一步收敛，我们改进了边界盒回归的损失函数，以实现零附近的高灵敏度。 其中sgn是符号函数，指数4/3的条款（tk/ck）4/3，和k∈{x,y,w,h}。是为了增加非线性并保持灵敏度和损失梯度之间的权衡。输入(tx,ty,tw,th)与边界箱输出偏移量（gx-px,gy-py,gw/pw,gh/ph）绘制成图。对于不同权重的原始和修改后的损失函数ci，i∈{x,y,w,h}。不同阶段（图4和图5）。修改后的损失函数在零点附近的曲线更平滑，表明当候选边界盒和真实标签之间的偏移接近零时，回归器的步长更小（即灵敏度更高）。这一修改使得级联边界盒回归器随着阶段的增加而进一步收敛。 图6说明了在损失函数中采取不同指数值的效果。我们可以看到，较大的指数值对应于损失函数在零附近的较高灵敏度，但收敛速度较慢。指数项为4/3是灵敏度和收敛速度之间的权衡。该值是经过多次实验后选择的经验值。 试验结果 阶段性的比较 在DOTA数据集上，我们比较了三级、四级和五级级联R-CNN++的检测性能，它们都以ResNet-50为骨干。结果见表2，其中AP表示平均精度，AP50、AP75和AP90分别表示使用0.5、0.75和0.9的IoU阈值的检测精度。APS、APM和APL分别表示小型、中型和大型物体的检测精度。 如表2所示，整体检测精度随着阶段的增加而提高，以FPS（每秒帧数）衡量的推理速度没有明显下降。 建议修改的消融实验 通过使用ResNet-50骨干网进行消融实验，进一步分析了Cascade R-CNN++的检测性能。结果显示在表3中。采用新的集合策略和修改后的边界盒回归损失函数的级联检测器取得了最好的精度，在AP90中也有明显的改善。 与最先进的检测器的比较 在DOTA-v1.5数据集上，提议的Cascade R-CNN++的性能与最先进的两级/多级检测器进行了比较，详见表4。用*表示的条目使用了包括多尺度训练/推理和SoftNMS在内的增强措施，如[43,45]。 如表4所示，与Faster R-CNN、FPN、RetinaNet和原始Cascade R-CNN相比，提议的Cascade R-CN++在所有指标上都取得了更高的精度。在AP90上的改进最为明显，其次是对中型和小型物体的检测精度（即APM和APS）。这些结果证明，所提出的方法是有效的，并且优于最先进的检测器，特别是在高质量检测方面。在实验中，我们还实现了具有多尺度训练/推理和softNMS的Cascade R-CNN++，在表4中用Cascade R-CNN++ *表示。通过这些改进，Cascade R-CNN++超过了Cascade R-CNN 4.6分。值得注意的是，最近的其他研究从不同的角度（如特征金字塔）探讨了改进措施，表明这些改进措施的累积效应可以进一步提高多阶段检测器在遥感物体检测、实例分割、关键点检测等领域的性能。 在另一个遥感数据集NWPU VHR-10上也进行了比较（表5）。训练以0.01的学习率开始，在30 k和40 k的迭代中分别降低到0.001和0.0001，并在50 k的迭代中完成。其他实施设置与DOTA-v1.5上的实验相同。 从表5中我们可以看出，所提出的Cascade R-CNN++在NWPU VHR-10数据集上产生了最好的性能，特别是在AP75和AP90所显示的高质量检测上。小物体的检测精度比原来的Cascade R-CNN方法提高了4.8%。 模型在多分辨率遥感图像上的可迁移性 进一步的分析是为了比较所提出的模型和原来的Cascade R-CNN在多分辨率遥感图像中的可迁移性。遥感数据集DOTA-v1.5中的图像按不同的系数（如2、3和4）进行了放大。由原始分辨率图像训练的探测模型直接用于推理，以模拟用有限的数据变异性训练的探测器被用于探测不同分辨率图像中的物体的大多数情况。如前所述，DOTA-v1.5数据集包含16类物体，如飞机、船舶、储罐、大型车辆、小型车辆等。这里我们以飞机和港口的检测为例。图7（单物体）和图8（多物体）显示了在多分辨率图像上实现的物体检测性能。 从图7可以看出，在单物体和大物体检测中，Cascade R-CNN++获得的IoUs略好于Cascade R-CNN。在多物体检测中（图8），Cascade R-CNN的性能随着升级因子的增加而迅速下降，而Cascade R-CNN++在不同分辨率的图像中表现出更好的迁移能力。特别是对于小物体的检测，如图8c,g中的白色椭圆所示，当图像被放大3倍时，Cascade R-CNN++可以检测到大部分的小物体，而Cascade R-CNN则漏掉了大部分的小物体。当图像被放大四倍时，如图8d,h，两个检测模型都漏检了一些小物体。在飞机的检测中（图8d），我们注意到Cascade R-CNN几乎漏掉了所有的小飞机，而Cascade R-CNN++仍然可以检测到几个小飞机。 我们对DOTA-v1.5中所有测试图像上的16类物体进行了上述实验，使用了1、3/2、2、5/2、3、24/7和4的上标比例。图9显示了边界盒回归后获得的IU的博弈图。3/2的升尺度比率是指图像被升尺度2倍，降尺度3倍的情况。这与其他比率相同。 从图9中我们可以看出，对于按不同比例放大的遥感图像，Cascade R-CNN++比Cascade R-CNN获得了更高的IoU。随着放大比例的增加，Cascade R-CNN++获得的IoU分布的改善变得更加明显。这些结果表明，在多分辨率遥感图像中，Cascade R-CNN++比Cascade R-CNN获得了更高的检测质量。 结论 在本研究中，我们提出了Cascade R-CNN++作为一种改进的级联结构，以实现多分辨率遥感图像的高质量物体检测。新模型克服了原有级联R-CNN的扩展问题，在推理时采用了新的集合策略进行分类，从而消除了分类器和RoI特征之间的不匹配。此外，我们修改了边界盒回归的损失函数，以实现零附近更高的灵敏度，这使得随着级联阶段的增加，可以进一步收敛。使用DOTA-v1.5和NWPU VHR-10数据集验证了所提方法的有效性。级联R-CNN++可以随着阶段的增加而达到更高的精度，并且在高质量检测方面取得了明显的改善（例如AP90）。我们对检测质量进行了进一步分析，以验证模型在多分辨率遥感图像中的可迁移性。与Cascade R-CNN相比，所提出的Cascade R-CNN++在多分辨率图像中检测不同类别的物体时取得了更高的IoU值。随着图像分辨率的降低，这一趋势变得更加明显。 由于遥感训练数据集的可变性有限，深度学习模型在多分辨率图像之间的可迁移性对于遥感物体检测至关重要。”训练一次，应用于多尺度 “是最终目标。本文提出的级联结构和损失函数可以帮助模型提高跨多分辨率图像的可迁移性。它们是独立的组成部分，可以进一步应用于另一个多阶段模型。在未来，我们将探索级联结构在其他任务中的应用，如实例分割和关键点检测。]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://shawnmiloguo.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://shawnmiloguo.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[<h3>External Posts on Your al-folio Blog</h3> <p>If you prefer publishing blog posts on medium.com or other external sources, starting version v0.5.0, <a href="https://github.com/alshedivat/al-folio">al-folio</a> lets you to display your external posts in the blog feed of your website! 🎉🎉</p> <p>Configuring external sources of super simple. After upgrading to v0.5.0, just add the following section to your _config.yml:</p> <pre>external_sources:<br />  - name: medium.com  # name of the source (arbitrary string)<br />    rss_url: <a href="https://medium.com/@al-folio/feed">https://medium.com/@&lt;your-medium-username&gt;/feed</a></pre> <p>The example above adds your medium.com blog post feed as an external source. But you can add arbitrary RSS feeds as sources.</p> <p>Any questions or suggestions? 👉 Start <a href="https://github.com/alshedivat/al-folio/discussions">a discussion on GitHub</a>!</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b60a1d241a0a" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">快速评估监督学习中常用遥感分类算法的时间效率</title><link href="https://shawnmiloguo.github.io/blog/2022/FPTC/" rel="alternate" type="text/html" title="快速评估监督学习中常用遥感分类算法的时间效率"/><published>2022-03-11T00:00:00+00:00</published><updated>2022-03-11T00:00:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2022/FPTC</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2022/FPTC/"><![CDATA[<p>本文的提出了全参数时间复杂度(Full parameter time complexity，以下简称FPTC)，它考虑了所有可能耗时的参数。同时，我们定义了一个系数$\omega$来模拟不同分类器在不同平台之间的物理差异。<br/> 在下面的章节中，我们将根据FPTC在本文中的定义，具体推导以下几个算法的FPTC，其中包括：$k$NN ($k$-nearest neighbors) , LR (logistic regression) , CART (classification and regression tree) , RF (random forest)和 SVM (support vector machine) 。为了检验FPTC和相应的系数$\omega$的有效性，我们选择了新疆维吾尔自治区和Sentinel-2A数据集作为案例研究。<br/> 本文将首先阐述FPTC的定义，然后推导常用几个算法的FPTC，随后在具体的数据集中，验证我们提出的FPTC的有效性，同时进一步研究相关参数的影响。</p> <h1 id="原文链接">原文链接</h1> <p>Zheng, X., Jia, J., Guo, S., Chen, J., Sun, L., Xiong, Y., &amp; Xu, W. (2021). Full Parameter Time Complexity (FPTC): A Method to Evaluate the Running Time of Machine Learning Classifiers for Land Use/Land Cover Classification. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 14, 2222–2235. https://doi.org/10.1109/JSTARS.2021.3050166</p> <h1 id="算法时间估算的基本理论">算法时间估算的基本理论</h1> <p>对自然灾害和风险的评估是从公众到政府应急管理人员等各种行为者决策过程的基础。迅速量化损失和预期的未来损失通常是了解当前情况的第一步。遥感影像的土地利用/土地覆盖 (Land use/land cover, 以下简称LULC) 产品可以为这一目的提供第一手信息 。由于这一决策过程通常是紧迫的，在有限的时间和资源下选择合适的分类算法来实现这一目标可能是具有挑战性的引用。除了分类精度之外，算法的实际时间消耗是运行任务之前需要仔细评估的另一个方面 （Donoho2012,Huang2017,Khatami2016）。在没有准确预测时间消耗的情况下，在这些紧急情况下选择LULC分类算法可能是盲目的和主观的。</p> <p>通常，估计分类任务的时间消耗的方法可以分为两类：(1) 基于采样数据的方法和；(2) 基于时间复杂度的方法。第一类包括基于运行程序和启动对采样数据集的时间计算功能进行估计。这方法是假定样本和整个数据集之间的实际运行时间可以通过线性或非线性关系来简化。虽然这些方法被用于各种研究，但是它们的缺点是：(1) 这种线性或非线性关系高度依赖于硬件，不能在不同的计算环境中推广；(2) 算法的不同参数 (操作参数和隐藏参数) 的影响被视为一个黑匣子。同时，这些参数对运行时间的影响尚不清楚。第二类涉及基于时间复杂性分析的评估。常用的渐近时间复杂度就属于这一类，通常称为传统时间复杂度 (Traditional time complexity，以下简称TTC)。TTC是输入大小(例如，样本数量)的函数，它衡量在单位操作迭代(例如，加法或乘法)下，随着输入大小的增加，计算复杂度的变化。假定每个单元操作的时间具有相同的值，因此可以估计迭代次数与运行时间成比例。在计算TTC的过程中，忽略了许多低阶细节。例如，当我们计算函数 $f\left(n\right)=an^2+bn+c$ 的TTC时(<br/> 其中$n$ 代表了输入规模)，我们只关心$n$的最高次项，即 $f\left(n\right)=n^2$ 。$O(n^2)$ 表示了这个函数的时间复杂度的最上界。 TTC的目的是在理论级别捕获随着数据大小的增加而加速的运行时间 $({N})$。然而， 这很难用于运行时间的准确预测，特别是在遥感LULC分类任务中，时间消耗不仅与数据大小$({N})$有关，还与其他参数有关（例如，波段数或者SVM中支持向量的个数）。 如何考虑这些参数的影响来预测总体时间消耗仍然是一个挑战。</p> <p>事实上，在不考虑不同平台(如CPU和GPU)之间的物理差异的情况下，分类算法的时间消耗会受到：(1) 数据大小; (2) 类的数量；(3) 波段/特征的数量; (4) 算法的迭代结构; (5) 算法的操作参数(如随机森林中的树的数量)和 (6) 算法的隐藏参数(如支持向量的数量)的影响。所有这些组件都通过未知机制以不同的方式影响算法的实际时间消耗。确定如何量化每个部分的贡献是预测实际时间的关键。</p> <h1 id="基于fptc进行时间估算的基础理论与常见算法fptc的推导">基于FPTC进行时间估算的基础理论与常见算法FPTC的推导</h1> <p>FPTC 包含了两个部分：一部分为 $F(n,m,v,\boldsymbol{\theta}’)$，这个部分与算法息息相关，可以根据对特定分类器的结构分析得出。这个部分是关于 $n,m,v$ 和 $\boldsymbol{\theta}’$的函数。其中，$n$ 为样本量大小， $m$ 为类别数， $v$ 为波段数， $\boldsymbol{\theta}’$ 代表与算法相关的参数合集。值得注意的是不同算法的 $\boldsymbol{\theta}’$ 可能是不一样的。举个例子， $k$NN 的 $\boldsymbol{\theta}’$ 可能包含了最近邻数 $u$, 而SVM的$\boldsymbol{\theta}’$可能包含了迭代次数$Q$和支持向量个数$k$。第二个部分是参数$\omega $, 它是反映计算环境因素的物理相关部分对运行时间的影响, 例如CPU/GPU或者RAM的速度。因此，系数 $\omega $与运行平台息息相关。通常，在数据集的一小部分上进行预实验可以帮助我们评估特定分类器的这个系数。结合这两个部分，FPTC的定义如下：</p> \[t^*= F(n,m,v,\boldsymbol{\theta}')\] \[t'= \omega \times t^*\] <p>$t’\ $表示真实的运行时间， $\omega$ 表示系数， $\ t^*\ $是通过分析算法结构儿预估的时间。在下一节中，我们将推导出遥感领域中五种经典和常用的分类器的FPTC算法相关部分。我们按以下顺序推导出所选算法的FPTC： $k$NN，LR，CART，RF和 SVM。</p> <h1 id="knn的fptc推导">$k$NN的FPTC推导</h1> <p>$k$NN分类器是一个懒惰的学习器，这意味着建立模型的时间成本很低，但对测试样本进行分类的时间成本相对较高。为了计算测试样本的时间复杂度，我们将$k$NN分类器的FPTC分解为两部分来说明。首先，计算训练样本$\textbf{x}^{(e)}$ 和测试数据之间的距离的FPTC为$F(v)$。当训练集有$n$个样本时，FPTC为$F(vn)$。其次，算法需要从训练集中选择距离最小的$u$个训练样本。这是经典的最优搜索问题，最优FPTC为$F(nv+\ n{log}<em>2u)$。因此，$k$NN分类器的总FPTC为$F(nv+n{log}_2u)$。考虑到相应的系数${\omega}</em>{knn}$，$k$NN分类器的FPTC与实际运行时间$t’_{kNN}$关联如下：</p> \[t'_{kNN}=\omega_{kNN} \times t^*_{kNN} = \omega_{kNN} \times F(nv+nlog_2u)\] <p><img src="/SIAT-GeoScience/assets/image-20220321144323-mk87iku.png" alt="image.png" class="rounded"/></p> <p>KNN分类器的FPTC推导过程示意图。</p> <h1 id="lr的fptc推导">LR的FPTC推导</h1> <p>多分类LR分类器将其后验概率由Sigmoid变换替换为Softmax变换来执行多分类任务的。LR通常将L2范数作为正则化项加入到损失函数中，以提高LR分类器的稳定性和鲁棒性。根据我们的推导，具有L2范数和Softmax后验概率的LR的损失函数采用以下形式：</p> \[J(\boldsymbol{\theta}) = -\frac{1}{n} \cdot\sum_{i=1}^n\sum^m_{j=1}1\left\{y^{(i)}=j\right\}\cdot log\frac{exp(\boldsymbol{\theta}^T_j \textbf{x}^{(i)})}{\sum^m_{l=1}exp(\boldsymbol{\theta}^T_l\textbf{x}^{(i)})}+\frac{a}{2}\cdot\parallel\boldsymbol{\theta}\parallel^2_2\] <p>其中，$\boldsymbol{\theta }$是 $v\times m$ 的矩阵, $\boldsymbol{\theta }$ 中的元素是LR中的参数, ${\theta }_{pj}$ 是要素图层$p$中$j$类别的权重，$\alpha$的大小影响正则化强度。</p> <p>LR分类器的目标是最小化损失函数时得到$\boldsymbol{\theta}$的最优值。随机平均梯度(stochastic average gradient, SAG) 是优化LR分类器的常用策略。SAG算法是对随机梯度下降算法(stochastic gradient descent，SGD)的一种改进。根据我们的推导，具有L2范数和Softmax变换的LR分类器中的参数 \(\boldsymbol{\theta}_j^T = \left\{\theta_{1j},\theta_{2j},\theta_{3j},......,\theta_{vj}\right\}\) 是根据公式5-7进行更新。</p> \[\boldsymbol{\theta}^{r+1}_j= \boldsymbol{\theta}^{r}_{j} -\frac{\lambda}{n} \sum^n_{i=1}z^r_i\] \[\textbf{z}^r_i= \begin{cases} \nabla_{\boldsymbol{\theta_{j}}}J(\boldsymbol{\theta})&amp; if \ i=i_r\\ z_i^r &amp; otherwise \end{cases}\] \[\nabla_{\boldsymbol{\theta_{j}}} J(\boldsymbol{\theta})= \textbf{x}^{(i)}(1\left\{y^{(i)}=j\right\})- \frac{exp(\boldsymbol{\theta}^T_j \textbf{x}^{(i)})}{\sum^m_{l=1}exp(\boldsymbol{\theta}^T_l\textbf{x}^{(i)})} +\alpha\boldsymbol{\theta}_j\] <p>其中， $\lambda$ 是学习率，$i_r\ $ 是从${1,\ 2,\ 3,\dots ,\ n}$ 中随机选出的第 $r$次迭代.</p> <p>对于每次迭代，(公式5)-(公式7)便更新一次。因此，损失函数便根据(公式7)计算了一次。同时，具有$v$元素的$\boldsymbol{\theta_j}$便根据(公式6)更新了一次。基于上述分析，每次迭代的FPTC为$F(mvn)$。在多分类的LR中，假设对每个类别进行$q$次迭代后收敛（$q$为SAG过程中迭代次数），则总FPTC为$F(Qmvn)$。在这种情况下，$m$类别的FPTC为写为$F(Qm^2vn)$。最后，LR的FPTC与实际运行时间$t’_{LR}$关联如下，推导LR的FPTC的关键步骤如图所示：</p> \[t'_{LR}=\omega_{LR} \times t^*_{LR}=\omega_{LR}\times F(Qm^2vn)\] <p><img src="/SIAT-GeoScience/assets/image-20220321144853-se7lutf.png" alt="image.png" class="rounded"/></p> <p>LR多分类器的FPTC推导过程示意图。</p> <h1 id="fptc的验证与精度评价">FPTC的验证与精度评价</h1> <p>为了验证FPTC的准确性，我们采用了三种评估方法：1)、用1：1的曲线图将实际运行时间与FPTC进行比较；2)、利用FPTC估计运行时间，并计算估计运行时间与观测运行时间之间的均方根误差(Root Mean Squared Error, RMSE)；3)、比较FPTC和TTC在不同特征选择下的实际运行时间。</p> <p><img src="/SIAT-GeoScience/assets/image-20220321144946-ypvxaof.png" alt="image.png" class="rounded"/></p> <p>我们从训练数据集中随机选择子训练样本，并构造子训练样本集。对这些样本进行分类，并记录真实的运行时间。如图所示，FPTC与实际运行时间之间的线性关系表明了FPTC的有效性。5个分类器的R平方值均大于0.99($k$NN：0.991，LR：0.997，CART：0.999，RF：1.000，SVM：0.999)，表明FPTC的算法部分与实际运行时间之间存在极强的线性关系({p} $&lt;$ 0.001)。</p> <p>每一个算法的参数 $\omega$ 可以从各自相关性曲线的斜率中获得。</p> <p>无论训练数据的大小如何，都可以基于两个可用的数据集粗略地估计斜率。这意味着可以通过在总数据集的两个小部分下预先运行算法来获得此值。由于系数$\omega$表示FPTC的物理部分，因此仅当算法应用于不同的计算环境时，该值才会改变。</p> <p><img src="/SIAT-GeoScience/assets/image-20220321145116-updnpcw.png" alt="image.png" class="rounded"/></p> <p>TTC(左列)和FPTC(中列)与实际运行时间(右列)的比较。</p> <p>此外，FPTC还可以通过不同的参数反映运行时间的变化。当n个训练样本由低到高变化，且其他影响参数保持不变时，支持向量机的FPTC最容易受到这种变化的影响，其次是RF、CART、kNN和LR。如果n从1变为128，则LR的FPTC增加128倍，kNN增加128倍多，CART和RF增加896倍，SVM增加16,384倍以上。当分类数m由低变高且其他影响参数保持不变时，支持向量机和LR的FPTC最容易受到这种变化的影响，其次是CART和RF，而kNN则不受影响。例如，如果m从两个类变为200个类，则SVM和LR的FPTC增加10,000倍，CART和RF的FPTC增加100倍。当特征数或波段数v由低变高且其他影响参数不变时，SVM、LR、CART和RF的时间复杂度在多项式时间内变化，而kNN的时间复杂度受影响较小。<br/> 其次，为了进一步说明FPTC和TTC的差异，我们分析了在不同波段(v=3, 4, 5,…,10)和不同样本大小(n=10, 20, 30,…,100,000)的所有组合下，FPTC和TTC的变化趋势，并与实际运行时间趋势进行了比较。在图9中，TTC、FPTC和实际运行时间的值以红色到绿色从低到高映射。结果表明，TTC对v的变化没有反应，而FPTC能更好地反映v的变化。<br/> 正如我们所看到的，在不同的带宽和数据大小下，FPTC显示出与实际运行时间相似的模式。TTC的模式是不同的，因为TTC忽略了不同特征/波段的影响。</p> <h1 id="总结">总结</h1> <p>在自然灾害应急响应中，准确的时间预测有助于应急管理者在有限的时间和资源下选择分类算法。在本研究中，我们提出了FPTC和系数$\omega$来估计每个分类器的运行时间。通过研究分类器程序的总体结构及其数学原理，推导出五种常见分类器($k$NN、LR、CART、RF和SVM)的FPTC。根据实际运行时间与FPTC之间的关系，建立了线性回归模型，并由线性回归得到了系数$\omega $。然后，我们准确地预测了每个分类器的运行时间，并筛选出合适的分类器。研究结果可概括如下：</p> <ul> <li> <p>提出了一种定量评估机器学习分类器时间效率的方法–FPTC。我们推导了五种通用分类器的FPTC。结果表明$k$NN 的FPTC 是 $F(nv+\ n{log}_2u)$, LR的FPTC是 $F(Qm^2vn)$, CART的FPTC是 $F((m+1)nv{log}_2n)$), RF是FPTC是 $F(s(m+1)nv{log}_2n)$, SVM的FPTC是 $F(m^2Qv\ (n+k))$.</p> </li> <li> <p>在我们的研究中，FPTC与运行时间之间存在很强的线性关系 (${R}^2$ $\geq 0.991$, $\ p\le 0.001$)。 这种线性关系验证了FPTC推导过程的正确性。每种算法的修正系数都可以从强线性回归中得到。</p> </li> <li> <p>每个分类器的运行时间用FPTC中的系数$\omega$来估计。研究表明，实际运行时间与估计运行时间之间的平均均方根误差为3.34s，说明了用FPTC预测算法运行时间的可行性和准确性。</p> </li> <li> <p>研究表明，支持向量机的训练参数$Q$与样本数有显著的线性相关关系($R^2=1.00$), 而LR的$Q$是稳定的，不随$n$的变化而变化。根据上述规则，支持向量机的总FPTC被修正为$F(m^2vn^2)$，LR的总FPTC被修正为$F(m^2vn)$。更新的FPTC不受程序是否提前运行的影响。</p> </li> </ul> <p>未来的研究中，我们计划为算法推导出更多的FPTC值。对于紧急任务，可以快速筛选出精度高、FPTC低的合适算法，帮助应急管理人员根据可获得的遥感数据量，快速做出应对自然灾害的决策。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[本文的提出了全参数时间复杂度(Full parameter time complexity，以下简称FPTC)，它考虑了所有可能耗时的参数。同时，我们定义了一个系数$\omega$来模拟不同分类器在不同平台之间的物理差异。 在下面的章节中，我们将根据FPTC在本文中的定义，具体推导以下几个算法的FPTC，其中包括：$k$NN ($k$-nearest neighbors) , LR (logistic regression) , CART (classification and regression tree) , RF (random forest)和 SVM (support vector machine) 。为了检验FPTC和相应的系数$\omega$的有效性，我们选择了新疆维吾尔自治区和Sentinel-2A数据集作为案例研究。 本文将首先阐述FPTC的定义，然后推导常用几个算法的FPTC，随后在具体的数据集中，验证我们提出的FPTC的有效性，同时进一步研究相关参数的影响。 原文链接 Zheng, X., Jia, J., Guo, S., Chen, J., Sun, L., Xiong, Y., &amp; Xu, W. (2021). Full Parameter Time Complexity (FPTC): A Method to Evaluate the Running Time of Machine Learning Classifiers for Land Use/Land Cover Classification. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 14, 2222–2235. https://doi.org/10.1109/JSTARS.2021.3050166 算法时间估算的基本理论 对自然灾害和风险的评估是从公众到政府应急管理人员等各种行为者决策过程的基础。迅速量化损失和预期的未来损失通常是了解当前情况的第一步。遥感影像的土地利用/土地覆盖 (Land use/land cover, 以下简称LULC) 产品可以为这一目的提供第一手信息 。由于这一决策过程通常是紧迫的，在有限的时间和资源下选择合适的分类算法来实现这一目标可能是具有挑战性的引用。除了分类精度之外，算法的实际时间消耗是运行任务之前需要仔细评估的另一个方面 （Donoho2012,Huang2017,Khatami2016）。在没有准确预测时间消耗的情况下，在这些紧急情况下选择LULC分类算法可能是盲目的和主观的。 通常，估计分类任务的时间消耗的方法可以分为两类：(1) 基于采样数据的方法和；(2) 基于时间复杂度的方法。第一类包括基于运行程序和启动对采样数据集的时间计算功能进行估计。这方法是假定样本和整个数据集之间的实际运行时间可以通过线性或非线性关系来简化。虽然这些方法被用于各种研究，但是它们的缺点是：(1) 这种线性或非线性关系高度依赖于硬件，不能在不同的计算环境中推广；(2) 算法的不同参数 (操作参数和隐藏参数) 的影响被视为一个黑匣子。同时，这些参数对运行时间的影响尚不清楚。第二类涉及基于时间复杂性分析的评估。常用的渐近时间复杂度就属于这一类，通常称为传统时间复杂度 (Traditional time complexity，以下简称TTC)。TTC是输入大小(例如，样本数量)的函数，它衡量在单位操作迭代(例如，加法或乘法)下，随着输入大小的增加，计算复杂度的变化。假定每个单元操作的时间具有相同的值，因此可以估计迭代次数与运行时间成比例。在计算TTC的过程中，忽略了许多低阶细节。例如，当我们计算函数 $f\left(n\right)=an^2+bn+c$ 的TTC时( 其中$n$ 代表了输入规模)，我们只关心$n$的最高次项，即 $f\left(n\right)=n^2$ 。$O(n^2)$ 表示了这个函数的时间复杂度的最上界。 TTC的目的是在理论级别捕获随着数据大小的增加而加速的运行时间 $({N})$。然而， 这很难用于运行时间的准确预测，特别是在遥感LULC分类任务中，时间消耗不仅与数据大小$({N})$有关，还与其他参数有关（例如，波段数或者SVM中支持向量的个数）。 如何考虑这些参数的影响来预测总体时间消耗仍然是一个挑战。 事实上，在不考虑不同平台(如CPU和GPU)之间的物理差异的情况下，分类算法的时间消耗会受到：(1) 数据大小; (2) 类的数量；(3) 波段/特征的数量; (4) 算法的迭代结构; (5) 算法的操作参数(如随机森林中的树的数量)和 (6) 算法的隐藏参数(如支持向量的数量)的影响。所有这些组件都通过未知机制以不同的方式影响算法的实际时间消耗。确定如何量化每个部分的贡献是预测实际时间的关键。 基于FPTC进行时间估算的基础理论与常见算法FPTC的推导 FPTC 包含了两个部分：一部分为 $F(n,m,v,\boldsymbol{\theta}’)$，这个部分与算法息息相关，可以根据对特定分类器的结构分析得出。这个部分是关于 $n,m,v$ 和 $\boldsymbol{\theta}’$的函数。其中，$n$ 为样本量大小， $m$ 为类别数， $v$ 为波段数， $\boldsymbol{\theta}’$ 代表与算法相关的参数合集。值得注意的是不同算法的 $\boldsymbol{\theta}’$ 可能是不一样的。举个例子， $k$NN 的 $\boldsymbol{\theta}’$ 可能包含了最近邻数 $u$, 而SVM的$\boldsymbol{\theta}’$可能包含了迭代次数$Q$和支持向量个数$k$。第二个部分是参数$\omega $, 它是反映计算环境因素的物理相关部分对运行时间的影响, 例如CPU/GPU或者RAM的速度。因此，系数 $\omega $与运行平台息息相关。通常，在数据集的一小部分上进行预实验可以帮助我们评估特定分类器的这个系数。结合这两个部分，FPTC的定义如下： \[t^*= F(n,m,v,\boldsymbol{\theta}')\] \[t'= \omega \times t^*\] $t’\ $表示真实的运行时间， $\omega$ 表示系数， $\ t^*\ $是通过分析算法结构儿预估的时间。在下一节中，我们将推导出遥感领域中五种经典和常用的分类器的FPTC算法相关部分。我们按以下顺序推导出所选算法的FPTC： $k$NN，LR，CART，RF和 SVM。 $k$NN的FPTC推导 $k$NN分类器是一个懒惰的学习器，这意味着建立模型的时间成本很低，但对测试样本进行分类的时间成本相对较高。为了计算测试样本的时间复杂度，我们将$k$NN分类器的FPTC分解为两部分来说明。首先，计算训练样本$\textbf{x}^{(e)}$ 和测试数据之间的距离的FPTC为$F(v)$。当训练集有$n$个样本时，FPTC为$F(vn)$。其次，算法需要从训练集中选择距离最小的$u$个训练样本。这是经典的最优搜索问题，最优FPTC为$F(nv+\ n{log}2u)$。因此，$k$NN分类器的总FPTC为$F(nv+n{log}_2u)$。考虑到相应的系数${\omega}{knn}$，$k$NN分类器的FPTC与实际运行时间$t’_{kNN}$关联如下： \[t'_{kNN}=\omega_{kNN} \times t^*_{kNN} = \omega_{kNN} \times F(nv+nlog_2u)\] KNN分类器的FPTC推导过程示意图。 LR的FPTC推导 多分类LR分类器将其后验概率由Sigmoid变换替换为Softmax变换来执行多分类任务的。LR通常将L2范数作为正则化项加入到损失函数中，以提高LR分类器的稳定性和鲁棒性。根据我们的推导，具有L2范数和Softmax后验概率的LR的损失函数采用以下形式： \[J(\boldsymbol{\theta}) = -\frac{1}{n} \cdot\sum_{i=1}^n\sum^m_{j=1}1\left\{y^{(i)}=j\right\}\cdot log\frac{exp(\boldsymbol{\theta}^T_j \textbf{x}^{(i)})}{\sum^m_{l=1}exp(\boldsymbol{\theta}^T_l\textbf{x}^{(i)})}+\frac{a}{2}\cdot\parallel\boldsymbol{\theta}\parallel^2_2\] 其中，$\boldsymbol{\theta }$是 $v\times m$ 的矩阵, $\boldsymbol{\theta }$ 中的元素是LR中的参数, ${\theta }_{pj}$ 是要素图层$p$中$j$类别的权重，$\alpha$的大小影响正则化强度。 LR分类器的目标是最小化损失函数时得到$\boldsymbol{\theta}$的最优值。随机平均梯度(stochastic average gradient, SAG) 是优化LR分类器的常用策略。SAG算法是对随机梯度下降算法(stochastic gradient descent，SGD)的一种改进。根据我们的推导，具有L2范数和Softmax变换的LR分类器中的参数 \(\boldsymbol{\theta}_j^T = \left\{\theta_{1j},\theta_{2j},\theta_{3j},......,\theta_{vj}\right\}\) 是根据公式5-7进行更新。 \[\boldsymbol{\theta}^{r+1}_j= \boldsymbol{\theta}^{r}_{j} -\frac{\lambda}{n} \sum^n_{i=1}z^r_i\] \[\textbf{z}^r_i= \begin{cases} \nabla_{\boldsymbol{\theta_{j}}}J(\boldsymbol{\theta})&amp; if \ i=i_r\\ z_i^r &amp; otherwise \end{cases}\] \[\nabla_{\boldsymbol{\theta_{j}}} J(\boldsymbol{\theta})= \textbf{x}^{(i)}(1\left\{y^{(i)}=j\right\})- \frac{exp(\boldsymbol{\theta}^T_j \textbf{x}^{(i)})}{\sum^m_{l=1}exp(\boldsymbol{\theta}^T_l\textbf{x}^{(i)})} +\alpha\boldsymbol{\theta}_j\] 其中， $\lambda$ 是学习率，$i_r\ $ 是从${1,\ 2,\ 3,\dots ,\ n}$ 中随机选出的第 $r$次迭代. 对于每次迭代，(公式5)-(公式7)便更新一次。因此，损失函数便根据(公式7)计算了一次。同时，具有$v$元素的$\boldsymbol{\theta_j}$便根据(公式6)更新了一次。基于上述分析，每次迭代的FPTC为$F(mvn)$。在多分类的LR中，假设对每个类别进行$q$次迭代后收敛（$q$为SAG过程中迭代次数），则总FPTC为$F(Qmvn)$。在这种情况下，$m$类别的FPTC为写为$F(Qm^2vn)$。最后，LR的FPTC与实际运行时间$t’_{LR}$关联如下，推导LR的FPTC的关键步骤如图所示： \[t'_{LR}=\omega_{LR} \times t^*_{LR}=\omega_{LR}\times F(Qm^2vn)\] LR多分类器的FPTC推导过程示意图。 FPTC的验证与精度评价 为了验证FPTC的准确性，我们采用了三种评估方法：1)、用1：1的曲线图将实际运行时间与FPTC进行比较；2)、利用FPTC估计运行时间，并计算估计运行时间与观测运行时间之间的均方根误差(Root Mean Squared Error, RMSE)；3)、比较FPTC和TTC在不同特征选择下的实际运行时间。 我们从训练数据集中随机选择子训练样本，并构造子训练样本集。对这些样本进行分类，并记录真实的运行时间。如图所示，FPTC与实际运行时间之间的线性关系表明了FPTC的有效性。5个分类器的R平方值均大于0.99($k$NN：0.991，LR：0.997，CART：0.999，RF：1.000，SVM：0.999)，表明FPTC的算法部分与实际运行时间之间存在极强的线性关系({p} $&lt;$ 0.001)。 每一个算法的参数 $\omega$ 可以从各自相关性曲线的斜率中获得。 无论训练数据的大小如何，都可以基于两个可用的数据集粗略地估计斜率。这意味着可以通过在总数据集的两个小部分下预先运行算法来获得此值。由于系数$\omega$表示FPTC的物理部分，因此仅当算法应用于不同的计算环境时，该值才会改变。 TTC(左列)和FPTC(中列)与实际运行时间(右列)的比较。 此外，FPTC还可以通过不同的参数反映运行时间的变化。当n个训练样本由低到高变化，且其他影响参数保持不变时，支持向量机的FPTC最容易受到这种变化的影响，其次是RF、CART、kNN和LR。如果n从1变为128，则LR的FPTC增加128倍，kNN增加128倍多，CART和RF增加896倍，SVM增加16,384倍以上。当分类数m由低变高且其他影响参数保持不变时，支持向量机和LR的FPTC最容易受到这种变化的影响，其次是CART和RF，而kNN则不受影响。例如，如果m从两个类变为200个类，则SVM和LR的FPTC增加10,000倍，CART和RF的FPTC增加100倍。当特征数或波段数v由低变高且其他影响参数不变时，SVM、LR、CART和RF的时间复杂度在多项式时间内变化，而kNN的时间复杂度受影响较小。 其次，为了进一步说明FPTC和TTC的差异，我们分析了在不同波段(v=3, 4, 5,…,10)和不同样本大小(n=10, 20, 30,…,100,000)的所有组合下，FPTC和TTC的变化趋势，并与实际运行时间趋势进行了比较。在图9中，TTC、FPTC和实际运行时间的值以红色到绿色从低到高映射。结果表明，TTC对v的变化没有反应，而FPTC能更好地反映v的变化。 正如我们所看到的，在不同的带宽和数据大小下，FPTC显示出与实际运行时间相似的模式。TTC的模式是不同的，因为TTC忽略了不同特征/波段的影响。 总结 在自然灾害应急响应中，准确的时间预测有助于应急管理者在有限的时间和资源下选择分类算法。在本研究中，我们提出了FPTC和系数$\omega$来估计每个分类器的运行时间。通过研究分类器程序的总体结构及其数学原理，推导出五种常见分类器($k$NN、LR、CART、RF和SVM)的FPTC。根据实际运行时间与FPTC之间的关系，建立了线性回归模型，并由线性回归得到了系数$\omega $。然后，我们准确地预测了每个分类器的运行时间，并筛选出合适的分类器。研究结果可概括如下： 提出了一种定量评估机器学习分类器时间效率的方法–FPTC。我们推导了五种通用分类器的FPTC。结果表明$k$NN 的FPTC 是 $F(nv+\ n{log}_2u)$, LR的FPTC是 $F(Qm^2vn)$, CART的FPTC是 $F((m+1)nv{log}_2n)$), RF是FPTC是 $F(s(m+1)nv{log}_2n)$, SVM的FPTC是 $F(m^2Qv\ (n+k))$. 在我们的研究中，FPTC与运行时间之间存在很强的线性关系 (${R}^2$ $\geq 0.991$, $\ p\le 0.001$)。 这种线性关系验证了FPTC推导过程的正确性。每种算法的修正系数都可以从强线性回归中得到。 每个分类器的运行时间用FPTC中的系数$\omega$来估计。研究表明，实际运行时间与估计运行时间之间的平均均方根误差为3.34s，说明了用FPTC预测算法运行时间的可行性和准确性。 研究表明，支持向量机的训练参数$Q$与样本数有显著的线性相关关系($R^2=1.00$), 而LR的$Q$是稳定的，不随$n$的变化而变化。根据上述规则，支持向量机的总FPTC被修正为$F(m^2vn^2)$，LR的总FPTC被修正为$F(m^2vn)$。更新的FPTC不受程序是否提前运行的影响。 未来的研究中，我们计划为算法推导出更多的FPTC值。对于紧急任务，可以快速筛选出精度高、FPTC低的合适算法，帮助应急管理人员根据可获得的遥感数据量，快速做出应对自然灾害的决策。]]></summary></entry><entry><title type="html">基于光学微波特征融合的新疆典型经济作物提取</title><link href="https://shawnmiloguo.github.io/blog/2022/SAR-OPT/" rel="alternate" type="text/html" title="基于光学微波特征融合的新疆典型经济作物提取"/><published>2022-03-10T00:00:00+00:00</published><updated>2022-03-10T00:00:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2022/SAR-OPT</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2022/SAR-OPT/"><![CDATA[<p>针对异物同谱效应造成的作物提取精度不足问题，本研究提出了一种集成光学和微波特征的方法，通过特征融合提高作物提取精度。本研究基于Sentinel-1合成孔径雷达影像和Sentinel-2多光谱数据，对新疆巴州地区的典型绿洲农业区进行作物分类制图。为提高雷达数据提取特征的质量，采用SHP-DSI方法，对时间序列Sentinel-1数据的后向散射强度进行相干斑抑制，并对相干系数进行精确估计和去偏。此外，首次在研究中提取了合成孔径雷达干涉（InSAR）产品用于作物分类，包括干涉相干系数，主从影像后向散射强度比和从SAR时间序列的振幅色离散度指数等。为探索红边特征在绿洲作物类型识别中的作用，本研究提取了Sentinel-2的3个红边波段并导出了11个红边指数，结合常规的多光谱特征，与雷达特征进行集成，以提高作物分类的精度。 为了处理高维特征，获取SAR和光学特征的最优组合，本研究提出了一种半自动化的特征筛选流程，基于随机森林算法的特征重要性排序以及递归特征增量（Recursive Feature Increment，RFI）算法对所有特征进行筛选，以达到最高的作物分类精度。本研究发现Sentinel-2的红边特征将作物分类精度提高了3.06%。在对比实验中本研究证实了时间序列Sentinel-1和Sentienl-2的特征融合在作物分类中可实现最高精度。</p> <h1 id="原文链接">原文链接</h1> <p>Sun, L., Chen, J., Guo, S., Deng, X., &amp; Han, Y. (2020). Integration of Time Series Sentinel-1 and Sentinel-2 Imagery for Crop Type Mapping over Oasis Agricultural Areas. Remote Sensing, 12(158), 1–27.</p> <h1 id="研究背景">研究背景</h1> <p>新疆是我国西北干旱半干旱地带的主要农业区。由于气候干燥，新疆的农业生产几乎完全依靠灌溉，导致水资源匮乏问题更加严重。新疆地区是我国棉花的主要产区，种植面积大，棉花品质较好，是国内棉花供给的重要支柱。2017年，新疆棉花种植面积占全国比重超过60%；棉花产量占全国比重超过70%。此外，棉花种植和其他农作物相比，需要大量的水源进行浇灌，加快了土地荒漠化的速度。新疆一些地区历经数次农业结构调整，实行“退白扩红”战略，大量种植辣椒和番茄，因此种植结构更加复杂，需要更加及时和精确的农作物种类分布制图。农作物种类分布是进行水资源和环境承载力估计所需的重要信息。在我国西北干旱半干旱地区，农业是支柱产业而生态环境相对较为脆弱，因此更为重要。随着空间技术的发展，遥感技术以已被应用到大范围的农作物种植面积、长势监测中，具有宏观、准确、及时等优点，监测结果可为国家农业生产管理、粮食政策制定提供重要参考依据。</p> <p>近年来，遥感技术被广泛应用于农作物种植面积监测及作物分类中。原来主要使用的是光学遥感影像，利用不同种类作物之间的物候期差异，通过植被指数的时间变化来进行某种作物的提取。有些研究采用MODIS植被指数时间序列进行作物分类，但是由于分辨率太低，不适用于地块尺寸小、异构性强的小农种植系统 。对于地块破碎、异构性强的种植区，中、高分辨率影像（30米以内）是更为合适的选择。此前也有不少研究采用Landsat NDVI时间序列进行作物提取、分类，但是由于Landsat重访周期较长，在作物生长关键期受频繁的云雨天气影响无法获取完整、连续的光学数据，严重影响监测的有效性 。Sentinel-2卫星的发射为遥感监测提供了较高时空分辨率的光学数据，重访周期为10天，分辨率达到10米，在小农种植系统的农作物种植面积、长势监测、作物分类等应用中具有较大的潜力 。但是，由于光学数据本身的特点，受云的影响，Sentinel-2在作物关键生长期的数据连续性仍然不能保证 。此外，对于具有相似物候周期的作物类型，只依靠光谱信息不足以进行区分。</p> <p>星载合成孔径雷达（SAR）遥感具有全天时、全天候、覆盖范围广、穿透能力强的特点，能够反映植被的结构特征与介电特性，已越来越多地用于遥感作物分类。Silva等在巴西热带半干旱地区采用L波段机载SAR影像研究了单/双/全极化SAR后向散射强度进行作物分类的潜力，发现增加极化通道可大幅度提高作物分类的精度 。还有研究表明，对于单极化和双极化SAR，使用多时相数据可以提高作物分类的准确性，其中采用交叉极化的后向散射系数其分类精度优于其他极化模式。随着Sentinel-1 A和B卫星的发射，可免费获取的SAR数据量显著增加，该数据具有双极化模式，双星6天单轨12天的重访周期和20米的空间分辨率，这对于中高分辨率的作物分类是目前较为理想的SAR数据源。然而，受SAR成像系统固有的相干斑噪声影响，单独采用SAR影像进行棉花提取的精度较低 。现有技术对SAR数据后向散射强度的相干斑抑制效果不理想，由于采用本地规则窗口进行滤波，没有考虑周边像素的统计特性，在抑制噪声的同时极易模糊强散射体与周边低相干区域。此外，大部分研究只关注雷达后向散射强度，没有对SAR影像的其他特征在作物分类中的作用进行评估。</p> <p>可见光遥感影像受云的影响难以得到长时间序列影像，SAR影像具有全天时、全天候工作的优点，可提供长时间序列数据弥补这一不足，且光谱和SAR影像由于传感器和成像机理的不同，在地物解译方面有互补作用 。如何结合光学数据和SAR数据进行综合处理，对作物种类进行精确分类和提取，成为研究的热点。</p> <p>本研究提出了一种集成Sentinel-1合成孔径雷达影像和Sentinel-1多光谱数据的方法，对新疆巴州地区的典型绿洲农业区进行作物分类制图。为提高雷达数据提取特征的质量，本研究采用SHP-DSI方法，对时间序列Sentinel-1数据的后向散射强度进行相干斑抑制，并对相干系数进行精确估计和去偏。此外，首次在研究中提取了合成孔径雷达干涉（InSAR）产品用于作物分类，包括干涉相干系数，主从影像后向散射强度比和从SAR时间序列的振幅色离散度指数等。为探索红边特征在绿洲作物类型识别中的作用，本研究提取了Sentinel-2的3个红边波段并导出了11个红边指数，结合常规的多光谱特征，与雷达特征进行集成，以提高作物分类的精度。为了处理高维特征，获取SAR和光学特征的最优组合，本研究提出了一种半自动化的特征筛选流程，基于随机森林算法的特征重要性排序以及递归特征增量（Recursive Feature Increment，RFI）算法对所有特征进行筛选，以达到最高的作物分类精度。本研究发现Sentinel-2的红边特征将作物分类精度提高了3.06%。在对比实验中本研究证实了时间序列Sentinel-1和Sentienl-2的特征融合在作物分类中可实现最高精度。</p> <h1 id="模型方法介绍">模型方法介绍</h1> <p>本研究中使用的工作流程如图 3.6.2所示。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320222619-dzamxcu.png" alt="image.png" class="rounded"/></p> <p>图 3.6.2实验流程</p> <ol> <li><strong>基于Sentinel-1数据提取SAR和InSAR</strong><strong>特征</strong> 对时间序列Sentinel-1 IW SLC数据进行预处理，包括精配准、镶嵌、裁剪。为提高SAR和InSAR特征的信噪比，基于Gamma置信区间判别从时序SAR数据中提取统计同质像元（SHP），并采用SHP-DSI算法进行相干斑滤波，在此基础上提取SAR和InSAR特征。</li> <li><strong>**基于Sentinel-2</strong>**数据提取多光谱特征<br/> 对多时相Sentinel-2数据进行预处理，采用sen2cor软件将L1C级Top of Atmosphere (TOA)产品转换为L2A级产品表面反射率(surface reflectance)，提取10米、20米分辨率的所有谱段（包括B2, B3, B4, B5 B6, B7, B8, B8A, B11, B12）；并计算植被指数、水体指数、红边指数等</li> <li><strong>雷达和光学特征融合</strong><br/> 基于随机森林（Random Forest，RF）算法对所有特征进行重要性排序，在此基础上采用递归特征增加（Recursive Feature Increment，RFI）方法选取最优特征组合，进行土地覆盖分类，获取农田掩膜；在农田掩膜范围内，进行作物分类，得到作物分类制图。</li> </ol> <h1 id="试验结果">试验结果</h1> <p>采用基于统计同质像素（SHP）的SHP-DSI 算法对SAR影像进行相干斑抑制和相干系数估计，结果如下：</p> <p><img src="/SIAT-GeoScience/assets/image-20220320223206-ge364cs.png" alt="image.png" class="rounded"/></p> <p>图3.6.3 SAR后向散射强度图 (a)原始强度图； (b) Refined Lee算法滤波后强度图；(c) SHP-DSI算法滤波后强度图</p> <p><img src="/SIAT-GeoScience/assets/image-20220320223248-jnsulrj.png" alt="image.png" class="rounded"/></p> <p>图3.6.4干涉相干系数 (a) 常规7*7滑窗估计的干涉相干系数;(b) SHP-DSI 算法估计的干涉相干系数</p> <p><a href="">表</a>3.6.6采用不同方法处理后的SAR&amp;InSAR特征进行作物分类的精度</p> <table> <thead> <tr> <th> </th> <th>Mean OA</th> <th>Kappa Coefficient</th> <th>F1-score chili</th> <th>F1-score corn</th> <th>F1-score cotton</th> <th>F1-score pear</th> <th>F1-score tomato</th> </tr> </thead> <tbody> <tr> <td>Original</td> <td>60.20%</td> <td>0.48</td> <td>0.55</td> <td>0.33</td> <td>0.67</td> <td>0.72</td> <td>0.58</td> </tr> <tr> <td>Refined Lee</td> <td>73.21%</td> <td>0.65</td> <td>0.66</td> <td>0.52</td> <td>0.80</td> <td>0.83</td> <td>0.74</td> </tr> <tr> <td>SHP DSI</td> <td>79.46%</td> <td>0.73</td> <td>0.75</td> <td>0.60</td> <td>0.88</td> <td>0.86</td> <td>0.77</td> </tr> </tbody> </table> <p>从表3.6.6中可以看到，采用SHP-DSI算法较原始数据和常规Refined Lee算法滤波后提取的SAR和InSAR特征在作物分类制图中显著提高了精度，无论是总体精度（OA）、Kappa系数，还是每一个作物种类的F1-sore都有显著提高。采用随机森林算法进行一级类分类以提取农田，并采用分层交叉验证（K=10份）方法对总体精度和农田提取精度进行验证，结果如下：</p> <p><img src="/SIAT-GeoScience/assets/image-20220320223402-iu5ftzt.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.6.5(a) 土地覆盖分类结果；(b) 农田掩膜</p> <p><img src="/SIAT-GeoScience/assets/image-20220320223423-v17caoc.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.6.6雷达和光学特征集成获取的作物种类制图</p> <p>对比只使用SAR特征，只使用光学特征，以及SAR和光学特征的最优组合分别进行作物分类制图，精度对比如下：</p> <p><a href="">表 </a>3.6.9分别采用Sentinel-1、Sentinel-2常规多光谱特征、Sentinel-2包括红边特征在内的所有光学特征、Sentinel-1&amp;2集成特征的作物分类制图精度对比</p> <table> <thead> <tr> <th> </th> <th>Number of features</th> <th>Mean OA</th> <th>Kappa Coefficient</th> </tr> </thead> <tbody> <tr> <td>Sentinel-1</td> <td>133</td> <td>79.46%</td> <td>0.73</td> </tr> <tr> <td>Sentinel-2 without red-edge features</td> <td>58</td> <td>82.37%</td> <td>0.77</td> </tr> <tr> <td>Sentinel-2</td> <td>104</td> <td>85.43%</td> <td>0.81</td> </tr> <tr> <td>Sentinel-1 &amp; Sentinel-2</td> <td>113</td> <td>86.98%</td> <td>0.83</td> </tr> </tbody> </table> <p>表3.6.9说明，Sentinel-2的红边特征对比常规多光谱特征，将作物分类的OA提高了3.06%,Kappa系数提高了0.04；Sentinel-1雷达和Sentinel-2光学特征融合后，总体精度(OA)和Kappa系数比单独使用雷达或光学特征都有显著提高。</p> <p>对比分别采用Sentinel-1、Sentinel-2常规多光谱特征、Sentinel-2包括红边特征在内的所有光学特征、Sentinel-1&amp;2集成特征的每种作物类别的提取精度如图3.6.7所示。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320223515-7sruzy2.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.6.7不同特征组合下不同种类作物的提取精度对比</p> <p>从图3.6.7中本研究可以发现，对于辣椒和玉米，红边特征对提取精度的提高较显著；对于棉花和香梨，只采用Sentinel-1雷达特征时，各自的提取精度已经很高，Sentinel-2多光谱特征的加入又进一步提高了提取精度；对于番茄的提取，采用雷达特征、常规多光谱特征、红边特征的提取精度是一样的，雷达和光学特征的集成才显著提高了提取精度。查看每种作物的提取精度对比，共同点是，采用Sentinel-1&amp;2集成特征时，辣椒、玉米、棉花、香梨、番茄每种作物的提取F1-score都是几个特征组合中最高的。</p> <h1 id="结论">结论</h1> <p>本研究通过西北某小农区的案例研究，提出了一种协同利用 Sentinel-1 和 Sentinel-2 特征进行绿洲作物类型测绘的方法。首先，引入了 SHP DSI 算法，对 SAR 强度进行去斑处理，准确估计干涉测量相干性，提高 SAR 特征的质量。研究表明，在仅使用 SAR 特征的情况下，使用 SHP DSI 方法可使作物分类精度提高 6.25%。从多时态的 Sentinel-1 和 Sentinel-2 图像中得到了多种 SAR 特征和光学特征，包括几种 InSAR 产品和红边光谱波段和指数。其次，根据随机森林分类器的换元重要性，提出了一种递归特征增量特征选择方法，得到 Sentinel-1和 Sentinel-2 特征的最优组合，用于农田提取和作物类型分类。最后，生成了作物分布图，总体精度为 83.22%， kappa 系数为 0.77。对 SAR 和光学特征的贡献进行了深入探讨。在所有 Sentinel-1 特征中,VH 强度所占比例最大,说明 VH 偏振对植被变化的敏感性较好。同时，还注意到 InSAR 的一些产品，如 VH 振幅色散、主从强度比、 4 月上旬的 VV相干性等，揭示了某些作物类型的良好分离性。至于 Sentinel-2 特征，我们证明了在绿洲作物类型测绘中使用红边光谱波段和指数的优点。与仅使用传统光学特征相比，红边特征的加入使作物分类 OA提高了 1.84%。这证明了 Sentinel-2 数据的优越性，因为光谱分辨率的提高。对使用 4 种特征组合的绿洲作物分类性能进行了比较。结果表明， SAR 和光学特征的集成取得了最佳性能。我们认为，时间序列 S1 和 S2 图像的集成具有优势，由于数据的免费、充分和开放政策，可以在绝大多数地区进一步探索用于作物状况监测。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[针对异物同谱效应造成的作物提取精度不足问题，本研究提出了一种集成光学和微波特征的方法，通过特征融合提高作物提取精度。本研究基于Sentinel-1合成孔径雷达影像和Sentinel-2多光谱数据，对新疆巴州地区的典型绿洲农业区进行作物分类制图。为提高雷达数据提取特征的质量，采用SHP-DSI方法，对时间序列Sentinel-1数据的后向散射强度进行相干斑抑制，并对相干系数进行精确估计和去偏。此外，首次在研究中提取了合成孔径雷达干涉（InSAR）产品用于作物分类，包括干涉相干系数，主从影像后向散射强度比和从SAR时间序列的振幅色离散度指数等。为探索红边特征在绿洲作物类型识别中的作用，本研究提取了Sentinel-2的3个红边波段并导出了11个红边指数，结合常规的多光谱特征，与雷达特征进行集成，以提高作物分类的精度。 为了处理高维特征，获取SAR和光学特征的最优组合，本研究提出了一种半自动化的特征筛选流程，基于随机森林算法的特征重要性排序以及递归特征增量（Recursive Feature Increment，RFI）算法对所有特征进行筛选，以达到最高的作物分类精度。本研究发现Sentinel-2的红边特征将作物分类精度提高了3.06%。在对比实验中本研究证实了时间序列Sentinel-1和Sentienl-2的特征融合在作物分类中可实现最高精度。 原文链接 Sun, L., Chen, J., Guo, S., Deng, X., &amp; Han, Y. (2020). Integration of Time Series Sentinel-1 and Sentinel-2 Imagery for Crop Type Mapping over Oasis Agricultural Areas. Remote Sensing, 12(158), 1–27. 研究背景 新疆是我国西北干旱半干旱地带的主要农业区。由于气候干燥，新疆的农业生产几乎完全依靠灌溉，导致水资源匮乏问题更加严重。新疆地区是我国棉花的主要产区，种植面积大，棉花品质较好，是国内棉花供给的重要支柱。2017年，新疆棉花种植面积占全国比重超过60%；棉花产量占全国比重超过70%。此外，棉花种植和其他农作物相比，需要大量的水源进行浇灌，加快了土地荒漠化的速度。新疆一些地区历经数次农业结构调整，实行“退白扩红”战略，大量种植辣椒和番茄，因此种植结构更加复杂，需要更加及时和精确的农作物种类分布制图。农作物种类分布是进行水资源和环境承载力估计所需的重要信息。在我国西北干旱半干旱地区，农业是支柱产业而生态环境相对较为脆弱，因此更为重要。随着空间技术的发展，遥感技术以已被应用到大范围的农作物种植面积、长势监测中，具有宏观、准确、及时等优点，监测结果可为国家农业生产管理、粮食政策制定提供重要参考依据。 近年来，遥感技术被广泛应用于农作物种植面积监测及作物分类中。原来主要使用的是光学遥感影像，利用不同种类作物之间的物候期差异，通过植被指数的时间变化来进行某种作物的提取。有些研究采用MODIS植被指数时间序列进行作物分类，但是由于分辨率太低，不适用于地块尺寸小、异构性强的小农种植系统 。对于地块破碎、异构性强的种植区，中、高分辨率影像（30米以内）是更为合适的选择。此前也有不少研究采用Landsat NDVI时间序列进行作物提取、分类，但是由于Landsat重访周期较长，在作物生长关键期受频繁的云雨天气影响无法获取完整、连续的光学数据，严重影响监测的有效性 。Sentinel-2卫星的发射为遥感监测提供了较高时空分辨率的光学数据，重访周期为10天，分辨率达到10米，在小农种植系统的农作物种植面积、长势监测、作物分类等应用中具有较大的潜力 。但是，由于光学数据本身的特点，受云的影响，Sentinel-2在作物关键生长期的数据连续性仍然不能保证 。此外，对于具有相似物候周期的作物类型，只依靠光谱信息不足以进行区分。 星载合成孔径雷达（SAR）遥感具有全天时、全天候、覆盖范围广、穿透能力强的特点，能够反映植被的结构特征与介电特性，已越来越多地用于遥感作物分类。Silva等在巴西热带半干旱地区采用L波段机载SAR影像研究了单/双/全极化SAR后向散射强度进行作物分类的潜力，发现增加极化通道可大幅度提高作物分类的精度 。还有研究表明，对于单极化和双极化SAR，使用多时相数据可以提高作物分类的准确性，其中采用交叉极化的后向散射系数其分类精度优于其他极化模式。随着Sentinel-1 A和B卫星的发射，可免费获取的SAR数据量显著增加，该数据具有双极化模式，双星6天单轨12天的重访周期和20米的空间分辨率，这对于中高分辨率的作物分类是目前较为理想的SAR数据源。然而，受SAR成像系统固有的相干斑噪声影响，单独采用SAR影像进行棉花提取的精度较低 。现有技术对SAR数据后向散射强度的相干斑抑制效果不理想，由于采用本地规则窗口进行滤波，没有考虑周边像素的统计特性，在抑制噪声的同时极易模糊强散射体与周边低相干区域。此外，大部分研究只关注雷达后向散射强度，没有对SAR影像的其他特征在作物分类中的作用进行评估。 可见光遥感影像受云的影响难以得到长时间序列影像，SAR影像具有全天时、全天候工作的优点，可提供长时间序列数据弥补这一不足，且光谱和SAR影像由于传感器和成像机理的不同，在地物解译方面有互补作用 。如何结合光学数据和SAR数据进行综合处理，对作物种类进行精确分类和提取，成为研究的热点。 本研究提出了一种集成Sentinel-1合成孔径雷达影像和Sentinel-1多光谱数据的方法，对新疆巴州地区的典型绿洲农业区进行作物分类制图。为提高雷达数据提取特征的质量，本研究采用SHP-DSI方法，对时间序列Sentinel-1数据的后向散射强度进行相干斑抑制，并对相干系数进行精确估计和去偏。此外，首次在研究中提取了合成孔径雷达干涉（InSAR）产品用于作物分类，包括干涉相干系数，主从影像后向散射强度比和从SAR时间序列的振幅色离散度指数等。为探索红边特征在绿洲作物类型识别中的作用，本研究提取了Sentinel-2的3个红边波段并导出了11个红边指数，结合常规的多光谱特征，与雷达特征进行集成，以提高作物分类的精度。为了处理高维特征，获取SAR和光学特征的最优组合，本研究提出了一种半自动化的特征筛选流程，基于随机森林算法的特征重要性排序以及递归特征增量（Recursive Feature Increment，RFI）算法对所有特征进行筛选，以达到最高的作物分类精度。本研究发现Sentinel-2的红边特征将作物分类精度提高了3.06%。在对比实验中本研究证实了时间序列Sentinel-1和Sentienl-2的特征融合在作物分类中可实现最高精度。 模型方法介绍 本研究中使用的工作流程如图 3.6.2所示。 图 3.6.2实验流程 基于Sentinel-1数据提取SAR和InSAR特征 对时间序列Sentinel-1 IW SLC数据进行预处理，包括精配准、镶嵌、裁剪。为提高SAR和InSAR特征的信噪比，基于Gamma置信区间判别从时序SAR数据中提取统计同质像元（SHP），并采用SHP-DSI算法进行相干斑滤波，在此基础上提取SAR和InSAR特征。 **基于Sentinel-2**数据提取多光谱特征 对多时相Sentinel-2数据进行预处理，采用sen2cor软件将L1C级Top of Atmosphere (TOA)产品转换为L2A级产品表面反射率(surface reflectance)，提取10米、20米分辨率的所有谱段（包括B2, B3, B4, B5 B6, B7, B8, B8A, B11, B12）；并计算植被指数、水体指数、红边指数等 雷达和光学特征融合 基于随机森林（Random Forest，RF）算法对所有特征进行重要性排序，在此基础上采用递归特征增加（Recursive Feature Increment，RFI）方法选取最优特征组合，进行土地覆盖分类，获取农田掩膜；在农田掩膜范围内，进行作物分类，得到作物分类制图。 试验结果 采用基于统计同质像素（SHP）的SHP-DSI 算法对SAR影像进行相干斑抑制和相干系数估计，结果如下： 图3.6.3 SAR后向散射强度图 (a)原始强度图； (b) Refined Lee算法滤波后强度图；(c) SHP-DSI算法滤波后强度图 图3.6.4干涉相干系数 (a) 常规7*7滑窗估计的干涉相干系数;(b) SHP-DSI 算法估计的干涉相干系数 表3.6.6采用不同方法处理后的SAR&amp;InSAR特征进行作物分类的精度   Mean OA Kappa Coefficient F1-score chili F1-score corn F1-score cotton F1-score pear F1-score tomato Original 60.20% 0.48 0.55 0.33 0.67 0.72 0.58 Refined Lee 73.21% 0.65 0.66 0.52 0.80 0.83 0.74 SHP DSI 79.46% 0.73 0.75 0.60 0.88 0.86 0.77 从表3.6.6中可以看到，采用SHP-DSI算法较原始数据和常规Refined Lee算法滤波后提取的SAR和InSAR特征在作物分类制图中显著提高了精度，无论是总体精度（OA）、Kappa系数，还是每一个作物种类的F1-sore都有显著提高。采用随机森林算法进行一级类分类以提取农田，并采用分层交叉验证（K=10份）方法对总体精度和农田提取精度进行验证，结果如下： 图3.6.5(a) 土地覆盖分类结果；(b) 农田掩膜 图3.6.6雷达和光学特征集成获取的作物种类制图 对比只使用SAR特征，只使用光学特征，以及SAR和光学特征的最优组合分别进行作物分类制图，精度对比如下： 表 3.6.9分别采用Sentinel-1、Sentinel-2常规多光谱特征、Sentinel-2包括红边特征在内的所有光学特征、Sentinel-1&amp;2集成特征的作物分类制图精度对比   Number of features Mean OA Kappa Coefficient Sentinel-1 133 79.46% 0.73 Sentinel-2 without red-edge features 58 82.37% 0.77 Sentinel-2 104 85.43% 0.81 Sentinel-1 &amp; Sentinel-2 113 86.98% 0.83 表3.6.9说明，Sentinel-2的红边特征对比常规多光谱特征，将作物分类的OA提高了3.06%,Kappa系数提高了0.04；Sentinel-1雷达和Sentinel-2光学特征融合后，总体精度(OA)和Kappa系数比单独使用雷达或光学特征都有显著提高。 对比分别采用Sentinel-1、Sentinel-2常规多光谱特征、Sentinel-2包括红边特征在内的所有光学特征、Sentinel-1&amp;2集成特征的每种作物类别的提取精度如图3.6.7所示。 图3.6.7不同特征组合下不同种类作物的提取精度对比 从图3.6.7中本研究可以发现，对于辣椒和玉米，红边特征对提取精度的提高较显著；对于棉花和香梨，只采用Sentinel-1雷达特征时，各自的提取精度已经很高，Sentinel-2多光谱特征的加入又进一步提高了提取精度；对于番茄的提取，采用雷达特征、常规多光谱特征、红边特征的提取精度是一样的，雷达和光学特征的集成才显著提高了提取精度。查看每种作物的提取精度对比，共同点是，采用Sentinel-1&amp;2集成特征时，辣椒、玉米、棉花、香梨、番茄每种作物的提取F1-score都是几个特征组合中最高的。 结论 本研究通过西北某小农区的案例研究，提出了一种协同利用 Sentinel-1 和 Sentinel-2 特征进行绿洲作物类型测绘的方法。首先，引入了 SHP DSI 算法，对 SAR 强度进行去斑处理，准确估计干涉测量相干性，提高 SAR 特征的质量。研究表明，在仅使用 SAR 特征的情况下，使用 SHP DSI 方法可使作物分类精度提高 6.25%。从多时态的 Sentinel-1 和 Sentinel-2 图像中得到了多种 SAR 特征和光学特征，包括几种 InSAR 产品和红边光谱波段和指数。其次，根据随机森林分类器的换元重要性，提出了一种递归特征增量特征选择方法，得到 Sentinel-1和 Sentinel-2 特征的最优组合，用于农田提取和作物类型分类。最后，生成了作物分布图，总体精度为 83.22%， kappa 系数为 0.77。对 SAR 和光学特征的贡献进行了深入探讨。在所有 Sentinel-1 特征中,VH 强度所占比例最大,说明 VH 偏振对植被变化的敏感性较好。同时，还注意到 InSAR 的一些产品，如 VH 振幅色散、主从强度比、 4 月上旬的 VV相干性等，揭示了某些作物类型的良好分离性。至于 Sentinel-2 特征，我们证明了在绿洲作物类型测绘中使用红边光谱波段和指数的优点。与仅使用传统光学特征相比，红边特征的加入使作物分类 OA提高了 1.84%。这证明了 Sentinel-2 数据的优越性，因为光谱分辨率的提高。对使用 4 种特征组合的绿洲作物分类性能进行了比较。结果表明， SAR 和光学特征的集成取得了最佳性能。我们认为，时间序列 S1 和 S2 图像的集成具有优势，由于数据的免费、充分和开放政策，可以在绝大多数地区进一步探索用于作物状况监测。]]></summary></entry><entry><title type="html">对抗样本噪声的遥感深度学习分类网络模型</title><link href="https://shawnmiloguo.github.io/blog/2022/WLN/" rel="alternate" type="text/html" title="对抗样本噪声的遥感深度学习分类网络模型"/><published>2022-03-09T00:00:00+00:00</published><updated>2022-03-09T00:00:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2022/WLN</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2022/WLN/"><![CDATA[<p>针对样本标签噪声造成的地物提取精度不足问题，本文提出了一种抗噪声标签的卷积神经网络框架，Weight Loss Net（WLN）。WLN主要包含三部分：（1）分割子网络，用于产生图像的逐像素分类结果，可以使用其他的分割模型进行替换；（2）损失权重参数，用于对每个训练样本赋权重，对干净样本赋予高权重值，对噪声样本赋予低权重值，降低噪声样本对网络训练过程中的影响，提高网络的抗噪性能；（3）类别平衡系数，帮助网络平等地学习每一个类别，避免由于不同类别之间的不平衡导致模型过拟合。 基于上述方法在公开数据集（Inria Aerial Image Labeling Dataset,以下简称Inria）上实验进行建筑物提取，通过图像膨胀和腐蚀操作模拟四种标签噪声类型（多标注噪声，少标注噪声，错标注噪声和漏标注噪声）。本研究在训练数据集加入不同噪声率及噪声等级的训练样本，并在干净的数据集进行测试，与原U-Net网络进行比较，评估网络的抗噪性能。</p> <p>实验结果表明，当噪声增加的时候，WLN能够保持模型的性能和维持较高的精度，而U-Net模型的精度则有所下降。在噪声率及噪声等级比较低的时候，U-Net并不会受到噪声标签的影响，这是因为深度学习模型具有一定的抗噪性；当噪声率及噪声等级逐渐增加时，U-Net网络精度下降明显。在噪声不断增加的时候，我们提出的WLN可以一直保持很高的精度。这一结果表明，本文提出的抗噪声标签的卷积网络框架可以降低噪声训练标签对分隔模型的影响。</p> <h1 id="原文链接">原文链接</h1> <p>Lin, C., Guo, S., Chen, J., Sun, L., Zheng, X., Yang, Y., &amp; Xiong, Y. (2021). Deep Learning Network Intensification for Preventing Noisy-Labeled Samples for Remote Sensing Classification. Remote Sensing, 13(1689), 1–19.</p> <h1 id="研究背景">研究背景</h1> <p>深度学习方法性能好坏取决于两个因素，训练数据量的大小以及标签标注的准确性。相比于数据量小的问题，标签标注噪声问题更难解决。遥感数据集中标签噪声普遍存在。一是因为遥感图像土地类型复杂，需要有一定专业知识才能够对其进行准确标注 。二是因为多个专家同时对同一副遥感图像进行标注，每个专家之间的标注结果不一致 。三是低成本的自动化标注或者缺乏专业知识的人员进行标注，标注的结果往往可靠性较差。标签噪声通过影响网络的损失值，使得网络参数往错误的方向更新，降低了网络的分类性能。因此深度学习中的标签噪声问题处理方法主要分为两类，一类是针对标签，一类是针对损失值。针对标签进行处理的方法有两种实现形式，一种是对训练数据进行筛选，一种是计算转移矩阵。样本筛选，这类方法的主要思想是从一个有噪声的训练数据集中选择干净的样本进行网络训练。最初，MALACH E等人认为噪声样本会对网络进行错误的更新，即使网络能够预测到正确的样本，也会由于噪声标签使得此时调整好的网络往错误的方向更新，因此提出将何时更新与怎么更新进行分离，使用两个卷积神经网络，只有当两个网络预测结果不一致的时候才进行参数更新。之后，ARPIT D等人发现在网络训练过程中，网络倾向于先学习干净的样本，再慢慢拟合噪声样本及困难样本。因此，许多研究采用小损失选择准则，将一定数量的小损失训练样本作为干净样本。HUANG J等人就是基于这一准则，通过多次的循环从欠拟合到过拟合的过程，根据样本的loss曲线，把loss高的样本作为噪声样本剔除，保留小损失样本 。JIANG L等人介绍了一种协助学习的模式，网络分为两个部分，教师网络和学生网络，基于小损失样本选择准则，教师网络向学生网络筛选出正确的样本，学生网络根据教师网络提供的样本进行网络训练。HAN B等人认为一个网络对于标签噪声的学习中错误会不断累加，多个网络具有不同的学习能力，可以过滤不同类型的噪声标签带来的错误，因此采用了两个CNN网络，每个CNN网络都选择一定数量的小损失样本，并将其反馈给另一个网络进行训练。这类方法可以通过简单地排除不可靠的样本，有效地避免噪声标签对网络的影响。但是这类方法的关键在于能否设计有效的样本选择策略，如果选择策略不好，可能排除大量有用的样本。</p> <p>第二种实现形式是计算噪声转移矩阵，该矩阵定义了一个类别变换到另一个类别的概率，通过计算噪声转移矩阵，将噪声标签纠正为干净标签。CHEN X等人在网络末尾添加一层线性层作为噪声适应层，估计标签标注类别被翻转为其他类的概率，之后推断出真实的标签，进行网络参数更新。XIAO T等人提出的网络分为三个部分，分类子网络和噪声子网络以及噪声适应层，分类子网络可以得到分类的概率，噪声子网络可以得到标签为某一类噪声的概率，噪声适应层将两个子网络的输出作为输入推断出真实标签的概率。网络分为两阶段训练，首先采用干净的样本对分类子网络和噪声子网络做预训练，之后再用带噪声标签的数据集进行训练，推断出真实的标签，更新网络模型，提高网络性能。SUKHBAATAR S等人同样采用两阶段训练，首先使用简单易分辨的图像对网络进行预训练，之后再使用含噪声标签的数据集对网络最后一层噪声适应层进行微调。这类方法很大程度上依赖对于噪声分布的准确假设，而在实际中，这种分布很难准确估计出来。</p> <p>第二类方法主要是针对损失值进行处理，有两种实现形式，一种是修改网络的损失函数，一种是对损失值进行赋权重。修改网络损失函数的方法基本思路是设计一个鲁棒性的损失函数，即使训练数据中含有噪声标签，也可以使得计算出来的损失值不受噪声数据的影响。MANWANI N等人提出对于二值分类情况下，神经网络的损失函数对标签噪声有天然的鲁棒性。GHOSH A等人对这一理论推导至多分类的情况，并且对比了MAE,MSE,CCE损失函数对标签噪声的鲁棒性，证明了MAE损失函数对噪声具有更强的鲁棒性。ZHANG Z等人在前者的基础上发现MAE在复杂数据集中对噪声标签的鲁棒性表现不佳，文章对MAE进行修改，结合CCE，提出GCE损失函数。受KL散度对称性的启发，WANG Y等人提出对称性的交叉熵损失函数，用对噪声鲁棒的反交叉熵损失函数对交叉熵损失函数进行增强，解决交叉熵损失函数在有噪声标签数据集中的学习不足和过拟合现象。设计鲁棒性的损失函数虽然可以提高网络的抗噪性能，但是网络仍然会受到标签噪声的影响，并且只在简单的情况下执行得比较好，例如容易分别的类或者类别数量少的情况，同时损失函数的修改会增加训练收敛的时间。</p> <p>第二种实现形式是对损失值赋权重，基本思路是对所有训练样本损失值分配权重，并在训练过程中迭代更新这些权重。LIU 等人证明了通过对训练样本进行重要性加权，可以使得标签噪声训练下的分类器达到无噪声分类器的性能。REN M等人使用元学习范式基于梯度方向调整训练样本的损失权重。首先获取一个干净标签的数据集作为验证集，每一轮网络训练后在验证集上进行验证，计算验证集的损失值，之后由验证集的损失值得到训练样本的权重并对网络进行参数更新。SHU J等人也采用了类似的方法，但不是隐式计算权重，而是使用多层感知机估计权重值。XUE C等人不但通过网络迭代区分干净样本和噪声样本，同时根据噪声水平对样本进行加权提取出噪声样本和困难样本中的有用信息。这类方法的有效性主要取决于样本权重调整方案是否能够正确地提高干净标签样本的损失权重值，降低噪声标签样本的损失权重值。此外，如今的标签噪声处理方法大部分是针对于场景识别任务，对于遥感图像分类中标签噪声的处理研究很少，上述方法只适用于场景识别任务，不适用于遥感图像分类任务。</p> <p>在本文中，我们提出了一种适用于遥感图像分类中标签噪声处理的通用网络框架，Weight LossNet（WLN）。WLN对标签噪声的处理思路主要采用了上面提到的对损失值赋权重。其中对样本权重的调整方案结合注意力机制，通过注意力机制网络得出每个样本的重要性，提高重要样本的损失权重值，降低非重要样本的损失权重值，避免标签噪声对模型的影响。之后在遥感图像公开数据集Inria Aerial Image Labeling Dataset上进行实验，并与原始的分类网络方法进行对比。本文的主要贡献总结如下：（1）研究卷积神经网络对于四种常见的标签噪声类型(不足标签、冗余标签、缺失标签、错误标签)的鲁棒性。（2）提出一种适用于遥感图像分类中标签噪声处理的通用网络框架，该算法在不同噪声类型水平下都能保持较高的精度和较好的泛化性能。</p> <h1 id="数据源及覆盖区域">数据源及覆盖区域</h1> <p>在本文的研究中，采用Inria Aerial Image Labeling Dataset（以下简称为Inria数据集）。该数据集解决了遥感领域最重要的问题之一：航空图像的像素级自动标注。Inria数据集图像分辨率为30cm,标签标注两类信息，建筑类别和非建筑类别。同时这些图像覆盖了不同的城市地区，不但有建筑物稠密的大城市还有建筑物稀少的小镇。</p> <p>Inria训练数据集包含180副5000*5000大小的图像，覆盖Austin, Chicago, Kitsap County, Western Tyrol, and Vienna这5个地区，总面积为405平方公里。标签由180张单通道的图像组成，其中255表示建筑类别，0表示非建筑类别，具体图像如图3.5.1所示。由于此数据集是用于比赛，无法获取到测试集的标签，因此本研究中将原训练集按照8:1:1的比例分为训练集，验证集和测试集三部分，三者相互独立，互不重叠。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320180501-00sj5ku.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.5.1从左到右分别为Austin，Chicago，Kitsap County，Western Tyrol和Vienna的图像及对应的标签图</p> <h1 id="实验噪声设置">实验噪声设置</h1> <p>标签噪声定义为实例与标注的所属类别不相对应，即标注错误。在像素级遥感土地覆被标注中，有四种常见的标签噪声，1）多标注噪声，即标签面积大于实际面积；2）少标注噪声，即标签面积小于实际面积；3）错标注噪声，即将对象标注为错误的类别，4）漏标注噪声，即对象的整个标签缺失。</p> <p>为了模拟标签噪声，我们采用不同的卷积核对标签进行图像膨胀和腐蚀操作。如图3.5.2所示，第一行表示图像膨胀处理，模拟多标注噪声（如图3.5.2的c，d所示，分别对实际标签进行卷积核为9<em>9，17</em>17的图像膨胀操作）。当卷积核大小增加到25*25时，标签中包含很多错误的像素，可以认为是错标注噪声样本（如e所示）。同理，采用图像腐蚀操作模拟少标注噪声（如图3.5.2的f,g）和漏标注标签样本（h）。为了明确多标注和少标注噪声不同的误差，在本研究中，我们设置了三个噪声等级，我们将卷积核为9的噪声表示Noise level 1，卷积核为17表示Noise level 2，卷积核为25表示Noise level 3。本研究设置了5个数据集样本噪声率，以测试网络在不同错误样本数量下的表现。我们从训练集中随机选取0%、25%、35%、45%和50%的噪声样本对训练数据集进行噪声处理。具体噪声标签图像如图3.5.2所示。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320180701-kbf1dgb.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.5.2四种噪声标签的图像</p> <p>图3.5.2第一列从左到右分别是原图，干净标签图，Noise level1的多标注噪声标签图，Noise level 2的多标注噪声标签图，Noise level 3的错标注噪声标签图；第二列从左到右分别为原图，干净标签图，Noiselevel 1的少标注噪声标签图，Noise level 2的少标注噪声标签图，Noise level 3的漏标注噪声标签图。</p> <h1 id="wln-网络结构">WLN 网络结构</h1> <p><img src="/SIAT-GeoScience/assets/image-20220320180814-c8vmves.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.5.3 WLN的网络结构图</p> <p>WLN网络包含两个子网络，分割子网络和注意力子网络，其中分割子网络由分割模型组成，用于产生分割结果并与标签计算得到损失值，注意力子网络由CNN模型和注意力模块组成，用于计算训练样本的损失权重值。为了解决当腐蚀噪声中标签类别严重失衡而引起注意力子网络无法对训练样本赋予正确损失权重的问题，我们通过标签计算类别平衡系数进行类别平衡，最后将损失值，损失权重值，类别平衡系数三者结合，作为最终的损失值，对分割子网络和注意力子网络进行反向传播更新参数。</p> <p>WLN网络的分割子网络采用的是U-Net分割模型，也可以替换成其他的分割模型。注意力机制子网络实现形式采用的是SE模块，SE模块是胡杰及其团队于2017年提出的一种卷积神经网络结构，如图3.5.4所示。SE模块的提出是为了考虑特征图中通道之间的关系，并为每个通道提供不同的权重。它通过学习自动获取每个特征通道的重要性，然后根据每个通道的重要性加强有用的特征，而抑制对当前任务无用的特征。squeeze和excitation是SE模块中的两个关键操作。这两个操作可以帮助SE模型捕获通道侧的依赖性，并大大减少参数和计算的数量。</p> <h1 id="实验结果及分析">实验结果及分析</h1> <p>本节按照上一章介绍的参数设置进行模型训练得到对应的WLN模型和U-Net模型，在相同的测试集中对两个模型进行评价，本文从定量提取精度和定性地物提取细节两个角度，按照上节所述的评价指标对地物提取结果进行评价。同时，在讨论部分对引进的两个参数，损失权重值和类别平衡系数的有效性进行分析。</p> <p>下面我们分别比较WLN和U-Net对于腐蚀和膨胀噪声类型的测试集提取精度结果。</p> <p>（1）膨胀噪声</p> <p>我们分别使用不同噪声率及不同噪声等级的膨胀噪声标签训练集对WLN网络和U-Net网络进行训练，并在干净的标签测试集上进行测试。表3.5.1和图3.5.8显示了两种方法在测试集的提取精度结果。从精度曲线图上可以看出，在干净的数据集中，U-Net和WLN都可以保持很高的精度。随着噪声率的不断增加，网络精度并不是立马下降。在Noise level 1下， U-Net方法仍能保持较高的精度，这可能是因为卷积神经网络具有特定的抗噪声能力。但是，当噪声率在50%时，U-Net的精度明显下降，在Noise level 2时，OA下降4.4%，MIOU下降7.7%，Kappa下降2.0%；在Noise level 3时，OA下降12.7%，MIOU下降20.7%，Kappa下降13.8%。相比之下，WLN在噪声率增加的情况下仍能保持较高的精度，噪声率在50%时，在Noise level 2时，OA下降1.2%，MIOU下降2.1%，Kappa下降1.1%；在Noise level 3时，OA下降0.2%，MIOU下降0.3%，Kappa下降0.8%。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320181106-xhrl4z3.png" alt="image.png" class="rounded"/></p> <p>（2）腐蚀噪声</p> <p>我们分别使用不同噪声率及不同噪声等级的腐蚀噪声标签训练集对WLN网络和U-Net网络进行训练，并在干净的标签测试集上进行测试。表3.5.2和图3.5.9显示了两种方法在测试集的提取精度结果。从精度曲线上可以看出，网络在腐蚀噪声中的精度变化与膨胀噪声中的精度变化相似。U-Net网络在噪声率以及噪声等级低的时候，由于自身的抗噪能力，可以避免噪声的影响。随着噪声率的增加（在Noiselevel 3，噪声率为50%时），U-Net方法在测试集上的OA精度在这个过程下降了8.4%，MIOU下降了24.2%，Kappa系数下降了43.3%，变化幅度较大。而WLN稳定性更好，OA在这个过程只变化了1.5%，MIOU变化了4.7%，Kappa系数变化了0.5%。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320181202-2xgkaeh.png" alt="image.png" class="rounded"/></p> <h1 id="提取细节比较">提取细节比较</h1> <p>这一小节我们通过目视解译的方式来评估WLN和U-Net模型在膨胀和腐蚀标签噪声下地物提取细节。</p> <p>（1）膨胀噪声</p> <p>图3.5.10是膨胀噪声类型下在噪声率为50%不同噪声等级下两种方法的提取结果。第一行和第二行是Noiselevel 1提取结果，第三行和第四行是Noise level 2的提取结果，第五行和第六行是Noise level 3的提取结果。从图中可以看出，在噪声级别比较低的时候，如Noiselevel 1，WLN和U-Net的提取结果相似，但是U-Net由于受到膨胀噪声的影响会将一些非建筑物的像素点分类为建筑物，如图中红框所示。当噪声级别比较高的时候，如Noiselevel 3，U-Net受膨胀噪声影响比较大，对于建筑物只能提取出大概的轮廓，会将建筑物中的街道也标记为建筑物，而WLN方法对于噪声的影响较小，可以很好的识别建筑物及建筑物之间的界限。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320181325-5bh6lsj.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.5.10膨胀噪声类型下U-Net和WLN的提取结果图</p> <p>（2）腐蚀噪声</p> <p>图3.5.11是腐蚀噪声类型下在噪声率为50%不同噪声级别两种方法的提取结果。第一行和第二行是Noise level 1提取结果，第三行和第四行是Noise level 2的提取结果，第五行和第六行是Noise<br/> level 3的提取结果。从图中可以看出，在噪声级别比较低时，如Noise level 1，WLN和U-Net的提取结果相对较完整，但是U-Net由于受到腐蚀噪声的影响，会将一些建筑物像素点分类为非建筑物，如图中红框所示，随着噪声级别的增加，这种影响会越来越大，如在Noise level 3中，U-Net基本已经无法对建筑物进行分类，而WLN即使在高噪声级别下依旧可以得到很好的分类结果。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320181435-8ifzmqa.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.5.11腐蚀噪声类型下U-Net和WLN的提取结果图</p> <h1 id="结论">结论</h1> <p>训练标签的错误通常很难被识别和纠正，尤其是在跨时间和地点的遥感数据集中。在本文中，我们提出了一种通用的抗噪声网络框架WLN，基于对每个训练样本进行加权损失的思想，将错误样本对遥感图像分类的影响降到最低。该框架由两个网络组成，即分割子网络和注意力子网络。分段子网络对图像逐个像素进行分类，并计算输出结果与标签，得到训练过程中的初始损失。注意力子网络生成批量样本的权重损失，并与类别平衡系数相结合，防止每个训练样本的类不平衡。这三部分结合得到最终的损失，并对两个子网络进行反推，更新网络参数。</p> <p>通过膨胀和腐蚀处理模拟四种标签噪声(不足标签、冗余标签、缺失标签、错误标签)来测试网络的抗噪声能力。在评估了所提出的WLN与原U-Net模型在Inria航空图像标签数据集中提取建筑物的性能后，我们发现：</p> <p>(1)当噪声率和噪声水平较低时，卷积神经网络几乎不受标签噪声的影响，这可能是由于网络特有的抗噪声能力。当训练集的标签噪声率超过一定阈值后，卷积神经网络的准确率就会明显下降。</p> <p>(2)对于四种标签噪声，如果数据集的样本噪声率和噪声水平逐渐增加，我们提出的方法WLN可以保持较高的精度，并优于原方法。</p> <p>(3)如果我们让网络选择哪些样本是必不可少的，就会发现局部最优问题。这种现象可能具有普遍性，可以通过加入类别平衡系数来调整类标签的不平衡性来缓解。这个问题将在以后的工作中进一步研究。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[针对样本标签噪声造成的地物提取精度不足问题，本文提出了一种抗噪声标签的卷积神经网络框架，Weight Loss Net（WLN）。WLN主要包含三部分：（1）分割子网络，用于产生图像的逐像素分类结果，可以使用其他的分割模型进行替换；（2）损失权重参数，用于对每个训练样本赋权重，对干净样本赋予高权重值，对噪声样本赋予低权重值，降低噪声样本对网络训练过程中的影响，提高网络的抗噪性能；（3）类别平衡系数，帮助网络平等地学习每一个类别，避免由于不同类别之间的不平衡导致模型过拟合。 基于上述方法在公开数据集（Inria Aerial Image Labeling Dataset,以下简称Inria）上实验进行建筑物提取，通过图像膨胀和腐蚀操作模拟四种标签噪声类型（多标注噪声，少标注噪声，错标注噪声和漏标注噪声）。本研究在训练数据集加入不同噪声率及噪声等级的训练样本，并在干净的数据集进行测试，与原U-Net网络进行比较，评估网络的抗噪性能。 实验结果表明，当噪声增加的时候，WLN能够保持模型的性能和维持较高的精度，而U-Net模型的精度则有所下降。在噪声率及噪声等级比较低的时候，U-Net并不会受到噪声标签的影响，这是因为深度学习模型具有一定的抗噪性；当噪声率及噪声等级逐渐增加时，U-Net网络精度下降明显。在噪声不断增加的时候，我们提出的WLN可以一直保持很高的精度。这一结果表明，本文提出的抗噪声标签的卷积网络框架可以降低噪声训练标签对分隔模型的影响。 原文链接 Lin, C., Guo, S., Chen, J., Sun, L., Zheng, X., Yang, Y., &amp; Xiong, Y. (2021). Deep Learning Network Intensification for Preventing Noisy-Labeled Samples for Remote Sensing Classification. Remote Sensing, 13(1689), 1–19. 研究背景 深度学习方法性能好坏取决于两个因素，训练数据量的大小以及标签标注的准确性。相比于数据量小的问题，标签标注噪声问题更难解决。遥感数据集中标签噪声普遍存在。一是因为遥感图像土地类型复杂，需要有一定专业知识才能够对其进行准确标注 。二是因为多个专家同时对同一副遥感图像进行标注，每个专家之间的标注结果不一致 。三是低成本的自动化标注或者缺乏专业知识的人员进行标注，标注的结果往往可靠性较差。标签噪声通过影响网络的损失值，使得网络参数往错误的方向更新，降低了网络的分类性能。因此深度学习中的标签噪声问题处理方法主要分为两类，一类是针对标签，一类是针对损失值。针对标签进行处理的方法有两种实现形式，一种是对训练数据进行筛选，一种是计算转移矩阵。样本筛选，这类方法的主要思想是从一个有噪声的训练数据集中选择干净的样本进行网络训练。最初，MALACH E等人认为噪声样本会对网络进行错误的更新，即使网络能够预测到正确的样本，也会由于噪声标签使得此时调整好的网络往错误的方向更新，因此提出将何时更新与怎么更新进行分离，使用两个卷积神经网络，只有当两个网络预测结果不一致的时候才进行参数更新。之后，ARPIT D等人发现在网络训练过程中，网络倾向于先学习干净的样本，再慢慢拟合噪声样本及困难样本。因此，许多研究采用小损失选择准则，将一定数量的小损失训练样本作为干净样本。HUANG J等人就是基于这一准则，通过多次的循环从欠拟合到过拟合的过程，根据样本的loss曲线，把loss高的样本作为噪声样本剔除，保留小损失样本 。JIANG L等人介绍了一种协助学习的模式，网络分为两个部分，教师网络和学生网络，基于小损失样本选择准则，教师网络向学生网络筛选出正确的样本，学生网络根据教师网络提供的样本进行网络训练。HAN B等人认为一个网络对于标签噪声的学习中错误会不断累加，多个网络具有不同的学习能力，可以过滤不同类型的噪声标签带来的错误，因此采用了两个CNN网络，每个CNN网络都选择一定数量的小损失样本，并将其反馈给另一个网络进行训练。这类方法可以通过简单地排除不可靠的样本，有效地避免噪声标签对网络的影响。但是这类方法的关键在于能否设计有效的样本选择策略，如果选择策略不好，可能排除大量有用的样本。 第二种实现形式是计算噪声转移矩阵，该矩阵定义了一个类别变换到另一个类别的概率，通过计算噪声转移矩阵，将噪声标签纠正为干净标签。CHEN X等人在网络末尾添加一层线性层作为噪声适应层，估计标签标注类别被翻转为其他类的概率，之后推断出真实的标签，进行网络参数更新。XIAO T等人提出的网络分为三个部分，分类子网络和噪声子网络以及噪声适应层，分类子网络可以得到分类的概率，噪声子网络可以得到标签为某一类噪声的概率，噪声适应层将两个子网络的输出作为输入推断出真实标签的概率。网络分为两阶段训练，首先采用干净的样本对分类子网络和噪声子网络做预训练，之后再用带噪声标签的数据集进行训练，推断出真实的标签，更新网络模型，提高网络性能。SUKHBAATAR S等人同样采用两阶段训练，首先使用简单易分辨的图像对网络进行预训练，之后再使用含噪声标签的数据集对网络最后一层噪声适应层进行微调。这类方法很大程度上依赖对于噪声分布的准确假设，而在实际中，这种分布很难准确估计出来。 第二类方法主要是针对损失值进行处理，有两种实现形式，一种是修改网络的损失函数，一种是对损失值进行赋权重。修改网络损失函数的方法基本思路是设计一个鲁棒性的损失函数，即使训练数据中含有噪声标签，也可以使得计算出来的损失值不受噪声数据的影响。MANWANI N等人提出对于二值分类情况下，神经网络的损失函数对标签噪声有天然的鲁棒性。GHOSH A等人对这一理论推导至多分类的情况，并且对比了MAE,MSE,CCE损失函数对标签噪声的鲁棒性，证明了MAE损失函数对噪声具有更强的鲁棒性。ZHANG Z等人在前者的基础上发现MAE在复杂数据集中对噪声标签的鲁棒性表现不佳，文章对MAE进行修改，结合CCE，提出GCE损失函数。受KL散度对称性的启发，WANG Y等人提出对称性的交叉熵损失函数，用对噪声鲁棒的反交叉熵损失函数对交叉熵损失函数进行增强，解决交叉熵损失函数在有噪声标签数据集中的学习不足和过拟合现象。设计鲁棒性的损失函数虽然可以提高网络的抗噪性能，但是网络仍然会受到标签噪声的影响，并且只在简单的情况下执行得比较好，例如容易分别的类或者类别数量少的情况，同时损失函数的修改会增加训练收敛的时间。 第二种实现形式是对损失值赋权重，基本思路是对所有训练样本损失值分配权重，并在训练过程中迭代更新这些权重。LIU 等人证明了通过对训练样本进行重要性加权，可以使得标签噪声训练下的分类器达到无噪声分类器的性能。REN M等人使用元学习范式基于梯度方向调整训练样本的损失权重。首先获取一个干净标签的数据集作为验证集，每一轮网络训练后在验证集上进行验证，计算验证集的损失值，之后由验证集的损失值得到训练样本的权重并对网络进行参数更新。SHU J等人也采用了类似的方法，但不是隐式计算权重，而是使用多层感知机估计权重值。XUE C等人不但通过网络迭代区分干净样本和噪声样本，同时根据噪声水平对样本进行加权提取出噪声样本和困难样本中的有用信息。这类方法的有效性主要取决于样本权重调整方案是否能够正确地提高干净标签样本的损失权重值，降低噪声标签样本的损失权重值。此外，如今的标签噪声处理方法大部分是针对于场景识别任务，对于遥感图像分类中标签噪声的处理研究很少，上述方法只适用于场景识别任务，不适用于遥感图像分类任务。 在本文中，我们提出了一种适用于遥感图像分类中标签噪声处理的通用网络框架，Weight LossNet（WLN）。WLN对标签噪声的处理思路主要采用了上面提到的对损失值赋权重。其中对样本权重的调整方案结合注意力机制，通过注意力机制网络得出每个样本的重要性，提高重要样本的损失权重值，降低非重要样本的损失权重值，避免标签噪声对模型的影响。之后在遥感图像公开数据集Inria Aerial Image Labeling Dataset上进行实验，并与原始的分类网络方法进行对比。本文的主要贡献总结如下：（1）研究卷积神经网络对于四种常见的标签噪声类型(不足标签、冗余标签、缺失标签、错误标签)的鲁棒性。（2）提出一种适用于遥感图像分类中标签噪声处理的通用网络框架，该算法在不同噪声类型水平下都能保持较高的精度和较好的泛化性能。 数据源及覆盖区域 在本文的研究中，采用Inria Aerial Image Labeling Dataset（以下简称为Inria数据集）。该数据集解决了遥感领域最重要的问题之一：航空图像的像素级自动标注。Inria数据集图像分辨率为30cm,标签标注两类信息，建筑类别和非建筑类别。同时这些图像覆盖了不同的城市地区，不但有建筑物稠密的大城市还有建筑物稀少的小镇。 Inria训练数据集包含180副5000*5000大小的图像，覆盖Austin, Chicago, Kitsap County, Western Tyrol, and Vienna这5个地区，总面积为405平方公里。标签由180张单通道的图像组成，其中255表示建筑类别，0表示非建筑类别，具体图像如图3.5.1所示。由于此数据集是用于比赛，无法获取到测试集的标签，因此本研究中将原训练集按照8:1:1的比例分为训练集，验证集和测试集三部分，三者相互独立，互不重叠。 图3.5.1从左到右分别为Austin，Chicago，Kitsap County，Western Tyrol和Vienna的图像及对应的标签图 实验噪声设置 标签噪声定义为实例与标注的所属类别不相对应，即标注错误。在像素级遥感土地覆被标注中，有四种常见的标签噪声，1）多标注噪声，即标签面积大于实际面积；2）少标注噪声，即标签面积小于实际面积；3）错标注噪声，即将对象标注为错误的类别，4）漏标注噪声，即对象的整个标签缺失。 为了模拟标签噪声，我们采用不同的卷积核对标签进行图像膨胀和腐蚀操作。如图3.5.2所示，第一行表示图像膨胀处理，模拟多标注噪声（如图3.5.2的c，d所示，分别对实际标签进行卷积核为99，1717的图像膨胀操作）。当卷积核大小增加到25*25时，标签中包含很多错误的像素，可以认为是错标注噪声样本（如e所示）。同理，采用图像腐蚀操作模拟少标注噪声（如图3.5.2的f,g）和漏标注标签样本（h）。为了明确多标注和少标注噪声不同的误差，在本研究中，我们设置了三个噪声等级，我们将卷积核为9的噪声表示Noise level 1，卷积核为17表示Noise level 2，卷积核为25表示Noise level 3。本研究设置了5个数据集样本噪声率，以测试网络在不同错误样本数量下的表现。我们从训练集中随机选取0%、25%、35%、45%和50%的噪声样本对训练数据集进行噪声处理。具体噪声标签图像如图3.5.2所示。 图3.5.2四种噪声标签的图像 图3.5.2第一列从左到右分别是原图，干净标签图，Noise level1的多标注噪声标签图，Noise level 2的多标注噪声标签图，Noise level 3的错标注噪声标签图；第二列从左到右分别为原图，干净标签图，Noiselevel 1的少标注噪声标签图，Noise level 2的少标注噪声标签图，Noise level 3的漏标注噪声标签图。 WLN 网络结构 图3.5.3 WLN的网络结构图 WLN网络包含两个子网络，分割子网络和注意力子网络，其中分割子网络由分割模型组成，用于产生分割结果并与标签计算得到损失值，注意力子网络由CNN模型和注意力模块组成，用于计算训练样本的损失权重值。为了解决当腐蚀噪声中标签类别严重失衡而引起注意力子网络无法对训练样本赋予正确损失权重的问题，我们通过标签计算类别平衡系数进行类别平衡，最后将损失值，损失权重值，类别平衡系数三者结合，作为最终的损失值，对分割子网络和注意力子网络进行反向传播更新参数。 WLN网络的分割子网络采用的是U-Net分割模型，也可以替换成其他的分割模型。注意力机制子网络实现形式采用的是SE模块，SE模块是胡杰及其团队于2017年提出的一种卷积神经网络结构，如图3.5.4所示。SE模块的提出是为了考虑特征图中通道之间的关系，并为每个通道提供不同的权重。它通过学习自动获取每个特征通道的重要性，然后根据每个通道的重要性加强有用的特征，而抑制对当前任务无用的特征。squeeze和excitation是SE模块中的两个关键操作。这两个操作可以帮助SE模型捕获通道侧的依赖性，并大大减少参数和计算的数量。 实验结果及分析 本节按照上一章介绍的参数设置进行模型训练得到对应的WLN模型和U-Net模型，在相同的测试集中对两个模型进行评价，本文从定量提取精度和定性地物提取细节两个角度，按照上节所述的评价指标对地物提取结果进行评价。同时，在讨论部分对引进的两个参数，损失权重值和类别平衡系数的有效性进行分析。 下面我们分别比较WLN和U-Net对于腐蚀和膨胀噪声类型的测试集提取精度结果。 （1）膨胀噪声 我们分别使用不同噪声率及不同噪声等级的膨胀噪声标签训练集对WLN网络和U-Net网络进行训练，并在干净的标签测试集上进行测试。表3.5.1和图3.5.8显示了两种方法在测试集的提取精度结果。从精度曲线图上可以看出，在干净的数据集中，U-Net和WLN都可以保持很高的精度。随着噪声率的不断增加，网络精度并不是立马下降。在Noise level 1下， U-Net方法仍能保持较高的精度，这可能是因为卷积神经网络具有特定的抗噪声能力。但是，当噪声率在50%时，U-Net的精度明显下降，在Noise level 2时，OA下降4.4%，MIOU下降7.7%，Kappa下降2.0%；在Noise level 3时，OA下降12.7%，MIOU下降20.7%，Kappa下降13.8%。相比之下，WLN在噪声率增加的情况下仍能保持较高的精度，噪声率在50%时，在Noise level 2时，OA下降1.2%，MIOU下降2.1%，Kappa下降1.1%；在Noise level 3时，OA下降0.2%，MIOU下降0.3%，Kappa下降0.8%。 （2）腐蚀噪声 我们分别使用不同噪声率及不同噪声等级的腐蚀噪声标签训练集对WLN网络和U-Net网络进行训练，并在干净的标签测试集上进行测试。表3.5.2和图3.5.9显示了两种方法在测试集的提取精度结果。从精度曲线上可以看出，网络在腐蚀噪声中的精度变化与膨胀噪声中的精度变化相似。U-Net网络在噪声率以及噪声等级低的时候，由于自身的抗噪能力，可以避免噪声的影响。随着噪声率的增加（在Noiselevel 3，噪声率为50%时），U-Net方法在测试集上的OA精度在这个过程下降了8.4%，MIOU下降了24.2%，Kappa系数下降了43.3%，变化幅度较大。而WLN稳定性更好，OA在这个过程只变化了1.5%，MIOU变化了4.7%，Kappa系数变化了0.5%。 提取细节比较 这一小节我们通过目视解译的方式来评估WLN和U-Net模型在膨胀和腐蚀标签噪声下地物提取细节。 （1）膨胀噪声 图3.5.10是膨胀噪声类型下在噪声率为50%不同噪声等级下两种方法的提取结果。第一行和第二行是Noiselevel 1提取结果，第三行和第四行是Noise level 2的提取结果，第五行和第六行是Noise level 3的提取结果。从图中可以看出，在噪声级别比较低的时候，如Noiselevel 1，WLN和U-Net的提取结果相似，但是U-Net由于受到膨胀噪声的影响会将一些非建筑物的像素点分类为建筑物，如图中红框所示。当噪声级别比较高的时候，如Noiselevel 3，U-Net受膨胀噪声影响比较大，对于建筑物只能提取出大概的轮廓，会将建筑物中的街道也标记为建筑物，而WLN方法对于噪声的影响较小，可以很好的识别建筑物及建筑物之间的界限。 图3.5.10膨胀噪声类型下U-Net和WLN的提取结果图 （2）腐蚀噪声 图3.5.11是腐蚀噪声类型下在噪声率为50%不同噪声级别两种方法的提取结果。第一行和第二行是Noise level 1提取结果，第三行和第四行是Noise level 2的提取结果，第五行和第六行是Noise level 3的提取结果。从图中可以看出，在噪声级别比较低时，如Noise level 1，WLN和U-Net的提取结果相对较完整，但是U-Net由于受到腐蚀噪声的影响，会将一些建筑物像素点分类为非建筑物，如图中红框所示，随着噪声级别的增加，这种影响会越来越大，如在Noise level 3中，U-Net基本已经无法对建筑物进行分类，而WLN即使在高噪声级别下依旧可以得到很好的分类结果。 图3.5.11腐蚀噪声类型下U-Net和WLN的提取结果图 结论 训练标签的错误通常很难被识别和纠正，尤其是在跨时间和地点的遥感数据集中。在本文中，我们提出了一种通用的抗噪声网络框架WLN，基于对每个训练样本进行加权损失的思想，将错误样本对遥感图像分类的影响降到最低。该框架由两个网络组成，即分割子网络和注意力子网络。分段子网络对图像逐个像素进行分类，并计算输出结果与标签，得到训练过程中的初始损失。注意力子网络生成批量样本的权重损失，并与类别平衡系数相结合，防止每个训练样本的类不平衡。这三部分结合得到最终的损失，并对两个子网络进行反推，更新网络参数。 通过膨胀和腐蚀处理模拟四种标签噪声(不足标签、冗余标签、缺失标签、错误标签)来测试网络的抗噪声能力。在评估了所提出的WLN与原U-Net模型在Inria航空图像标签数据集中提取建筑物的性能后，我们发现： (1)当噪声率和噪声水平较低时，卷积神经网络几乎不受标签噪声的影响，这可能是由于网络特有的抗噪声能力。当训练集的标签噪声率超过一定阈值后，卷积神经网络的准确率就会明显下降。 (2)对于四种标签噪声，如果数据集的样本噪声率和噪声水平逐渐增加，我们提出的方法WLN可以保持较高的精度，并优于原方法。 (3)如果我们让网络选择哪些样本是必不可少的，就会发现局部最优问题。这种现象可能具有普遍性，可以通过加入类别平衡系数来调整类标签的不平衡性来缓解。这个问题将在以后的工作中进一步研究。]]></summary></entry><entry><title type="html">基于HRU-Net的中高分辨率地表要素提取模型</title><link href="https://shawnmiloguo.github.io/blog/2022/HRUNET/" rel="alternate" type="text/html" title="基于HRU-Net的中高分辨率地表要素提取模型"/><published>2022-03-08T00:00:00+00:00</published><updated>2022-03-08T00:00:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2022/HRUNET</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2022/HRUNET/"><![CDATA[<p>多光谱遥感中，由于同物异谱效应，采用传统分类方法（如支持向量机、随机森林）对类似耕地这样的复合要素（休耕、弃耕、轮种情况下的耕地光谱差异较大）提取精度较低。卷积神经网络（CNN）对同一类地物的特征类内差异容忍度较高，具有较强的泛化能力，在同物异谱情况下有望提高复合要素的提取精度。 </p> <p>本文从网络结构和损失函数表达两个方面入手，专注于解决原有深度卷积网络应用到遥感地物分类时存在的高分辨率信息丢失问题。本文提出的方法是在U-Net网络框架基础上，通过结合GridNet，interlinked CNNds ，HRNet等网络全程保持高分辨率信息的核心思想，改进了网络的跳跃连接结构，提出的高分辨HRU-Net网络。于此同时，在HRU-NET设置损失函数中引入深度监督的思想，进一步保留的高分辨率信息训练网络参数。本文以实验以Landsat<br/> 4-5 TM传感器为数据源，以新疆卡拉水库附件建设兵团农田为实验区，进行模型验证。该方法可以进一步推广到其他具有同物异谱地物的分类任务中，以提高精度和地物分类细节丰富度。</p> <h1 id="原文链接">原文链接</h1> <p>Xu, W., Deng, X., Guo, S., Chen, J., Sun, L., Zheng, X., Xiong, Y., Shen, Y., &amp; Wang, X. (2020). High-Resolution U-Net : Preserving Image Details for Extraction Cultivated Land. Sensors, 20(15), 4064.</p> <p>(https://www.mdpi.com/1424-8220/20/15/4064/html)</p> <h1 id="研究背景">研究背景</h1> <p>耕地作为重要的土地利用/土地覆盖类型，其数量、质量和空间分布范围关系着人类社会和经济的发展，关乎国家粮食安全问题，且与生态环境保护紧密相连。准确、快速地获取耕地信息是土地利用/土地覆盖研究领域的热点之一。遥感技术为提取耕地类型提供了更加快速、全面、准确的手段，利用遥感图像分类方法提取耕地信息，了解耕地分布、耕地类型及耕地面积等对有效管理作物种植和优化作物种植结构有重要意义。</p> <p>传统的遥感分类方法（SVM, KNN, 和RF等）用于耕地提取时的难点主要有三个方面：1）耕地严重的同物异谱现象：耕地上种植的作物类型多种多样，灌溉方式和土壤类型存在差异，同时存在未覆盖地物的休耕期耕地，导致不同耕地的光谱特征差别明显，而传统的遥感分类方法，以扩大类间差距，减少类内差距为优化目标，不能很好的适应覆盖不同地物的耕地提取要求 ^[33,34]^ 。2）传统遥感分类方法采用的有限的特征，并且这些特征往往针对具体问题进行设计，特征跨地域泛化表征性不强，在研究区内训练的方法，很难在其他区域进行直接应用 ^[35,36]^ 。3）基于统计学习的传统算法，基于样点得到对象在特征空间的分布信息，算法复杂度较高，当训练样本较大时，会出现无法训练或精度饱和等现象，不适合处理大规模的遥感图像数据。</p> <p>近年来，深度学习在遥感图像分类领域发展迅速 ^[37,38]^ ，主要采用的有图片级分类和像素级分类两种方法。1）图片级分类算法，该方法以单个图像为判别单元，每个图像只能包含一种地物类别，通过卷积神经网络对图像的整体特征进行学习。这类算法的核心是图像的识别，通过将整幅影像切割成包含单一地物的若干子影像后，分别对子影像中的地物进行识别。这种方法的优势在于能够较好的利用领域特征，从而提高准确识别地物的类别。但缺点是无法给出像素级的分类结果。因此目前这里方法大多使用在地物识别和提取的应用场景下。例如，Alshehhi等提出了一种卷积神经网络，从高分辨率遥感数据中提取道路和建筑物。Long等提出了一种高分辨率遥感图像的三步物体定位算法，模拟了Fast R-CNN的工作流程，实现地物要素的提取 ^[39]^ 。2）像素级分类算法，以每个像素为判别单元，采用的全卷积网络去掉了卷积神经网络中的全连接层，换成了1*1卷积层，来实现端到端（像素到像素）的分类方法。这种替换保留了图像内容的空间信息，解除了卷积神经网络对输入图像大小的限制，同时大大减少了模型参数量，提高了算法效率。其中具有代表性的有，Jamie Sherrah提出了一种不包括常规下采样层的FCN算法，在ISPRS数据集中实现了89.1%的总体精度 ^[40]^ 。Marmanis等人设计了一个像素级分割架构，合成FCN和反卷积网络，并将CRF应用于后处理以进行细化，在基于ISPRS Vaihingen数据集标签的人工数据集中取得了88.5%的总体精度 ^[41]^ 。Chen等人采用叠加策略对FCN的分段结果进行后处理，相比传统的FCN-8和SegNet模型具有更高的精度。</p> <p>然而，在将像素级分类算法应用到遥感影像耕地提取过程中，为了获取不同尺度区域特征，深度卷积网络往往需要将高分辨率图像转化为低分辨率图像（polling）,来提取抽象不通尺度的语义信息作为特征用于后续分类。而重采样是常用的方式之一，这个过程造成图像高分辨信息（边缘信息，梯度信息或高频噪声信号等）的丢失，使得耕地提取结果边缘模糊，细节不够丰富准确，影响最终的耕地提取精度。</p> <p>目前在全卷积网络用于像素级分类的过程中，解决高分辨率丢失问题的方法大致分为两类：1）从低分辨率表达中学习恢复高分辨率信息2）网络结构中全程保持高分辨率信息。</p> <p>第一类，从低分辨率表达中学习恢复高分辨率信息。这类方法的核心思想是移除了卷积神经网络中的全连接层，从而得到低分辨率特征图，再从低分辨率特征图中学习得到高分辨率信息估计值。例如FCN通过对低分辨率特征图进行双线性插值得到不同尺度的高分辨率特征图，再将高分辨率特征图与网络提取特征过程中得到的相应尺度的特征图进行融合，以期更好的恢复高分辨率信息。另外，采用上采样子网，如解码器，逐步恢复由下采样过程输出的低分辨率特征图的高分辨率表示，也是一种常用的方法。上采样子网可以采用与下采样过程对称的形式，其中，SegNet ^[42]^ 和DeconvNet ^[43]^ 网络通过记录下采样过程中的池化索引，然后通过对应的反池化操作来进行上采样过程 ,逐步恢复图像高分辨率信息，而U-Net ^[44]^ ，FPN网络则增加了跳跃连接过程，将下采样子网与上采样子网中相应分辨率尺度的特征图进行融合操作，进一步恢复高分辨率信息。非对称上采样过程也被广泛使用，一些研究通过采用更复杂的卷积模块来改进跳跃连接过程(C. Peng, X.,2017;Z. Zhang,2018;M. A. Islam，2017)，另外一些研究则通过堆叠多个DeconvNet/UNet/Hourglass 来不断恢复高分率信息 ^[45,46]^ 。这类方法都是通过对低分辨信息进行学习来恢复高分辨率信息，尽管采用了各种跳跃连接方式来优化得到的高分辨率信息，但从低分辨率特征图中获取高分辨率特征的本质是一个病态推算的过程，在遥感地物分类的实际应用中，很难恢复出地物原有的细节纹理。</p> <p>第二类，全程保持高分辨率信息。这类方法在整个网络过程中一直保持高分辨率信息。用来保持高分辨率信息的网络结构一般包括连接多尺度信息（从高分辨率信息到低分辨率信息）的平行结构和融合不同尺度信息的多尺度信息交换结构。代表网络有GridNet，convolutional neural fabrics，interlinked CNNds和高分辨率网络（HRNet）等。其中，较早期的两个方法，convolutional neural fabrics 和interlinked CNNs，对何时开始低分辨率并行流以及如何跨并行流交换信息缺乏谨慎设计，未取得令人满意的结果。GridNet则类似于多个U-Nets的组合，包括两个对称信息交换阶段：第一阶段仅将信息从高分辨率传递到低分辨率，第二阶段仅将信息从低分辨率传递到高分辨率，这也限制了其分割质量。HRNet设计的并行连接结构和重复的不同尺度分辨率信息的交换融合操作则更好地保留了高分辨率信息，取得了更好的结果。然而这部分模型大多应用在自然图像的像素级分类过程中，通道个数与网络深度受到限制，不利于应用到遥感多波段影像的地物分类中。</p> <p>由于卫星遥感图像成像机理和平台的不同，图像中的高分辨率特征有可能是地物的细节信号（边缘信号，纹理信号），也可能是影像的噪声信号（传感器噪声，灰土量化噪声等），如何在有效抑制噪声，尽可能的保留深度卷积网络中图像的高分辨率信号，是将卷积神经网络引入卫星遥感地物分类的重要问题。</p> <p>针对上述问题，本文从网络结构和损失函数表达两个方面入手，专注于解决原有深度卷积网络应用到遥感地物分类时存在的高分辨率信息丢失问题。本文提出的方法是在U-Net网络框架基础上，通过结合GridNet，interlinked CNNds ，HRNet等网络全程保持高分辨率信息的核心思想，改进了网络的跳跃连接结构，提出的高分辨HRU-Net网络。于此同时，在HRU-NET设置损失函数中引入深度监督的思想，进一步保留的高分辨率信息训练网络参数。本文以实验以Landsat 4-5 TM传感器为数据源，以新疆卡拉水库附件建设兵团农田为实验区，进行模型验证。该方法可以进一步推广到其他具有同物异谱地物的分类过程中，以提高精度和地物分类细节丰富度。</p> <h1 id="高分辨率u-nethru-net算法介绍">高分辨率U-Net（HRU-Net）算法介绍</h1> <p>本文提出的HRU-Net方法，保留了U-Net网络的收缩路径和扩张路径，整个网络和U-Net网络一样具有5层分辨率尺度。改进之处主要体现为两点：</p> <p>（1）采用保持高分辨率细节信息的思想，改进U-Net中跳跃连接结构。</p> <p>（2）为了更好的利用各种分辨率特征图的信息，更好的传递梯度信息来学习网络参数，设计损失函数输入时，运用了深度监督的思想。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320173848-7vym0hr.png" alt="image.png" class="rounded"/></p> <h1 id="hru-net与u-netu-net-和rf的比较">HRU-Net与U-Net，U-Net ++和RF的比较</h1> <p>本研究从三个方面比较了HRU-Net，U-Net，U-Net ++和RF的结果：（1）总体精度，（2）边缘细节的准确性，（3）类间变化的鲁棒性。</p> <p>表3.1.4和图3.1.7显示了在测试数据集上每种方法的精度评估。在这三个数据集上，HRU-Net在总体精度（Acc），Kappa系数（K）和F1-score（F1）都优于其他三个模型。</p> <p>首先，表3.1.4中的结果表明NIR和SWIR波段可以将总体精度提高1％–4％。与TM-NRG和TM-RGB数据集的结果相比，TM-All数据集的准确性最高。当将NIR添加到RF模型中时，精度提高了3.35%，这可能与模型捕获更高尺度特征（例如可能的非线性波段组合）的能力有关。但是因为深度学习模型在这个方面做得更好，所以在添加新的训练波段时，改进的效果并不明显。其次，HRU-Net在所有三个数据集中均实现了最高的提取精度。特别是在TM-All数据集上，HRU-Net的总体精度达到92.81％，与U-Net<br/> ++相比提高了1.07％，与U-Net相比提高了2.98％，与RF相比提高了16％。HRU-Net的最佳kappa系数为0.75-0.81，与U-Net<br/> ++相比增加0.01-0.02，与U-Net相比增加0.07-0.09，与RF相比增加0.33-0.50。在F1-Score中也可以发现类似的结果。</p> <p>从表3.1.4中可以看出，NIR波段和SWIR波段可以提供一些有用信息来帮助区分耕地和其他耕地，同时对于RF模型的精度提高更大（RF模型的精度提高了1％–4％）。而对于深度学习模型精度提升仅为0.4％–1％。一个可能的原因是深度学习模型具有更多的学习能力，可以提取出更深层次的特征，例如形状和梯度。另一个原因可能是在类间光谱变化较大的情况下，NIR和SWIR波段虽然可以有效地将植被和非植被像素区分开，但是对于耕地和非耕地却不太有效，因为耕地在不同时期可以有植被覆盖和无植被覆盖。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320174014-9n4bjbe.png" alt="image.png" class="rounded"/></p> <p>图3.1.7为这三个模型在TM-All数据集上的混淆矩阵。结果表明，HRU-Net模型的召回率和总体精度都是最高的。与U-Net ++，U-Net和RF相比，HRU-Net中的类型1和类型2错误也保持最低。</p> <p>表3.1.5是HRU-Net在50％，60％和70％训练集下的总体精度。正如本研究预期的那样，训练集越小，准确性将越低，但是即使在50％的训练样本，HRU-Net中的准确性也比其他两个模型下降得慢，性能要好。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320174039-m40d837.png" alt="image.png" class="rounded"/></p> <p>表3.1.6是HRU-Net，U-Net ++和U-Net训练期间的时间消耗。RF被排除在外，因为它是由CPU而不是GPU训练的；因此，它无法与其他三种基于GPU的算法相提并论。HRU-Net与原始的U-Net相比，由于通过添加更复杂的跳跃连接而涉及了更多的模型参数使得训练时间增加了约2.6倍。与U-Net ++相比，两个网络在级别相同时，参数数量相似，两者消耗的时间也相似。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320174101-kwokrwd.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.1.7 Landsat TM-All数据集的测试数据集上的HRU-Net，U-Net ++，U-Net和RF模型的混淆矩阵。</p> <h1 id="边缘细节的准确性">边缘细节的准确性</h1> <p>如图3.1.8所示，通过目视解译来评估边缘细节的准确性。与U-Net ++和U-Net相比，HRU-Net的结果具有更清晰的边缘和更丰富的细节。具体来说，与U-Net<br/> ++相比，输出中保留了更详细的边界信息，同时HRU-Net的边缘比原始U-Net的边缘准确得多，而RF的输出图中，边缘不准确，并且没有农作物覆盖的农田由于类间变化RF无法正确检测。</p> <p>图3.1.9显示不同模型的类内变化的鲁棒性。在图3.1.8中，绘制了测试数据集中每个图块的总体精度。如图3.1.9（a）所示，RF模型变化最高，因为其拟合不同谱段的泛化能力最差。图3.1.9（b）显示了HRU-Net，U-Net++，以及U-Net的变化情况，在图3.1.9（b）中，HRU-Net的变化与U-Net<br/> ++相似，但是，它在所有三个数据集中总体精度都是最高的。这表明HRU-Net在解决类内变化问题的有效性。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320174159-vph0nlp.png" alt="image.png" class="rounded"/></p> <p>图3.1.8 HRU-Net，U-Net和随机森林模型在三个数据集的输出图对比</p> <p><img src="/SIAT-GeoScience/assets/image-20220320174235-dyug82k.png" alt="image.png" class="rounded"/></p> <p><img src="/SIAT-GeoScience/assets/image-20220320174256-878bcuw.png" alt="image.png" class="rounded"/></p> <p>图3.1.9测试数据集上的总体精度分布的箱线图（868个图块）。(a)RF和深度学习算法之间的比较；(b)HRU-Net，U-Net ++和U-Net之间的比较。</p> <h1 id="结论">结论</h1> <p>本文提出的HRU-Net网络，主要是为了解决两个问题：</p> <p>（1）传统方法进行耕地提取时的同物异谱问题，这使得耕地提取时，未覆盖植被的休耕期耕地很难被提取，提取精度很低。</p> <p>（2）利用深度学习进行耕地提取时高分辨率信息丢失的问题，这不仅导致了耕地提取结果边缘模糊，细节丢失，也使得深度学习网络对于遥感图像的光谱、纹理等信息利用不充分，无法发挥遥感影像多波段、信息丰富的优势，影响最终的耕地提取精度。</p> <p>针对以上两个问题，HR-UNet在全卷积网络U-Net的基础上，保留了U-Net网络的对称编解码结构，进行了以下两方面的改进：</p> <p>（1）根据在全卷积网络中全程保持高分辨率信息的思想，改进了U-Net网络的跳跃连接结构。</p> <p>（2）为了更好的利用保留的高分辨率信息训练网络参数，在设置损失函数时采用了深度监督的思想。</p> <p>在由Landsat影像不同波段数据组成的三个数据集TMall，TMnrg和TMrgb中，使用HRU-Net，U-Net，UNet++ ^[47]^ 和Random Forest分别进行耕地提取实验后，验证了本文提出的HRU-Net网络基本达到预期目标，并能得出以下结论：</p> <p>（1）在耕地提取精度上，相比基于深度学习的U-Net,<br/> UNet++网络和传统方法Random Forest，在整体精度，混淆矩阵，kappa系数和F1-score四个评价指标中，均取得了更好的结果。</p> <p>（2）在三个数据集中，三个方法均在包含Landsat影像全6个波段的TMall数据集中取得了最好的结果，其中，HRU-Net方法表现最好，整体耕地精度达到90.61%，Kappa系数达到0.8。</p> <p>（3）在三个数据集中，传统Random<br/> Forest方法均未能准确识别出未覆盖地物的休耕期耕地，而HRU-Net方法能准确识别出所有类型的耕地，解决了耕地提取中的同物异谱问题。</p> <p>（4）在三个数据集中，HRU-Net模型相比U-Net模型的耕地结果图边缘更为清晰，细节更为丰富，与遥感影像中耕地的实际分布情况以及标签更为吻合，说明HRU-Net针对高分辨率信息丢失问题的改进取得了明显的效果。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[多光谱遥感中，由于同物异谱效应，采用传统分类方法（如支持向量机、随机森林）对类似耕地这样的复合要素（休耕、弃耕、轮种情况下的耕地光谱差异较大）提取精度较低。卷积神经网络（CNN）对同一类地物的特征类内差异容忍度较高，具有较强的泛化能力，在同物异谱情况下有望提高复合要素的提取精度。 本文从网络结构和损失函数表达两个方面入手，专注于解决原有深度卷积网络应用到遥感地物分类时存在的高分辨率信息丢失问题。本文提出的方法是在U-Net网络框架基础上，通过结合GridNet，interlinked CNNds ，HRNet等网络全程保持高分辨率信息的核心思想，改进了网络的跳跃连接结构，提出的高分辨HRU-Net网络。于此同时，在HRU-NET设置损失函数中引入深度监督的思想，进一步保留的高分辨率信息训练网络参数。本文以实验以Landsat 4-5 TM传感器为数据源，以新疆卡拉水库附件建设兵团农田为实验区，进行模型验证。该方法可以进一步推广到其他具有同物异谱地物的分类任务中，以提高精度和地物分类细节丰富度。 原文链接 Xu, W., Deng, X., Guo, S., Chen, J., Sun, L., Zheng, X., Xiong, Y., Shen, Y., &amp; Wang, X. (2020). High-Resolution U-Net : Preserving Image Details for Extraction Cultivated Land. Sensors, 20(15), 4064. (https://www.mdpi.com/1424-8220/20/15/4064/html) 研究背景 耕地作为重要的土地利用/土地覆盖类型，其数量、质量和空间分布范围关系着人类社会和经济的发展，关乎国家粮食安全问题，且与生态环境保护紧密相连。准确、快速地获取耕地信息是土地利用/土地覆盖研究领域的热点之一。遥感技术为提取耕地类型提供了更加快速、全面、准确的手段，利用遥感图像分类方法提取耕地信息，了解耕地分布、耕地类型及耕地面积等对有效管理作物种植和优化作物种植结构有重要意义。 传统的遥感分类方法（SVM, KNN, 和RF等）用于耕地提取时的难点主要有三个方面：1）耕地严重的同物异谱现象：耕地上种植的作物类型多种多样，灌溉方式和土壤类型存在差异，同时存在未覆盖地物的休耕期耕地，导致不同耕地的光谱特征差别明显，而传统的遥感分类方法，以扩大类间差距，减少类内差距为优化目标，不能很好的适应覆盖不同地物的耕地提取要求 ^[33,34]^ 。2）传统遥感分类方法采用的有限的特征，并且这些特征往往针对具体问题进行设计，特征跨地域泛化表征性不强，在研究区内训练的方法，很难在其他区域进行直接应用 ^[35,36]^ 。3）基于统计学习的传统算法，基于样点得到对象在特征空间的分布信息，算法复杂度较高，当训练样本较大时，会出现无法训练或精度饱和等现象，不适合处理大规模的遥感图像数据。 近年来，深度学习在遥感图像分类领域发展迅速 ^[37,38]^ ，主要采用的有图片级分类和像素级分类两种方法。1）图片级分类算法，该方法以单个图像为判别单元，每个图像只能包含一种地物类别，通过卷积神经网络对图像的整体特征进行学习。这类算法的核心是图像的识别，通过将整幅影像切割成包含单一地物的若干子影像后，分别对子影像中的地物进行识别。这种方法的优势在于能够较好的利用领域特征，从而提高准确识别地物的类别。但缺点是无法给出像素级的分类结果。因此目前这里方法大多使用在地物识别和提取的应用场景下。例如，Alshehhi等提出了一种卷积神经网络，从高分辨率遥感数据中提取道路和建筑物。Long等提出了一种高分辨率遥感图像的三步物体定位算法，模拟了Fast R-CNN的工作流程，实现地物要素的提取 ^[39]^ 。2）像素级分类算法，以每个像素为判别单元，采用的全卷积网络去掉了卷积神经网络中的全连接层，换成了1*1卷积层，来实现端到端（像素到像素）的分类方法。这种替换保留了图像内容的空间信息，解除了卷积神经网络对输入图像大小的限制，同时大大减少了模型参数量，提高了算法效率。其中具有代表性的有，Jamie Sherrah提出了一种不包括常规下采样层的FCN算法，在ISPRS数据集中实现了89.1%的总体精度 ^[40]^ 。Marmanis等人设计了一个像素级分割架构，合成FCN和反卷积网络，并将CRF应用于后处理以进行细化，在基于ISPRS Vaihingen数据集标签的人工数据集中取得了88.5%的总体精度 ^[41]^ 。Chen等人采用叠加策略对FCN的分段结果进行后处理，相比传统的FCN-8和SegNet模型具有更高的精度。 然而，在将像素级分类算法应用到遥感影像耕地提取过程中，为了获取不同尺度区域特征，深度卷积网络往往需要将高分辨率图像转化为低分辨率图像（polling）,来提取抽象不通尺度的语义信息作为特征用于后续分类。而重采样是常用的方式之一，这个过程造成图像高分辨信息（边缘信息，梯度信息或高频噪声信号等）的丢失，使得耕地提取结果边缘模糊，细节不够丰富准确，影响最终的耕地提取精度。 目前在全卷积网络用于像素级分类的过程中，解决高分辨率丢失问题的方法大致分为两类：1）从低分辨率表达中学习恢复高分辨率信息2）网络结构中全程保持高分辨率信息。 第一类，从低分辨率表达中学习恢复高分辨率信息。这类方法的核心思想是移除了卷积神经网络中的全连接层，从而得到低分辨率特征图，再从低分辨率特征图中学习得到高分辨率信息估计值。例如FCN通过对低分辨率特征图进行双线性插值得到不同尺度的高分辨率特征图，再将高分辨率特征图与网络提取特征过程中得到的相应尺度的特征图进行融合，以期更好的恢复高分辨率信息。另外，采用上采样子网，如解码器，逐步恢复由下采样过程输出的低分辨率特征图的高分辨率表示，也是一种常用的方法。上采样子网可以采用与下采样过程对称的形式，其中，SegNet ^[42]^ 和DeconvNet ^[43]^ 网络通过记录下采样过程中的池化索引，然后通过对应的反池化操作来进行上采样过程 ,逐步恢复图像高分辨率信息，而U-Net ^[44]^ ，FPN网络则增加了跳跃连接过程，将下采样子网与上采样子网中相应分辨率尺度的特征图进行融合操作，进一步恢复高分辨率信息。非对称上采样过程也被广泛使用，一些研究通过采用更复杂的卷积模块来改进跳跃连接过程(C. Peng, X.,2017;Z. Zhang,2018;M. A. Islam，2017)，另外一些研究则通过堆叠多个DeconvNet/UNet/Hourglass 来不断恢复高分率信息 ^[45,46]^ 。这类方法都是通过对低分辨信息进行学习来恢复高分辨率信息，尽管采用了各种跳跃连接方式来优化得到的高分辨率信息，但从低分辨率特征图中获取高分辨率特征的本质是一个病态推算的过程，在遥感地物分类的实际应用中，很难恢复出地物原有的细节纹理。 第二类，全程保持高分辨率信息。这类方法在整个网络过程中一直保持高分辨率信息。用来保持高分辨率信息的网络结构一般包括连接多尺度信息（从高分辨率信息到低分辨率信息）的平行结构和融合不同尺度信息的多尺度信息交换结构。代表网络有GridNet，convolutional neural fabrics，interlinked CNNds和高分辨率网络（HRNet）等。其中，较早期的两个方法，convolutional neural fabrics 和interlinked CNNs，对何时开始低分辨率并行流以及如何跨并行流交换信息缺乏谨慎设计，未取得令人满意的结果。GridNet则类似于多个U-Nets的组合，包括两个对称信息交换阶段：第一阶段仅将信息从高分辨率传递到低分辨率，第二阶段仅将信息从低分辨率传递到高分辨率，这也限制了其分割质量。HRNet设计的并行连接结构和重复的不同尺度分辨率信息的交换融合操作则更好地保留了高分辨率信息，取得了更好的结果。然而这部分模型大多应用在自然图像的像素级分类过程中，通道个数与网络深度受到限制，不利于应用到遥感多波段影像的地物分类中。 由于卫星遥感图像成像机理和平台的不同，图像中的高分辨率特征有可能是地物的细节信号（边缘信号，纹理信号），也可能是影像的噪声信号（传感器噪声，灰土量化噪声等），如何在有效抑制噪声，尽可能的保留深度卷积网络中图像的高分辨率信号，是将卷积神经网络引入卫星遥感地物分类的重要问题。 针对上述问题，本文从网络结构和损失函数表达两个方面入手，专注于解决原有深度卷积网络应用到遥感地物分类时存在的高分辨率信息丢失问题。本文提出的方法是在U-Net网络框架基础上，通过结合GridNet，interlinked CNNds ，HRNet等网络全程保持高分辨率信息的核心思想，改进了网络的跳跃连接结构，提出的高分辨HRU-Net网络。于此同时，在HRU-NET设置损失函数中引入深度监督的思想，进一步保留的高分辨率信息训练网络参数。本文以实验以Landsat 4-5 TM传感器为数据源，以新疆卡拉水库附件建设兵团农田为实验区，进行模型验证。该方法可以进一步推广到其他具有同物异谱地物的分类过程中，以提高精度和地物分类细节丰富度。 高分辨率U-Net（HRU-Net）算法介绍 本文提出的HRU-Net方法，保留了U-Net网络的收缩路径和扩张路径，整个网络和U-Net网络一样具有5层分辨率尺度。改进之处主要体现为两点： （1）采用保持高分辨率细节信息的思想，改进U-Net中跳跃连接结构。 （2）为了更好的利用各种分辨率特征图的信息，更好的传递梯度信息来学习网络参数，设计损失函数输入时，运用了深度监督的思想。 HRU-Net与U-Net，U-Net ++和RF的比较 本研究从三个方面比较了HRU-Net，U-Net，U-Net ++和RF的结果：（1）总体精度，（2）边缘细节的准确性，（3）类间变化的鲁棒性。 表3.1.4和图3.1.7显示了在测试数据集上每种方法的精度评估。在这三个数据集上，HRU-Net在总体精度（Acc），Kappa系数（K）和F1-score（F1）都优于其他三个模型。 首先，表3.1.4中的结果表明NIR和SWIR波段可以将总体精度提高1％–4％。与TM-NRG和TM-RGB数据集的结果相比，TM-All数据集的准确性最高。当将NIR添加到RF模型中时，精度提高了3.35%，这可能与模型捕获更高尺度特征（例如可能的非线性波段组合）的能力有关。但是因为深度学习模型在这个方面做得更好，所以在添加新的训练波段时，改进的效果并不明显。其次，HRU-Net在所有三个数据集中均实现了最高的提取精度。特别是在TM-All数据集上，HRU-Net的总体精度达到92.81％，与U-Net ++相比提高了1.07％，与U-Net相比提高了2.98％，与RF相比提高了16％。HRU-Net的最佳kappa系数为0.75-0.81，与U-Net ++相比增加0.01-0.02，与U-Net相比增加0.07-0.09，与RF相比增加0.33-0.50。在F1-Score中也可以发现类似的结果。 从表3.1.4中可以看出，NIR波段和SWIR波段可以提供一些有用信息来帮助区分耕地和其他耕地，同时对于RF模型的精度提高更大（RF模型的精度提高了1％–4％）。而对于深度学习模型精度提升仅为0.4％–1％。一个可能的原因是深度学习模型具有更多的学习能力，可以提取出更深层次的特征，例如形状和梯度。另一个原因可能是在类间光谱变化较大的情况下，NIR和SWIR波段虽然可以有效地将植被和非植被像素区分开，但是对于耕地和非耕地却不太有效，因为耕地在不同时期可以有植被覆盖和无植被覆盖。 图3.1.7为这三个模型在TM-All数据集上的混淆矩阵。结果表明，HRU-Net模型的召回率和总体精度都是最高的。与U-Net ++，U-Net和RF相比，HRU-Net中的类型1和类型2错误也保持最低。 表3.1.5是HRU-Net在50％，60％和70％训练集下的总体精度。正如本研究预期的那样，训练集越小，准确性将越低，但是即使在50％的训练样本，HRU-Net中的准确性也比其他两个模型下降得慢，性能要好。 表3.1.6是HRU-Net，U-Net ++和U-Net训练期间的时间消耗。RF被排除在外，因为它是由CPU而不是GPU训练的；因此，它无法与其他三种基于GPU的算法相提并论。HRU-Net与原始的U-Net相比，由于通过添加更复杂的跳跃连接而涉及了更多的模型参数使得训练时间增加了约2.6倍。与U-Net ++相比，两个网络在级别相同时，参数数量相似，两者消耗的时间也相似。 图3.1.7 Landsat TM-All数据集的测试数据集上的HRU-Net，U-Net ++，U-Net和RF模型的混淆矩阵。 边缘细节的准确性 如图3.1.8所示，通过目视解译来评估边缘细节的准确性。与U-Net ++和U-Net相比，HRU-Net的结果具有更清晰的边缘和更丰富的细节。具体来说，与U-Net ++相比，输出中保留了更详细的边界信息，同时HRU-Net的边缘比原始U-Net的边缘准确得多，而RF的输出图中，边缘不准确，并且没有农作物覆盖的农田由于类间变化RF无法正确检测。 图3.1.9显示不同模型的类内变化的鲁棒性。在图3.1.8中，绘制了测试数据集中每个图块的总体精度。如图3.1.9（a）所示，RF模型变化最高，因为其拟合不同谱段的泛化能力最差。图3.1.9（b）显示了HRU-Net，U-Net++，以及U-Net的变化情况，在图3.1.9（b）中，HRU-Net的变化与U-Net ++相似，但是，它在所有三个数据集中总体精度都是最高的。这表明HRU-Net在解决类内变化问题的有效性。 图3.1.8 HRU-Net，U-Net和随机森林模型在三个数据集的输出图对比 图3.1.9测试数据集上的总体精度分布的箱线图（868个图块）。(a)RF和深度学习算法之间的比较；(b)HRU-Net，U-Net ++和U-Net之间的比较。 结论 本文提出的HRU-Net网络，主要是为了解决两个问题： （1）传统方法进行耕地提取时的同物异谱问题，这使得耕地提取时，未覆盖植被的休耕期耕地很难被提取，提取精度很低。 （2）利用深度学习进行耕地提取时高分辨率信息丢失的问题，这不仅导致了耕地提取结果边缘模糊，细节丢失，也使得深度学习网络对于遥感图像的光谱、纹理等信息利用不充分，无法发挥遥感影像多波段、信息丰富的优势，影响最终的耕地提取精度。 针对以上两个问题，HR-UNet在全卷积网络U-Net的基础上，保留了U-Net网络的对称编解码结构，进行了以下两方面的改进： （1）根据在全卷积网络中全程保持高分辨率信息的思想，改进了U-Net网络的跳跃连接结构。 （2）为了更好的利用保留的高分辨率信息训练网络参数，在设置损失函数时采用了深度监督的思想。 在由Landsat影像不同波段数据组成的三个数据集TMall，TMnrg和TMrgb中，使用HRU-Net，U-Net，UNet++ ^[47]^ 和Random Forest分别进行耕地提取实验后，验证了本文提出的HRU-Net网络基本达到预期目标，并能得出以下结论： （1）在耕地提取精度上，相比基于深度学习的U-Net, UNet++网络和传统方法Random Forest，在整体精度，混淆矩阵，kappa系数和F1-score四个评价指标中，均取得了更好的结果。 （2）在三个数据集中，三个方法均在包含Landsat影像全6个波段的TMall数据集中取得了最好的结果，其中，HRU-Net方法表现最好，整体耕地精度达到90.61%，Kappa系数达到0.8。 （3）在三个数据集中，传统Random Forest方法均未能准确识别出未覆盖地物的休耕期耕地，而HRU-Net方法能准确识别出所有类型的耕地，解决了耕地提取中的同物异谱问题。 （4）在三个数据集中，HRU-Net模型相比U-Net模型的耕地结果图边缘更为清晰，细节更为丰富，与遥感影像中耕地的实际分布情况以及标签更为吻合，说明HRU-Net针对高分辨率信息丢失问题的改进取得了明显的效果。]]></summary></entry><entry><title type="html">基于对抗神经网络ISRGAN的多源遥感数据融合与超分辨模型</title><link href="https://shawnmiloguo.github.io/blog/2022/SRGAN/" rel="alternate" type="text/html" title="基于对抗神经网络ISRGAN的多源遥感数据融合与超分辨模型"/><published>2022-03-07T00:00:00+00:00</published><updated>2022-03-07T00:00:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2022/SRGAN</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2022/SRGAN/"><![CDATA[<p>为满足具体监测任务尤其是应急响应任务对时空分辨率的要求，需要对多时间、空间尺度的遥感数据进行融合。传统数据融合方法鲁棒性较低，模型无法跨区域、跨传感器应用，因此，本研究基于人工智能领域的超分辨率生成对抗网络（以下简称SRGAN），开展多尺度数据融合方法研究，提出ISRGAN影像超分辨模型。</p> <p>ISRGAN模型以超分辨率生成对抗网络SRGAN为基础，为解决SRGAN模型训练不稳定以及在跨区域和跨传感器上的迁移性不足的问题，针对性地修改了SRGAN的损失函数并对其网络结构进行了改进，使模型训练地更加稳定，在跨区域和跨传感器上有着良好的迁移能力。</p> <h1 id="原文链接">原文链接</h1> <p>Xiong, Y., Guo, S., Chen, J., Deng, X., &amp; Sun, L. (2020). Improved SRGAN for Remote Sensing Image Super-Resolution Across Locations and Sensors. Remote Sensing, 12(1263), 1–22. https://doi.org/10.3390/rs12081263</p> <h1 id="研究背景">研究背景</h1> <p>详细和准确的土地覆盖和土地利用空间变化信息是地方生态和环境研究的重要基础。对于这些任务，需要高空间分辨率图像来捕捉地球表面的时空动态变化过程 ^[1]^ 。目前获取高时空分辨率影像的方法主要有两种：1）多源影像融合模型 和2）影像超分辨率模型 。</p> <p>与图像融合模型相比，超分辨模型不需要在相近的时间内获取相同区域的高空间分辨率影像，使得这些方法在计算机视觉和遥感领域的不同场景中都具有更强的可操作性。</p> <p>图像超分辨率模型的基本假设是，如果低空间分辨率图像遵循与创建低空间分辨率图像相同的重采样过程，则可以重建或从其他高空间分辨率图像中学习到低空间分辨率图像中缺失的细节。基于这个假设，在过去的十年里，人们致力于准确地预测点扩散函数，它代表了形成低分辨率像素的混合过程。主要有三种方法：1）基于插值的方法，2）基于重构的方法，3）基于学习的方法（表 1）。</p> <p>首先，插值法是基于一定的数学策略，从相关点计算要恢复的目标点的像素值，其复杂度低，效率高。但是，得到的图像的边缘效果很明显，在插值过程中没有产生新的信息，无法恢复图像的细节。</p> <p>其次，重构法对成像过程进行建模，整合来自同一场景的不同信息，获得高质量的重构结果 。通常这些方法为了提高空间分辨率而牺牲时间分辨率，需要预先配准和大量的算力。</p> <p>第三，学习法克服了难以确定重建方法的分辨率改进倍数的限制，可以面向单一图像，这是目前超分辨率重建的主要发展方向 。在这类方法中，常用的方法有近邻嵌入法 、稀疏表示法 和深度学习法。</p> <p>表 1超分辨方法对比</p> <table> <thead> <tr> <th>方法大类</th> <th>模型</th> <th>基本思想</th> <th>优点</th> <th>缺点</th> </tr> </thead> <tbody> <tr> <td>插值法</td> <td>最近邻插值法，二次卷积法，三次卷积法</td> <td>当前像素值可以用邻近的像素表示</td> <td>复杂度低，效率高</td> <td>图像纹理细节无法预测</td> </tr> <tr> <td>重构法</td> <td>联合地图配准，PSF反卷积，稀疏回归法</td> <td>通过重建技术恢复图像物理性质和特征，使点扩散函数进一步恢复图像细节</td> <td>融合同一场景的不同信息，得到高质量重建结果</td> <td>配准需要耗费大量计算时间</td> </tr> <tr> <td>学习法</td> <td>邻域嵌入法，稀疏表达法，贝叶斯网络，SRCNN，SRGAN</td> <td>通过学习大量图像样本，创建点扩散函数</td> <td>样本数量较多时生成的图像更接近目标图像，获得更高的PSNR</td> <td>训练时间长，需要大量数据集，模型泛化能力差</td> </tr> </tbody> </table> <p>学习法通常需要高度代表性来覆盖整个总体数据变化的训练样本。在实践中，为了达到这一目的，通常需要收集大量的训练样本。但是在遥感领域，几乎不可能准备这样的训练样本集，因为遥感数据的变化不仅取决于目标的变化，还取决于不同的位置和不同的卫星传感器。由于这种限制，许多基于学习的方法都局限于某个位置和特定的传感器，导致模型跨区域和传感器的泛化能力有限。这一限制仍然给为不同区域和不同传感器训练一个超分辨率模型带来了挑战。</p> <p>近年来，随着人工智能特别是基于神经网络的深度学习方法的快速发展，深度学习对于大样本的非线性过程拟合有着明显的优势，在计算机视觉领域得到了广泛的应用。这些模型的一个优点是能够处理大样本集，同时保持良好的泛化能力。在图像超分辨率领域，2014年Dong首次提出了超分辨率的神经网络SRCNN ^[16]^ 。与传统的超分辨率图像相比，该方法取得了更高的峰值信噪比，但当图像上的采样比较高时，重建图像会过于平滑，导致细节丢失。为了克服这一不足，Ledig,<br/> C.提出了一种超分辨率生成对抗网络模型SRGAN，将原始CNN结构替换为GAN ^[17]^ 。作为深度学习领域最新的学习模型，SRGAN在捕获大样本的高维非线性特征方面显示出许多优势。然而，SRGAN模型在不同位置和不同传感器的遥感图像上的泛化能力仍然未知。</p> <p>在本研究中，验证了基于GAN的方法可以提高跨区域和传感器的泛化能力，通过一些修改，可以一次性训练，并将结果应用于不同的区域和传感器。本研究主要贡献如下：</p> <ul> <li> <p>1）在SRGAN的基础上，本文提出了ISRGAN，解决了SRGAN训练不稳定以及模型泛化能力弱的问题；</p> </li> <li> <p>2）计算模型在广东GF1数据集和新疆GF1数据集上的定量指标并进行t检验，验证了模型在跨区域上的普适性；</p> </li> <li> <p>3）计算模型在新疆GF1数据集和新疆Landsat8数据集上的定量指标并进行t检验，验证了模型在跨传感器上的普适性；</p> </li> <li> <p>4）以应用服务为目标，以遥感图像超分辨为基础，将超分辨后的遥感图像应用于土地覆盖分类和地物提取，提高分类及地物提取精度。</p> </li> </ul> <h1 id="模型跨区域和跨传感器超分辨结果分析">模型跨区域和跨传感器超分辨结果分析</h1> <p>基于广东高分1号数据集上训练的ISRGAN超分辨模型，我们分别迁移到新疆高分1号数据集、新疆Landsat8数据集上进行模型的跨区域，跨传感器测试。测试部分结果分别如图2.1.2~图2.1.4所示。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320170737-s85vdps.png" alt="image.png" class="rounded"/></p> <p>图 2.1.2在广东训练完成的ISRGAN模型在广东本地GF1数据集超分辨率测试结果（a）输入的图像；（b）超分辨图像；（c）地面真值；（d）（e）（f）分别表示超分辨图像真实图像在红、绿和蓝三波段1:1灰度图，斜率分别为1.0063，1.0032和0.9955。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320170817-bmbxu9t.png" alt="image.png" class="rounded"/></p> <p>图 2.1.3模型跨区域检验：在广东训练完成的ISRGAN模型直接迁移到新疆GF1数据集超分辨率测试结果（a）输入的图像；（b）超分辨图像；（c）地面真值；（d）（e）（f）分别表示超分辨图像真实图像在红、绿和蓝三波段1:1灰度图，斜率分别为0.9658，0.9378和0.9485。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320170844-0s7hyrz.png" alt="image.png" class="rounded"/></p> <p>图2.1.4模型跨传感器检验：将广东训练完成的ISRGAN模型在直接迁移到新疆Landsat数据集的超分辨率测试结果（a）输入的图像；（b）超分辨图像；（c）地面真值；（d）（e）（f）分别表示超分辨图像真实图像在红、绿和蓝三波段1:1灰度图，斜率分别为0.9527，0.9564和0.9760。</p> <h1 id="与传统超分辨模型对比试验">与传统超分辨模型对比试验</h1> <p>本文主要对比了超分辨领域经典方法领域嵌入法及稀疏表达法，根据相应的超分辨结果，计算其与原始图像的定量化指标，在本文中，由于同一时间同一场景下的Landsat8卫星数据和高分一号卫星数据很难获取，而且其对应的像元个数不一致，考虑到后续在验证模型在跨区域和跨传感器上的普适性上计算标准的一致性，故本文的所有定量计算的参考影像均为超分辨之前的原始影像，计算方法为将超分辨后的影像进行相应的降采样处理，再计算其与原始影像的量化指标。图2.1.5展示了本文基于ISRGAN方法和领域嵌入法、稀疏表达法及SRGAN在3个测试集中测试的部分对比结。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320171422-tfhuzi7.png" alt="image.png" class="rounded"/></p> <h1 id="结论">结论</h1> <p>本文以生成对抗网络在计算机视觉上的超分辨算法为基础，针对生成对抗网络本身在训练时存在的梯度消失和模式崩坏等问题，结合WGAN中所提出的最小化Wasserstein距离的方法，对原始超分辨网络（SRGAN）进行修改，提出了ISRGAN网络，并将其应用在遥感影像超分辨上，主要得出以下结论：</p> <p>（1）本文所提出的ISRGAN超分辨网络，将其应用在遥感影像超分辨上，所取得的效果在定量指标上要优于领域嵌入法及稀疏表达法等传统影像超分辨方法。</p> <p>（2）为了实现超分辨模型的一次训练，多次使用，我们直接将在用广东高分1影像数据训练的模型应用在新疆高分1影像数据，并对两组数据集超分辨结果的定量指标做t检验，验证了超分辨模型在跨区域上具有普适性。</p> <p>（3）为了结合国产高分1影像数据与Landsat8影像数据各自的优势，本文将在高分1数据上训练的超分辨模型直接应用在Landsat8数据，并对超分辨结果的定量指标做t检验，验证了超分辨模型在跨传感器上具有普适性。</p> <p>（4）以土地利用分类和地物提取为例，对比Landsat8影像超分辨前后的分类和提取精度，其中土地利用分类采用K-means聚类算法，地物提取使用SVM算法。结果表明，超分辨影像在分类和地物提取的目视效果及精度均有明显提高，表明遥感影像超分辨在资源开发、环境监测、灾害研究和全球变化分析等方面极具应用价值。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[为满足具体监测任务尤其是应急响应任务对时空分辨率的要求，需要对多时间、空间尺度的遥感数据进行融合。传统数据融合方法鲁棒性较低，模型无法跨区域、跨传感器应用，因此，本研究基于人工智能领域的超分辨率生成对抗网络（以下简称SRGAN），开展多尺度数据融合方法研究，提出ISRGAN影像超分辨模型。 ISRGAN模型以超分辨率生成对抗网络SRGAN为基础，为解决SRGAN模型训练不稳定以及在跨区域和跨传感器上的迁移性不足的问题，针对性地修改了SRGAN的损失函数并对其网络结构进行了改进，使模型训练地更加稳定，在跨区域和跨传感器上有着良好的迁移能力。 原文链接 Xiong, Y., Guo, S., Chen, J., Deng, X., &amp; Sun, L. (2020). Improved SRGAN for Remote Sensing Image Super-Resolution Across Locations and Sensors. Remote Sensing, 12(1263), 1–22. https://doi.org/10.3390/rs12081263 研究背景 详细和准确的土地覆盖和土地利用空间变化信息是地方生态和环境研究的重要基础。对于这些任务，需要高空间分辨率图像来捕捉地球表面的时空动态变化过程 ^[1]^ 。目前获取高时空分辨率影像的方法主要有两种：1）多源影像融合模型 和2）影像超分辨率模型 。 与图像融合模型相比，超分辨模型不需要在相近的时间内获取相同区域的高空间分辨率影像，使得这些方法在计算机视觉和遥感领域的不同场景中都具有更强的可操作性。 图像超分辨率模型的基本假设是，如果低空间分辨率图像遵循与创建低空间分辨率图像相同的重采样过程，则可以重建或从其他高空间分辨率图像中学习到低空间分辨率图像中缺失的细节。基于这个假设，在过去的十年里，人们致力于准确地预测点扩散函数，它代表了形成低分辨率像素的混合过程。主要有三种方法：1）基于插值的方法，2）基于重构的方法，3）基于学习的方法（表 1）。 首先，插值法是基于一定的数学策略，从相关点计算要恢复的目标点的像素值，其复杂度低，效率高。但是，得到的图像的边缘效果很明显，在插值过程中没有产生新的信息，无法恢复图像的细节。 其次，重构法对成像过程进行建模，整合来自同一场景的不同信息，获得高质量的重构结果 。通常这些方法为了提高空间分辨率而牺牲时间分辨率，需要预先配准和大量的算力。 第三，学习法克服了难以确定重建方法的分辨率改进倍数的限制，可以面向单一图像，这是目前超分辨率重建的主要发展方向 。在这类方法中，常用的方法有近邻嵌入法 、稀疏表示法 和深度学习法。 表 1超分辨方法对比 方法大类 模型 基本思想 优点 缺点 插值法 最近邻插值法，二次卷积法，三次卷积法 当前像素值可以用邻近的像素表示 复杂度低，效率高 图像纹理细节无法预测 重构法 联合地图配准，PSF反卷积，稀疏回归法 通过重建技术恢复图像物理性质和特征，使点扩散函数进一步恢复图像细节 融合同一场景的不同信息，得到高质量重建结果 配准需要耗费大量计算时间 学习法 邻域嵌入法，稀疏表达法，贝叶斯网络，SRCNN，SRGAN 通过学习大量图像样本，创建点扩散函数 样本数量较多时生成的图像更接近目标图像，获得更高的PSNR 训练时间长，需要大量数据集，模型泛化能力差 学习法通常需要高度代表性来覆盖整个总体数据变化的训练样本。在实践中，为了达到这一目的，通常需要收集大量的训练样本。但是在遥感领域，几乎不可能准备这样的训练样本集，因为遥感数据的变化不仅取决于目标的变化，还取决于不同的位置和不同的卫星传感器。由于这种限制，许多基于学习的方法都局限于某个位置和特定的传感器，导致模型跨区域和传感器的泛化能力有限。这一限制仍然给为不同区域和不同传感器训练一个超分辨率模型带来了挑战。 近年来，随着人工智能特别是基于神经网络的深度学习方法的快速发展，深度学习对于大样本的非线性过程拟合有着明显的优势，在计算机视觉领域得到了广泛的应用。这些模型的一个优点是能够处理大样本集，同时保持良好的泛化能力。在图像超分辨率领域，2014年Dong首次提出了超分辨率的神经网络SRCNN ^[16]^ 。与传统的超分辨率图像相比，该方法取得了更高的峰值信噪比，但当图像上的采样比较高时，重建图像会过于平滑，导致细节丢失。为了克服这一不足，Ledig, C.提出了一种超分辨率生成对抗网络模型SRGAN，将原始CNN结构替换为GAN ^[17]^ 。作为深度学习领域最新的学习模型，SRGAN在捕获大样本的高维非线性特征方面显示出许多优势。然而，SRGAN模型在不同位置和不同传感器的遥感图像上的泛化能力仍然未知。 在本研究中，验证了基于GAN的方法可以提高跨区域和传感器的泛化能力，通过一些修改，可以一次性训练，并将结果应用于不同的区域和传感器。本研究主要贡献如下： 1）在SRGAN的基础上，本文提出了ISRGAN，解决了SRGAN训练不稳定以及模型泛化能力弱的问题； 2）计算模型在广东GF1数据集和新疆GF1数据集上的定量指标并进行t检验，验证了模型在跨区域上的普适性； 3）计算模型在新疆GF1数据集和新疆Landsat8数据集上的定量指标并进行t检验，验证了模型在跨传感器上的普适性； 4）以应用服务为目标，以遥感图像超分辨为基础，将超分辨后的遥感图像应用于土地覆盖分类和地物提取，提高分类及地物提取精度。 模型跨区域和跨传感器超分辨结果分析 基于广东高分1号数据集上训练的ISRGAN超分辨模型，我们分别迁移到新疆高分1号数据集、新疆Landsat8数据集上进行模型的跨区域，跨传感器测试。测试部分结果分别如图2.1.2~图2.1.4所示。 图 2.1.2在广东训练完成的ISRGAN模型在广东本地GF1数据集超分辨率测试结果（a）输入的图像；（b）超分辨图像；（c）地面真值；（d）（e）（f）分别表示超分辨图像真实图像在红、绿和蓝三波段1:1灰度图，斜率分别为1.0063，1.0032和0.9955。 图 2.1.3模型跨区域检验：在广东训练完成的ISRGAN模型直接迁移到新疆GF1数据集超分辨率测试结果（a）输入的图像；（b）超分辨图像；（c）地面真值；（d）（e）（f）分别表示超分辨图像真实图像在红、绿和蓝三波段1:1灰度图，斜率分别为0.9658，0.9378和0.9485。 图2.1.4模型跨传感器检验：将广东训练完成的ISRGAN模型在直接迁移到新疆Landsat数据集的超分辨率测试结果（a）输入的图像；（b）超分辨图像；（c）地面真值；（d）（e）（f）分别表示超分辨图像真实图像在红、绿和蓝三波段1:1灰度图，斜率分别为0.9527，0.9564和0.9760。 与传统超分辨模型对比试验 本文主要对比了超分辨领域经典方法领域嵌入法及稀疏表达法，根据相应的超分辨结果，计算其与原始图像的定量化指标，在本文中，由于同一时间同一场景下的Landsat8卫星数据和高分一号卫星数据很难获取，而且其对应的像元个数不一致，考虑到后续在验证模型在跨区域和跨传感器上的普适性上计算标准的一致性，故本文的所有定量计算的参考影像均为超分辨之前的原始影像，计算方法为将超分辨后的影像进行相应的降采样处理，再计算其与原始影像的量化指标。图2.1.5展示了本文基于ISRGAN方法和领域嵌入法、稀疏表达法及SRGAN在3个测试集中测试的部分对比结。 结论 本文以生成对抗网络在计算机视觉上的超分辨算法为基础，针对生成对抗网络本身在训练时存在的梯度消失和模式崩坏等问题，结合WGAN中所提出的最小化Wasserstein距离的方法，对原始超分辨网络（SRGAN）进行修改，提出了ISRGAN网络，并将其应用在遥感影像超分辨上，主要得出以下结论： （1）本文所提出的ISRGAN超分辨网络，将其应用在遥感影像超分辨上，所取得的效果在定量指标上要优于领域嵌入法及稀疏表达法等传统影像超分辨方法。 （2）为了实现超分辨模型的一次训练，多次使用，我们直接将在用广东高分1影像数据训练的模型应用在新疆高分1影像数据，并对两组数据集超分辨结果的定量指标做t检验，验证了超分辨模型在跨区域上具有普适性。 （3）为了结合国产高分1影像数据与Landsat8影像数据各自的优势，本文将在高分1数据上训练的超分辨模型直接应用在Landsat8数据，并对超分辨结果的定量指标做t检验，验证了超分辨模型在跨传感器上具有普适性。 （4）以土地利用分类和地物提取为例，对比Landsat8影像超分辨前后的分类和提取精度，其中土地利用分类采用K-means聚类算法，地物提取使用SVM算法。结果表明，超分辨影像在分类和地物提取的目视效果及精度均有明显提高，表明遥感影像超分辨在资源开发、环境监测、灾害研究和全球变化分析等方面极具应用价值。]]></summary></entry></feed>