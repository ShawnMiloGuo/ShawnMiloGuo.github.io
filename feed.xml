<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="cn"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://shawnmiloguo.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://shawnmiloguo.github.io/" rel="alternate" type="text/html" hreflang="cn"/><updated>2025-03-19T14:19:32+00:00</updated><id>https://shawnmiloguo.github.io/feed.xml</id><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://shawnmiloguo.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[<p>May 14, 2024[[read-time]] min read We’re introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants. In December, we launched our first natively multimodal model Gemini 1.0 in three sizes: Ultra, Pro and Nano. Just a few months later we released 1.5 Pro, with enhanced performance and a breakthrough long context window of 1 million tokens.Developers and enterprise customers have been putting 1.5 Pro to use in incredible ways and finding its long context window, multimodal reasoning capabilities and impressive overall performance incredibly useful.We know from user feedback that some applications need lower latency and a lower cost to serve. This inspired us to keep innovating, so today, we’re introducing Gemini 1.5 Flash: a model that’s lighter-weight than 1.5 Pro, and designed to be fast and efficient to serve at scale.Both 1.5 Pro and 1.5 Flash are available in public preview with a 1 million token context window in Google AI Studio and Vertex AI. And now, 1.5 Pro is also available with a 2 million token context window via waitlist to developers using the API and to Google Cloud customers.We’re also introducing updates across the Gemini family of models, announcing our next generation of open models, Gemma 2, and sharing progress on the future of AI assistants, with Project Astra.Context lengths of leading foundation models compared with Gemini 1.5’s 2 million token capability1.5 Flash is the newest addition to the Gemini model family and the fastest Gemini model served in the API. It’s optimized for high-volume, high-frequency tasks at scale, is more cost-efficient to serve and features our breakthrough long context window.While it’s a lighter weight model than 1.5 Pro, it’s highly capable of multimodal reasoning across vast amounts of information and delivers impressive quality for its size.The new Gemini 1.5 Flash model is optimized for speed and efficiency, is highly capable of multimodal reasoning and features our breakthrough long context window.1.5 Flash excels at summarization, chat applications, image and video captioning, data extraction from long documents and tables, and more. This is because it’s been trained by 1.5 Pro through a process called “distillation,” where the most essential knowledge and skills from a larger model are transferred to a smaller, more efficient model.Read more about 1.5 Flash in our updated Gemini 1.5 technical report, on the Gemini technology page, and learn about 1.5 Flash’s availability and pricing.Over the last few months, we’ve significantly improved 1.5 Pro, our best model for general performance across a wide range of tasks.Beyond extending its context window to 2 million tokens, we’ve enhanced its code generation, logical reasoning and planning, multi-turn conversation, and audio and image understanding through data and algorithmic advances. We see strong improvements on public and internal benchmarks for each of these tasks.1.5 Pro can now follow increasingly complex and nuanced instructions, including ones that specify product-level behavior involving role, format and style. We’ve improved control over the model’s responses for specific use cases, like crafting the persona and response style of a chat agent or automating workflows through multiple function calls. And we’ve enabled users to steer model behavior by setting system instructions.We added audio understanding in the Gemini API and Google AI Studio, so 1.5 Pro can now reason across image and audio for videos uploaded in Google AI Studio. And we’re now integrating 1.5 Pro into Google products, including Gemini Advanced and in Workspace apps.Read more about 1.5 Pro in our updated Gemini 1.5 technical report and on the Gemini technology page.Gemini Nano is expanding beyond text-only inputs to include images as well. Starting with Pixel, applications using Gemini Nano with Multimodality will be able to understand the world the way people do — not just through text, but also through sight, sound and spoken language.Read more about Gemini 1.0 Nano on Android.Today, we’re also sharing a series of updates to Gemma, our family of open models built from the same research and technology used to create the Gemini models.We’re announcing Gemma 2, our next generation of open models for responsible AI innovation. Gemma 2 has a new architecture designed for breakthrough performance and efficiency, and will be available in new sizes.The Gemma family is also expanding with PaliGemma, our first vision-language model inspired by PaLI-3. And we’ve upgraded our Responsible Generative AI Toolkit with LLM Comparator for evaluating the quality of model responses.Read more on the Developer blog.As part of Google DeepMind’s mission to build AI responsibly to benefit humanity, we’ve always wanted to develop universal AI agents that can be helpful in everyday life. That’s why today, we’re sharing our progress in building the future of AI assistants with Project Astra (advanced seeing and talking responsive agent).To be truly useful, an agent needs to understand and respond to the complex and dynamic world just like people do — and take in and remember what it sees and hears to understand context and take action. It also needs to be proactive, teachable and personal, so users can talk to it naturally and without lag or delay.While we’ve made incredible progress developing AI systems that can understand multimodal information, getting response time down to something conversational is a difficult engineering challenge. Over the past few years, we’ve been working to improve how our models perceive, reason and converse to make the pace and quality of interaction feel more natural.Building on Gemini, we’ve developed prototype agents that can process information faster by continuously encoding video frames, combining the video and speech input into a timeline of events, and caching this information for efficient recall.By leveraging our leading speech models, we also enhanced how they sound, giving the agents a wider range of intonations. These agents can better understand the context they’re being used in, and respond quickly, in conversation.With technology like this, it’s easy to envision a future where people could have an expert AI assistant by their side, through a phone or glasses. And some of these capabilities are coming to Google products, like the Gemini app and web experience, later this year.We’ve made incredible progress so far with our family of Gemini models, and we’re always striving to advance the state-of-the-art even further. By investing in a relentless production line of innovation, we’re able to explore new ideas at the frontier, while also unlocking the possibility of new and exciting Gemini use cases.Learn more about Gemini and its capabilities. Your information will be used in accordance with Google’s privacy policy.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      Done. Just one step more.
    
      Check your inbox to confirm your subscription.
    You are already subscribed to our newsletter.
    You can also subscribe with a
    different email address
    
    .
    
  Let’s stay in touch. Get the latest news from Google in your inbox.
          Follow Us
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://shawnmiloguo.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://shawnmiloguo.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[<h3>External Posts on Your al-folio Blog</h3> <p>If you prefer publishing blog posts on medium.com or other external sources, starting version v0.5.0, <a href="https://github.com/alshedivat/al-folio">al-folio</a> lets you to display your external posts in the blog feed of your website! 🎉🎉</p> <p>Configuring external sources of super simple. After upgrading to v0.5.0, just add the following section to your _config.yml:</p> <pre>external_sources:<br />  - name: medium.com  # name of the source (arbitrary string)<br />    rss_url: <a href="https://medium.com/@al-folio/feed">https://medium.com/@&lt;your-medium-username&gt;/feed</a></pre> <p>The example above adds your medium.com blog post feed as an external source. But you can add arbitrary RSS feeds as sources.</p> <p>Any questions or suggestions? 👉 Start <a href="https://github.com/alshedivat/al-folio/discussions">a discussion on GitHub</a>!</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b60a1d241a0a" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">基于HRU-Net的中高分辨率地表要素提取模型</title><link href="https://shawnmiloguo.github.io/blog/2022/HRUNET/" rel="alternate" type="text/html" title="基于HRU-Net的中高分辨率地表要素提取模型"/><published>2022-01-08T00:00:00+00:00</published><updated>2022-01-08T00:00:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2022/HRUNET</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2022/HRUNET/"><![CDATA[<p>多光谱遥感中，由于同物异谱效应，采用传统分类方法（如支持向量机、随机森林）对类似耕地这样的复合要素（休耕、弃耕、轮种情况下的耕地光谱差异较大）提取精度较低。卷积神经网络（CNN）对同一类地物的特征类内差异容忍度较高，具有较强的泛化能力，在同物异谱情况下有望提高复合要素的提取精度。 </p> <p>本文从网络结构和损失函数表达两个方面入手，专注于解决原有深度卷积网络应用到遥感地物分类时存在的高分辨率信息丢失问题。本文提出的方法是在U-Net网络框架基础上，通过结合GridNet，interlinked CNNds ，HRNet等网络全程保持高分辨率信息的核心思想，改进了网络的跳跃连接结构，提出的高分辨HRU-Net网络。于此同时，在HRU-NET设置损失函数中引入深度监督的思想，进一步保留的高分辨率信息训练网络参数。本文以实验以Landsat<br/> 4-5 TM传感器为数据源，以新疆卡拉水库附件建设兵团农田为实验区，进行模型验证。该方法可以进一步推广到其他具有同物异谱地物的分类任务中，以提高精度和地物分类细节丰富度。</p> <h1 id="原文连接">原文连接</h1> <p>Xu, W., Deng, X., Guo, S., Chen, J., Sun, L., Zheng, X., Xiong, Y., Shen, Y., &amp; Wang, X. (2020). High-Resolution U-Net : Preserving Image Details for Extraction Cultivated Land. Sensors, 20(15), 4064.</p> <p>(https://www.mdpi.com/1424-8220/20/15/4064/html)</p> <h1 id="研究背景">研究背景</h1> <p>耕地作为重要的土地利用/土地覆盖类型，其数量、质量和空间分布范围关系着人类社会和经济的发展，关乎国家粮食安全问题，且与生态环境保护紧密相连。准确、快速地获取耕地信息是土地利用/土地覆盖研究领域的热点之一。遥感技术为提取耕地类型提供了更加快速、全面、准确的手段，利用遥感图像分类方法提取耕地信息，了解耕地分布、耕地类型及耕地面积等对有效管理作物种植和优化作物种植结构有重要意义。</p> <p>传统的遥感分类方法（SVM, KNN, 和RF等）用于耕地提取时的难点主要有三个方面：1）耕地严重的同物异谱现象：耕地上种植的作物类型多种多样，灌溉方式和土壤类型存在差异，同时存在未覆盖地物的休耕期耕地，导致不同耕地的光谱特征差别明显，而传统的遥感分类方法，以扩大类间差距，减少类内差距为优化目标，不能很好的适应覆盖不同地物的耕地提取要求 ^[33,34]^ 。2）传统遥感分类方法采用的有限的特征，并且这些特征往往针对具体问题进行设计，特征跨地域泛化表征性不强，在研究区内训练的方法，很难在其他区域进行直接应用 ^[35,36]^ 。3）基于统计学习的传统算法，基于样点得到对象在特征空间的分布信息，算法复杂度较高，当训练样本较大时，会出现无法训练或精度饱和等现象，不适合处理大规模的遥感图像数据。</p> <p>近年来，深度学习在遥感图像分类领域发展迅速 ^[37,38]^ ，主要采用的有图片级分类和像素级分类两种方法。1）图片级分类算法，该方法以单个图像为判别单元，每个图像只能包含一种地物类别，通过卷积神经网络对图像的整体特征进行学习。这类算法的核心是图像的识别，通过将整幅影像切割成包含单一地物的若干子影像后，分别对子影像中的地物进行识别。这种方法的优势在于能够较好的利用领域特征，从而提高准确识别地物的类别。但缺点是无法给出像素级的分类结果。因此目前这里方法大多使用在地物识别和提取的应用场景下。例如，Alshehhi等提出了一种卷积神经网络，从高分辨率遥感数据中提取道路和建筑物。Long等提出了一种高分辨率遥感图像的三步物体定位算法，模拟了Fast R-CNN的工作流程，实现地物要素的提取 ^[39]^ 。2）像素级分类算法，以每个像素为判别单元，采用的全卷积网络去掉了卷积神经网络中的全连接层，换成了1*1卷积层，来实现端到端（像素到像素）的分类方法。这种替换保留了图像内容的空间信息，解除了卷积神经网络对输入图像大小的限制，同时大大减少了模型参数量，提高了算法效率。其中具有代表性的有，Jamie Sherrah提出了一种不包括常规下采样层的FCN算法，在ISPRS数据集中实现了89.1%的总体精度 ^[40]^ 。Marmanis等人设计了一个像素级分割架构，合成FCN和反卷积网络，并将CRF应用于后处理以进行细化，在基于ISPRS Vaihingen数据集标签的人工数据集中取得了88.5%的总体精度 ^[41]^ 。Chen等人采用叠加策略对FCN的分段结果进行后处理，相比传统的FCN-8和SegNet模型具有更高的精度。</p> <p>然而，在将像素级分类算法应用到遥感影像耕地提取过程中，为了获取不同尺度区域特征，深度卷积网络往往需要将高分辨率图像转化为低分辨率图像（polling）,来提取抽象不通尺度的语义信息作为特征用于后续分类。而重采样是常用的方式之一，这个过程造成图像高分辨信息（边缘信息，梯度信息或高频噪声信号等）的丢失，使得耕地提取结果边缘模糊，细节不够丰富准确，影响最终的耕地提取精度。</p> <p>目前在全卷积网络用于像素级分类的过程中，解决高分辨率丢失问题的方法大致分为两类：1）从低分辨率表达中学习恢复高分辨率信息2）网络结构中全程保持高分辨率信息。</p> <p>第一类，从低分辨率表达中学习恢复高分辨率信息。这类方法的核心思想是移除了卷积神经网络中的全连接层，从而得到低分辨率特征图，再从低分辨率特征图中学习得到高分辨率信息估计值。例如FCN通过对低分辨率特征图进行双线性插值得到不同尺度的高分辨率特征图，再将高分辨率特征图与网络提取特征过程中得到的相应尺度的特征图进行融合，以期更好的恢复高分辨率信息。另外，采用上采样子网，如解码器，逐步恢复由下采样过程输出的低分辨率特征图的高分辨率表示，也是一种常用的方法。上采样子网可以采用与下采样过程对称的形式，其中，SegNet ^[42]^ 和DeconvNet ^[43]^ 网络通过记录下采样过程中的池化索引，然后通过对应的反池化操作来进行上采样过程 ,逐步恢复图像高分辨率信息，而U-Net ^[44]^ ，FPN网络则增加了跳跃连接过程，将下采样子网与上采样子网中相应分辨率尺度的特征图进行融合操作，进一步恢复高分辨率信息。非对称上采样过程也被广泛使用，一些研究通过采用更复杂的卷积模块来改进跳跃连接过程(C. Peng, X.,2017;Z. Zhang,2018;M. A. Islam，2017)，另外一些研究则通过堆叠多个DeconvNet/UNet/Hourglass 来不断恢复高分率信息 ^[45,46]^ 。这类方法都是通过对低分辨信息进行学习来恢复高分辨率信息，尽管采用了各种跳跃连接方式来优化得到的高分辨率信息，但从低分辨率特征图中获取高分辨率特征的本质是一个病态推算的过程，在遥感地物分类的实际应用中，很难恢复出地物原有的细节纹理。</p> <p>第二类，全程保持高分辨率信息。这类方法在整个网络过程中一直保持高分辨率信息。用来保持高分辨率信息的网络结构一般包括连接多尺度信息（从高分辨率信息到低分辨率信息）的平行结构和融合不同尺度信息的多尺度信息交换结构。代表网络有GridNet，convolutional neural fabrics，interlinked CNNds和高分辨率网络（HRNet）等。其中，较早期的两个方法，convolutional neural fabrics 和interlinked CNNs，对何时开始低分辨率并行流以及如何跨并行流交换信息缺乏谨慎设计，未取得令人满意的结果。GridNet则类似于多个U-Nets的组合，包括两个对称信息交换阶段：第一阶段仅将信息从高分辨率传递到低分辨率，第二阶段仅将信息从低分辨率传递到高分辨率，这也限制了其分割质量。HRNet设计的并行连接结构和重复的不同尺度分辨率信息的交换融合操作则更好地保留了高分辨率信息，取得了更好的结果。然而这部分模型大多应用在自然图像的像素级分类过程中，通道个数与网络深度受到限制，不利于应用到遥感多波段影像的地物分类中。</p> <p>由于卫星遥感图像成像机理和平台的不同，图像中的高分辨率特征有可能是地物的细节信号（边缘信号，纹理信号），也可能是影像的噪声信号（传感器噪声，灰土量化噪声等），如何在有效抑制噪声，尽可能的保留深度卷积网络中图像的高分辨率信号，是将卷积神经网络引入卫星遥感地物分类的重要问题。</p> <p>针对上述问题，本文从网络结构和损失函数表达两个方面入手，专注于解决原有深度卷积网络应用到遥感地物分类时存在的高分辨率信息丢失问题。本文提出的方法是在U-Net网络框架基础上，通过结合GridNet，interlinked CNNds ，HRNet等网络全程保持高分辨率信息的核心思想，改进了网络的跳跃连接结构，提出的高分辨HRU-Net网络。于此同时，在HRU-NET设置损失函数中引入深度监督的思想，进一步保留的高分辨率信息训练网络参数。本文以实验以Landsat 4-5 TM传感器为数据源，以新疆卡拉水库附件建设兵团农田为实验区，进行模型验证。该方法可以进一步推广到其他具有同物异谱地物的分类过程中，以提高精度和地物分类细节丰富度。</p> <h1 id="高分辨率u-nethru-net算法介绍">高分辨率U-Net（HRU-Net）算法介绍</h1> <p>本文提出的HRU-Net方法，保留了U-Net网络的收缩路径和扩张路径，整个网络和U-Net网络一样具有5层分辨率尺度。改进之处主要体现为两点：</p> <p>（1）采用保持高分辨率细节信息的思想，改进U-Net中跳跃连接结构。</p> <p>（2）为了更好的利用各种分辨率特征图的信息，更好的传递梯度信息来学习网络参数，设计损失函数输入时，运用了深度监督的思想。</p> <p><img src="/assets/img/postImages/image-20220320173848-7vym0hr.png" alt="image.png" class="rounded"/></p> <h1 id="hru-net与u-netu-net-和rf的比较">HRU-Net与U-Net，U-Net ++和RF的比较</h1> <p>本研究从三个方面比较了HRU-Net，U-Net，U-Net ++和RF的结果：（1）总体精度，（2）边缘细节的准确性，（3）类间变化的鲁棒性。</p> <p>表3.1.4和图3.1.7显示了在测试数据集上每种方法的精度评估。在这三个数据集上，HRU-Net在总体精度（Acc），Kappa系数（K）和F1-score（F1）都优于其他三个模型。</p> <p>首先，表3.1.4中的结果表明NIR和SWIR波段可以将总体精度提高1％–4％。与TM-NRG和TM-RGB数据集的结果相比，TM-All数据集的准确性最高。当将NIR添加到RF模型中时，精度提高了3.35%，这可能与模型捕获更高尺度特征（例如可能的非线性波段组合）的能力有关。但是因为深度学习模型在这个方面做得更好，所以在添加新的训练波段时，改进的效果并不明显。其次，HRU-Net在所有三个数据集中均实现了最高的提取精度。特别是在TM-All数据集上，HRU-Net的总体精度达到92.81％，与U-Net<br/> ++相比提高了1.07％，与U-Net相比提高了2.98％，与RF相比提高了16％。HRU-Net的最佳kappa系数为0.75-0.81，与U-Net<br/> ++相比增加0.01-0.02，与U-Net相比增加0.07-0.09，与RF相比增加0.33-0.50。在F1-Score中也可以发现类似的结果。</p> <p>从表3.1.4中可以看出，NIR波段和SWIR波段可以提供一些有用信息来帮助区分耕地和其他耕地，同时对于RF模型的精度提高更大（RF模型的精度提高了1％–4％）。而对于深度学习模型精度提升仅为0.4％–1％。一个可能的原因是深度学习模型具有更多的学习能力，可以提取出更深层次的特征，例如形状和梯度。另一个原因可能是在类间光谱变化较大的情况下，NIR和SWIR波段虽然可以有效地将植被和非植被像素区分开，但是对于耕地和非耕地却不太有效，因为耕地在不同时期可以有植被覆盖和无植被覆盖。</p> <p><img src="/assets/img/postImages/image-20220320174014-9n4bjbe.png" alt="image.png" class="rounded"/></p> <p>图3.1.7为这三个模型在TM-All数据集上的混淆矩阵。结果表明，HRU-Net模型的召回率和总体精度都是最高的。与U-Net ++，U-Net和RF相比，HRU-Net中的类型1和类型2错误也保持最低。</p> <p>表3.1.5是HRU-Net在50％，60％和70％训练集下的总体精度。正如本研究预期的那样，训练集越小，准确性将越低，但是即使在50％的训练样本，HRU-Net中的准确性也比其他两个模型下降得慢，性能要好。</p> <p><img src="/assets/img/postImages/image-20220320174039-m40d837.png" alt="image.png" class="rounded"/></p> <p>表3.1.6是HRU-Net，U-Net ++和U-Net训练期间的时间消耗。RF被排除在外，因为它是由CPU而不是GPU训练的；因此，它无法与其他三种基于GPU的算法相提并论。HRU-Net与原始的U-Net相比，由于通过添加更复杂的跳跃连接而涉及了更多的模型参数使得训练时间增加了约2.6倍。与U-Net ++相比，两个网络在级别相同时，参数数量相似，两者消耗的时间也相似。</p> <p><img src="/assets/img/postImages/image-20220320174101-kwokrwd.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.1.7 Landsat TM-All数据集的测试数据集上的HRU-Net，U-Net ++，U-Net和RF模型的混淆矩阵。</p> <h1 id="边缘细节的准确性">边缘细节的准确性</h1> <p>如图3.1.8所示，通过目视解译来评估边缘细节的准确性。与U-Net ++和U-Net相比，HRU-Net的结果具有更清晰的边缘和更丰富的细节。具体来说，与U-Net<br/> ++相比，输出中保留了更详细的边界信息，同时HRU-Net的边缘比原始U-Net的边缘准确得多，而RF的输出图中，边缘不准确，并且没有农作物覆盖的农田由于类间变化RF无法正确检测。</p> <p>图3.1.9显示不同模型的类内变化的鲁棒性。在图3.1.8中，绘制了测试数据集中每个图块的总体精度。如图3.1.9（a）所示，RF模型变化最高，因为其拟合不同谱段的泛化能力最差。图3.1.9（b）显示了HRU-Net，U-Net++，以及U-Net的变化情况，在图3.1.9（b）中，HRU-Net的变化与U-Net<br/> ++相似，但是，它在所有三个数据集中总体精度都是最高的。这表明HRU-Net在解决类内变化问题的有效性。</p> <p><img src="/assets/img/postImages/image-20220320174159-vph0nlp.png" alt="image.png" class="rounded"/></p> <p>图3.1.8 HRU-Net，U-Net和随机森林模型在三个数据集的输出图对比</p> <p><img src="/assets/img/postImages/image-20220320174235-dyug82k.png" alt="image.png" class="rounded"/></p> <p><img src="/assets/img/postImages/image-20220320174256-878bcuw.png" alt="image.png" class="rounded"/></p> <p>图3.1.9测试数据集上的总体精度分布的箱线图（868个图块）。(a)RF和深度学习算法之间的比较；(b)HRU-Net，U-Net ++和U-Net之间的比较。</p> <h1 id="结论">结论</h1> <p>本文提出的HRU-Net网络，主要是为了解决两个问题：</p> <p>（1）传统方法进行耕地提取时的同物异谱问题，这使得耕地提取时，未覆盖植被的休耕期耕地很难被提取，提取精度很低。</p> <p>（2）利用深度学习进行耕地提取时高分辨率信息丢失的问题，这不仅导致了耕地提取结果边缘模糊，细节丢失，也使得深度学习网络对于遥感图像的光谱、纹理等信息利用不充分，无法发挥遥感影像多波段、信息丰富的优势，影响最终的耕地提取精度。</p> <p>针对以上两个问题，HR-UNet在全卷积网络U-Net的基础上，保留了U-Net网络的对称编解码结构，进行了以下两方面的改进：</p> <p>（1）根据在全卷积网络中全程保持高分辨率信息的思想，改进了U-Net网络的跳跃连接结构。</p> <p>（2）为了更好的利用保留的高分辨率信息训练网络参数，在设置损失函数时采用了深度监督的思想。</p> <p>在由Landsat影像不同波段数据组成的三个数据集TMall，TMnrg和TMrgb中，使用HRU-Net，U-Net，UNet++ ^[47]^ 和Random Forest分别进行耕地提取实验后，验证了本文提出的HRU-Net网络基本达到预期目标，并能得出以下结论：</p> <p>（1）在耕地提取精度上，相比基于深度学习的U-Net,<br/> UNet++网络和传统方法Random Forest，在整体精度，混淆矩阵，kappa系数和F1-score四个评价指标中，均取得了更好的结果。</p> <p>（2）在三个数据集中，三个方法均在包含Landsat影像全6个波段的TMall数据集中取得了最好的结果，其中，HRU-Net方法表现最好，整体耕地精度达到90.61%，Kappa系数达到0.8。</p> <p>（3）在三个数据集中，传统Random<br/> Forest方法均未能准确识别出未覆盖地物的休耕期耕地，而HRU-Net方法能准确识别出所有类型的耕地，解决了耕地提取中的同物异谱问题。</p> <p>（4）在三个数据集中，HRU-Net模型相比U-Net模型的耕地结果图边缘更为清晰，细节更为丰富，与遥感影像中耕地的实际分布情况以及标签更为吻合，说明HRU-Net针对高分辨率信息丢失问题的改进取得了明显的效果。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[多光谱遥感中，由于同物异谱效应，采用传统分类方法（如支持向量机、随机森林）对类似耕地这样的复合要素（休耕、弃耕、轮种情况下的耕地光谱差异较大）提取精度较低。卷积神经网络（CNN）对同一类地物的特征类内差异容忍度较高，具有较强的泛化能力，在同物异谱情况下有望提高复合要素的提取精度。]]></summary></entry><entry><title type="html">Hocpd</title><link href="https://shawnmiloguo.github.io/blog/2018/HOCPD/" rel="alternate" type="text/html" title="Hocpd"/><published>2018-06-18T00:00:00+00:00</published><updated>2018-06-18T00:00:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2018/HOCPD</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2018/HOCPD/"><![CDATA[<hr/> <p>layout: post title: 基于时空混合的MODIS产品降尺度模型-以海表叶绿素为例 date: 2018-02-03 21:01:00 description: 海表叶绿素时空融合 tags: 时空融合 categories: 时空融合算法研发 thumbnail: /assets/img/postImages/2016-02-03-图10.png —</p> <h2 id="原文链接">原文链接</h2> <p>https://doi.org/10.1016/j.jag.2018.06.004</p> <h2 id="海岸带卫星遥感监测数据空间插补和尺度转换技术">海岸带卫星遥感监测数据空间插补和尺度转换技术</h2> <p>海表水色是理解动态海洋生物发展过程的重要因素（Esaias等，1998）。 借助于MODIS Tarra和Aqua卫星的高时间重访频率（每天两次），NASA的MODIS海洋水色产品在过去几十年中被广泛用于海洋动态和全球环境变化的监测（Dasgupta，Singh和Kafatos ，2009; Esaias等，1998; McClain，2009）。 近海水域的水质状况反映了人类与当地环境之间的相互作用，是海洋科学中常见并且重要的一个关键领域（Cherukuru等，2016）。 然而，考虑到MODIS数据的低空间分辨率（1km），使用NASA MODIS海洋色产品难以捕获近海水域的详细信息。 因此，在这些区域获得高空间和时间分辨率数据，从而了解近海环境中生物过程，是当前海洋遥感的迫切要求（Esaias等，1998; McClain，2009）。</p> <p>在过去的十年中，在计算机视觉和遥感领域，人们一直致力于如何提高低影像观测的空间分辨率（Yang，Wright，Huang，＆Ma，2010; Yue，Shen，Li，Yuan ，＆Zhang，2016）。目前主要的方法有两大类，第一类方法为：图像超分辨率技术，第二类方法为：时空数据融合。</p> <p>在图像超分辨率领域，其基本假设是：如果这些图像遵循与用于创建低的相同的重采样过程，低空间分辨率图像中的缺失细节可以从其他高空间分辨率图像中学习或重建（Fernandez-Beltran，Latorre-Carmona，＆Pla，2016; Raul Zurita-Milla，Clevers，＆Schaepman，2008）。在这些方法中，关键步骤是准确预测点扩散函数（PSF），它代表形成低分辨率像素的混合过程（Yue et al。，2016）。其中典型的案例是基于图像重建（RE）技术创建PSF，例如迭代反投影（IBP）和PSF反卷积。这些技术提取某些物理特性和特征，以提供有关低空间分辨率图像的更详细信息，并使用常规插值结果对该信息进行聚类，以获得最终的超分辨率图像（Fisher＆Mustard，2004; Miskin＆MacKay，2000; Takeda， Farsiu，＆Milanfar，2007）。这一类方法建立再大量图像样本时，例如在卷积神经网络（CNN）（Dong，Loy，＆He，2016），稀疏编码（Yang等人， ，2010），贝叶斯网络（Lu＆Qin，2014），基于内核的方法（Takeda等，2007），以及基于SVM的方法（H. Zhang＆Huang，2013）。然而，在实践中，低分辨率遥感图像的实际混合过程可能太复杂而不能被基于有限样本的一个通用PSF模型来进行捕获。此外，当尺度比例变大时，这些方法的准确性迅速降低。大多数超分辨率算法的降尺度比为2比4.相反，MODIS和Landsat数据之间的尺度比例为1km / 30m = 33.3。由于这种巨大的尺度差异，将这些方法应用在MODIS数据从1km缩小到30m时，最终的结果往往表现的非常不理想。</p> <p>为了避免构建PSF和通过样本来预测图像的具体细节，时空数据融合技术通过遵循某些规则将精细图像合并到粗糙图像来获得更高的空间分辨率纹理细节。当没有精细的空间分辨率数据可用时，时间序列数据被用作辅助数据在同一位置提供与之对应的细节（B. Chen，Huang，＆Xu，2015）。这些时空数据融合技术基本基于两个假设：时间信息的尺度不变性和空间信息的时间恒定性（H.K. Zhang，Huang，Zhang，Cao＆Yu，2015）。与超分辨率方法相比，时间序列图像融合技术不能直接从粗略数据预测高分辨率细节。相反，它通过对应的算法，结合了在同一位置的时间序列高空间分辨率图像，来提供图像中的细节。目前基于这些技术已经建立了许多应用，例如田间尺度的作物进展（F. Gao等，2017），NDVI时间序列（B. Zhang等，2016），空间和时间表面反射率变化（Emelyanova） ，McVicar，Van Niel，Li和van Dijk，2013），初级生产力总值（Singh，2011），植被季节动态变化（R. Zurita-Milla，Kaiser，Clevers，Schneider，＆Schaepman，2009），森林干扰（Hilker）等人，2009年）和季节性湿地监测（Mizuochi等，2017）。据我们所知，这些时空数据融合技术尚未在海表水色产品上进行数据降尺度的尝试。</p> <p>基于分离的时空降尺度融合模型（U-STFM）被选取，作为本研究中的时空数据融合的核心技术。原因在于它更适应下垫面的变化（Huang＆Zhang，2014） ）。 U-STFM通过将时间序列的变化率与混合像素的线性分解模型相结合，为快速变化的景观中的时间序列图像融合提供了一种新的处理结构。这种方法已经在土地覆盖变化应用中得到了很好的测试，例如MODIS地表反射率降尺度，并证明了其有效性（Huang＆Zhang，2014）。本章节所遇到的问题是如何使用这个模型来面对海表水色产品的降尺度问题。</p> <p>当应用U-STFM降低MODIS海表水色叶绿素a浓度产品时，需要解决两个问题。首先，U-STFM模型要求高空间分辨率数据和低空间分辨率数据在时间序列中变化率保持一致。然而，在水色遥感中，在大气校正过程和及使用不同模型对MODIS和Landsat产品处理得到海洋表面叶绿素-a浓度产物的过程中被破坏掉了（Pahlevan，Sarkar，＆Franz，2016）。其次，在U-STFM中，必须减小分割区域的尺寸以获得每个分割区域的更准确的变化率，以便在最终输出中提供更详细的信息。然而，较小的区域可能导致线性非混合方程中得到不一致解，这将导致最终输出中的数据缺口或不合理的预测。</p> <h3 id="基于u-stfm模型的水色遥感数据插补和重构">基于U-STFM模型的水色遥感数据插补和重构</h3> <p>U-STFM模型对精细和粗略空间分辨率时间序列数据上的像素或区域需要相同的变化率。由于MODIS和Landsat叶绿素-a产品的变化率的一致性可以被不同的叶绿素a反演模型破坏（Pahlevan等，2016），因此很难直接应用U-STFM对 MODIS和Landsat叶绿素-a产品进行空间降尺度。然而，不同于加工后的产品，初始MODIS和Landsat Rrs产品可以保持变化率的一致性，因为两者遵循具有类似的大气校正过程（Pahlevan等，2017）。这项研究通过首先用时间序列MODIS和Landsat数据预测被测时间的Rrs数据，其次通过以找出预测的反射率数据与MODIS 1km叶绿素-a产品之间的相关性，通过回归来预测最终的高空间分辨率的叶绿素a浓度产品。</p> <p>在应用U-STFM模型来预测遥感反射率时，面临的第二个问题是分割区域的大小与线性非混合方程的稳定解之间的权衡。分割区域越小，近海叶绿素a的空间异质性越好。然而，较小的分割将导致线性非混合方程中的不一致解，这将导致可观察到的硬分割边界或最终输出中的不合理预测。为了克服数据缺口或不合理的异常值，解决方案是在具有相同目标日期的时间序列数据中多次应用U-STFM模型来估计最可能的预测。最终的结果取所有预测的中值。通过这种方式和，云盖引起的数据缺失也可以填补。图9显示了基本工作流程。整体处理可归纳为以下三个步骤：</p> <p>1）预处理：按时间序列准备匹配的MODIS和Landsat遥感反射对数据;</p> <p>2）时空数据融合：使用U-STFM根据匹配的MODIS和Landsat遥感反射对获得的变化率，预测目标日期的高空间分辨率Rrs;</p> <p>3）回归：建立U-STFM（30m）和MODIS叶绿素-a产物（1km）预测的Rrs之间的回归模型，并预测最终的高空间分辨率叶绿素a数据（30m）。</p> <h3 id="数据的预处理">数据的预处理</h3> <p>在本章节的实例中，我们采用的原始数据是MODIS Rrs 469和Rrs 555，以及Landsat 8 TOA反射率数据中的第2和第3波段。MODIS Rrs 469和Rrs 555来自NASA MODIS每日海表水色2级产品数据，可直接用作 U-STFM的输入参数。 但是，Landsat TOA反射率数据需要在使用前处理为Rrs数据。 在这项研究中，NASA的SeaDAS软件中的L2gen模型被用来完成这项处理，该模型是由NASA的海洋生物处理组（OBPG）（https://seadas.gsfc.nasa.gov/）研发创建，用于通过选择适当的大气校正算法来生成Rrs数据。 Franz，Bailey，Kuring和Werdell（2015）描述了该模型在SeaDAS中应用于Landsat 8开发的大气校正中的实现过程。 此外该模型对MODIS和Landsat Rrs数据应用相同的陆地和云掩模（Concha＆Schott，2016）。</p> <p>本研究使用了三个主要数据集。其中一个是2013年至2017年的Landsat 8 TOA反射率，可以从USGS Earth Explorer网站（https://earthexplorer.usgs.gov/）下载。 MODIS Rrs和叶绿素-a产品从NASA Ocean Color网站（https://oceancolor.gsfc.nasa.gov/）下载（NASA戈达德太空飞行中心，海洋生态实验室，2014）。 MODIS的重访频率是每天，Landsat 8是16天。由于云层覆盖和遥感反射的质量，大多数近海地区都被云罩掩盖。这导致仅有12个匹配日期，其中有效数据可用作U-STFM模型中的输入。数据的细节显示在表1中.Landsat 8 Rrs 482nm和Rrs 561nm在SeaDAS 7.3.1中用L2gen模型计算。 Landsat的Rrs和MODIS数据都被地理参考到相同的地理框架，以最小化两个传感器之间的几何重合失调。</p> <p>Landsat 8叶绿素-a产品也在SeaDAS 7.3.1中计算，以L2gen模型作为参考数据，与最终缩小的MODIS叶绿素-a数据进行比较。在L2gen模型中，用于叶绿素a检索的标准NASA算法是三波段经验Rrs带比算法（OC3），其转换为清水中的经验带差算法（OCI）。对于Landsat 8，使用NASA生物光学海洋算法数据集（NOMAD）调整经验系数，以调整相对于传感器的中心波长的差异。这些经验系数可以在NASA海表水色网页（https://oceancolor.gsfc.nasa.gov/atbd/chlor_a/）上找到。 SeaDAS中的叶绿素-a算法使用443,482和561 nm波段作为波段比（Franz，Bailey，Kuring，＆Werdell，2014）。</p> <h3 id="使用u-stfm时空融合模型进行更高分辨率的遥感反射预测">使用U-STFM时空融合模型进行更高分辨率的遥感反射预测</h3> <p>待预测的目标日期的MODIS数据，以及目标日期之前和之后的至少两个匹配的MODIS和Landsat观测值，需要作为U-STFM模型的输入数据，来预测目标日期的高空间分辨率Landsat数据。 在本节中，以避免对读者造成不必要的混淆，方程的表达与Huang和Zhang 2014年的论文保持一致。 本节简要介绍U-STFM模型。 详细解释可以在Huang和Zhang的论文中找到（Huang＆Zhang，2014），U-STFM的主要步骤如图2所示。</p> <p>为了预测MODIS像素中更详细的信息，最常见的技术是线性分离技术（Burette，Meroni和Colombo 2008; Zurita-Milla等，2009），线性分离假设低分辨率像素中的反射率可以用在该低空间分辨率像素内的端部成员的平均反射率的线性组合表示。 U-STFM的工作流程如图10所示。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image086.jpg" alt="img"/></p> <p><strong>图 10 U-STFM 模型处理流程图</strong></p> <h3 id="325-回归模型建立预测光谱和modis叶绿素产品的关系">3.2.5 回归模型建立预测光谱和MODIS叶绿素产品的关系</h3> <p>U-STFM模型的输出是电磁波谱的蓝色和绿色区域中的Rrs（30m），具有详细的纹理信息。 接下来，需要适当的回归模型来将反射率数据转换为每日叶绿素-a浓度产物。 该回归的整体工作流程如图11所示。</p> <p>对于具有相同目标日期的不同三日期对，U-STFM模型被多次应用以避免不稳定的解混解决方案。 结果，在同一天，预测了几个遥感反射率。 这些预测的中值用于每个像素。 选择中位数统计量的原因是线性非混合过程的不稳定解决方案要么没有解决方案要么给出大值，这可以被认为是多个预测的异常值。 同时，该程序还可以填补MODIS观测中由云层和坏像素引起的数据缺口。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image088.jpg" alt="img"/></p> <p><strong>图11 MODIS叶绿素产品空间降尺度流程图</strong></p> <p>电磁波谱的蓝色区域（450-495nm）和绿色区域（495-570nm）的Rrs与叶绿素-a浓度高度相关，这是由于叶绿素-a在这些区域的强烈吸收和反射(Hu, et al., 2012; Morel, Maritorena, 2001; Werdell, Bailey, 2005)。目前用于MODIS的默认叶绿素算法基于几种OCx形成的算法，其系数使用来自NASA生物光学海洋算法数据集（NOMAD）版本2的原位数据导出（https://oceancolor.gsfc.nasa.gov/后处理/ R2009 / ocv6 /）。在该研究中，OC2M-HI带比回归模型（方程10）用于建立蓝带，绿带和叶绿素-a浓度之间的相关性（O’Reilly等，2000）。由于MODIS叶绿素a产品的原始分辨率为1km，所以通过使用ArcMap中的平均聚合方法将U-STFM遥感反射率从30m扩展到1km，首先建立了1km规模的相关性（ESRI，https：// www .esri.com / EN-US /家）。</p> <h3 id="326-实验验证方案">3.2.6 实验验证方案</h3> <p>两个测试已应用于降尺度过程的两个主要步骤。 一种是检查是否正确预测了高空间分辨率（30 m）的遥感反射率。 第二是测试最终的高分辨率叶绿素产品是否与原始的MODIS叶绿素-a产品一致。</p> <h4 id="1-高空间分辨率rrs数据测试"><strong>1.</strong> <strong>高空间分辨率Rrs数据测试</strong></h4> <p>Landsat 8蓝色和绿色的遥感反射被用作该测试中的地面实测数据，使用SeaDAS l2gen模型与Landsat 8 TOA数据在与观察MODIS数据相同的日期进行处理。 应该注意的是，Landsat 8的当地观测时间早于上午10:30，比MODIS Aqua数据提前4小时，因此如果原始MODIS数据也是如此，预测的准确性低可能是由于此期间的水运动造成的。 显示Landsat数据的准确度低。</p> <p>使用预测数据和观察数据之间的平均绝对差（AAD），平均相对差（ARD），相关系数（CC）和均方根误差（RMSE）来评估U-STFM图像融合模型的性能。</p> <h4 id="2-最终预测结果与原始modis数据产品一致性分析"><strong>2.</strong> <strong>最终预测结果与原始MODIS数据产品一致性分析</strong></h4> <p>本文的主要目的是在近海地区附近的MODIS 1km叶绿素产品中生产更高空间分辨率的日叶绿素a产品。这种最终的高分辨率叶绿素产品是否与最初的MODIS 1km叶绿素一致 - 需要测试具有相似精度的产品。</p> <p>在同一天测试的Landsat 8叶绿素-a产品用作参考数据，以比较最终的较高空间分辨率叶绿素-a产物和原始MODIS叶绿素-a产物。计算了两个RMSE。一个是最终叶绿素-a产品和参考数据之间的RMSE。另一个是原始MODIS产品和参考数据之间的RMSE。如果这两种RMSE保持相似，则意味着最终的叶绿素a产品与最初的MODIS 1km叶绿素a产品一致。</p> <p>使用局部标准偏差（9×9窗口）来定量评估图像中包含的局部信息。具有较高纹理的较高空间分辨率图像将显示较大的局部标准偏差值，反之亦然。</p> <h3 id="327-实例研究区域">3.2.7 实例研究区域</h3> <p>渤海湾是形成渤海湾的三个海湾之一，是中国东北第二大渤海湾。海河和其他15条河流流入渤海湾。因此，整个华北平原的径流集中在渤海湾，海湾是一个受到严重污染的水体（X. Chen et al。，2010）。渤海湾环绕着几个主要港口：天津港，唐山曹妃甸港，京唐港和黄骅港，使海湾成为一条拥挤的水道。渤海周边近海地区是中国人口密度最大，工业化程度最高的三个地区之一（X. Gao＆Chen，2012）。根据中国国家海洋局的报告，渤海遭受工业废弃物，农业，土壤侵蚀，商业废弃物和污水造成的严重水污染。海岸和港口附近的化学需氧量（COD）和溶解氧（DO）仍然很高，而且随着海湾地区的经济增长而增加（PEMSEA和BSEMP，2005）。因此，高空间分辨率的海洋色产品对于该领域的环境评估至关重要。</p> <p>研究区域1选自位于中国渤海湾东北部的唐山曹妃甸港附近的海域。它是一个约1638 Km2的区域，具有高人类活动（118.402°E-118.842°E和38.805°W-39.189°W）。港口活动和河流污水在该地区产生高浓度的叶绿素和重金属。图4显示了唐山曹妃甸港及其附近海域的面积。</p> <p>本章第二个研究区在深圳香港海域，该区域人类活动频繁，海面环境复杂，岛屿众多，海表纹理丰富。同时该区域有相应的 实测浮标数据，可以对最终产品的精度提供验证。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image130.jpg" alt="img"/></p> <p><strong>图 4 研究区域1：渤海湾海域，研究区域2：深圳香港海域</strong></p> <p>本研究使用了三个主要数据集。其中一个是2013年至2017年的Landsat 8 TOA反射率，可以从USGS Earth Explorer网站（https://earthexplorer.usgs.gov/）下载。 MODIS Rrs和叶绿素-a产品从NASA Ocean Color网站（https://oceancolor.gsfc.nasa.gov/）下载（NASA戈达德太空飞行中心，海洋生态实验室，2014）。 MODIS的重访频率是每天，Landsat 8是16天。由于云层覆盖和遥感反射的质量，大多数近海地区都被云罩掩盖。这导致仅有12个匹配日期，其中有效数据可用作U-STFM模型中的输入。数据的细节显示在表1中.Landsat 8 Rrs 482nm和Rrs 561nm在SeaDAS 7.3.1中用L2gen模型计算。 Landsat的Rrs和MODIS数据都被地理参考到相同的地理框架，以最小化两个传感器之间的几何重合失调。</p> <p>Landsat 8叶绿素-a产品也在SeaDAS 7.3.1中计算，以L2gen模型作为参考数据，与最终缩小的MODIS叶绿素-a数据进行比较。在L2gen模型中，用于叶绿素a检索的标准NASA算法是三波段经验Rrs带比算法（OC3），其转换为清水中的经验带差算法（OCI）。对于Landsat 8，使用NASA生物光学海洋算法数据集（NOMAD）调整经验系数，以调整相对于传感器的中心波长的差异。这些经验系数可以在NASA海表水色网页（https://oceancolor.gsfc.nasa.gov/atbd/chlor_a/）上找到。 SeaDAS中的叶绿素-a算法使用443,482和561 nm波段作为波段比（Franz，Bailey，Kuring，＆Werdell，2014）。</p> <p>Table 1 Data list of Landsat 8 and MODIS Aqua Ocean Color Level 2 products used in study area 1</p> <table> <thead> <tr> <th><strong>Date</strong></th> <th><strong>Landsat 8 TOA</strong> <strong>and MODIS Aqua Ocean Color Data names</strong></th> <th><strong>Bands in use</strong></th> </tr> </thead> <tbody> <tr> <td><strong>2013</strong> <strong>Sep 26th</strong></td> <td>LC81220332013269LGN00.tar.gz</td> <td>Landsat 8: Band 2 and Band 3 MODIS: Rrs 469nm, Rrs 555nm and chlorophyll-a product were used in this study.</td> </tr> <tr> <td>A2013269053000.L2_LAC_OC.nc</td> <td> </td> <td> </td> </tr> <tr> <td><strong>2013 Nov 29th</strong></td> <td>LC81220332013333LGN00.tar.gz</td> <td> </td> </tr> <tr> <td>A2013333053000.L2_LAC_OC.nc</td> <td> </td> <td> </td> </tr> <tr> <td><strong>2014 Aug 12nd</strong></td> <td>LC81220332014224LGN00.tar.gz</td> <td> </td> </tr> <tr> <td>A2014224053000.L2_LAC_OC.nc</td> <td> </td> <td> </td> </tr> <tr> <td><strong>2014 Sep 13rd</strong></td> <td>LC81220332014256LGN00.tar.gz</td> <td> </td> </tr> <tr> <td>A2014256053000.L2_LAC_OC.nc</td> <td> </td> <td> </td> </tr> <tr> <td><strong>2015 Jan 19th</strong></td> <td>LC81220332015019LGN00.tar.gz</td> <td> </td> </tr> <tr> <td>A2015019053000.L2_LAC_OC.nc</td> <td> </td> <td> </td> </tr> <tr> <td><strong>2015 Oct 2nd</strong></td> <td>LC81220332015275LGN00.tar.gz</td> <td> </td> </tr> <tr> <td>A2015275053000.L2_LAC_OC.nc</td> <td> </td> <td> </td> </tr> <tr> <td><strong>2015 Dec 5th</strong></td> <td>LC81220332015339LGN00.tar.gz</td> <td> </td> </tr> <tr> <td>A2015339053000.L2_LAC_OC.nc</td> <td> </td> <td> </td> </tr> <tr> <td><strong>2016 Jan 6th</strong></td> <td>LC81220332016006LGN00.tar.gz</td> <td> </td> </tr> <tr> <td>A2016006053000.L2_LAC_OC.nc</td> <td> </td> <td> </td> </tr> <tr> <td><strong>2016 Mar 10th</strong></td> <td>LC81220332016070LGN00.tar.gz</td> <td> </td> </tr> <tr> <td>A2016070053000.L2_LAC_OC.nc</td> <td> </td> <td> </td> </tr> <tr> <td><strong>2016 Mar 26th</strong></td> <td>LC81220332016086LGN00.tar.gz</td> <td> </td> </tr> <tr> <td>A2016086053000.L2_LAC_OC.nc</td> <td> </td> <td> </td> </tr> <tr> <td><strong>2016 Dec 23rd</strong></td> <td>LC81220332016358LGN00.tar.gz</td> <td> </td> </tr> <tr> <td>A2016358053000.L2_LAC_OC.nc</td> <td> </td> <td> </td> </tr> <tr> <td><strong>2017 Feb 25th</strong></td> <td>LC81220332017056LGN00.tar.gz</td> <td> </td> </tr> <tr> <td>A2017056053000.L2_LAC_OC.nc</td> <td> </td> <td> </td> </tr> </tbody> </table> <p>Table 2 Data list of Landsat 8 and MODIS Aqua Ocean Color Level 2 products in study area 2</p> <table> <thead> <tr> <th>Date</th> <th>Landsat 8 TOA And MODIS Aqua Ocean Color Data names</th> <th>Bands in use</th> </tr> </thead> <tbody> <tr> <td>2014 Nov.25</td> <td>LC08_L1TP_121045_20141125_20170417_01_T1.tar.gz A2014329052000.L2_LAC_OC.nc</td> <td>Landsat 8: Band2 and Band 3 MODIS: Rrs 469nm, Rrs 555nm and chlorophyll-a product were used in this study.</td> </tr> <tr> <td>2016 Nov.14</td> <td>LC08_L1TP_121045_20161114_20170318_01_T1.tar.gz A2016319052000.L2_LAC_OC.nc</td> <td> </td> </tr> <tr> <td>2017 Nov.1</td> <td>LC08_L1TP_121045_20171101_20171109_01_T1.tar.gz A2017305052000.L2_LAC_OC.nc</td> <td> </td> </tr> </tbody> </table> <h3 id="328-实验结果和讨论">3.2.8 实验结果和讨论</h3> <h4 id="1-利用u-stfm模型来对海域rrs反射率数据进行预测"><strong>1.</strong> <strong>利用U-STFM</strong>模型来对海域Rrs反射率数据进行预测</h4> <p>本研究收集了12对有效的MODIS和Landsat 8数据。在本节中，目标预测日期设置为2016年3月10日。其他日期的结果也会在稍后显示。由于U-STFM模型需要三对（在目标之前 - 之后的日期）进行预测，因此有24个之前的目标后案例，导致2016年3月10日的遥感反射总数预测为24个。原样如图5所示，云层和坏水像素被掩盖为黑色。有效区域受到前期目标后日期的质量的高度影响，因为只有在三个图像中的每一个中相同的像素有效时才能认为该像素对于预测是有效的。通过获得每个位置的这些图像的中值，将这24个预测合并为单个预测。</p> <p>2016年3月10日在Rrs蓝带中的U-STFM的最终预测如图6（b）所示。将其与图6（a）中所示的原始MODIS粗Rrs 469数据和图6（c）中所示的地面实况Landsat 8频带2（Rrs 482nm）进行比较。与MODIS数据相比，预测显示在海湾区域附近更加详细的纹理，其中遥感反射率因人类活动和水流而变化。同时，预测保持与MODIS数据相同的基本分布模式趋势。与Landsat 8数据相比，U-STFM模型的预测已经捕获了该海湾区域中遥感反射率的空间变化的基本模式。出现在图像之前或之后的那些纹理仍保留在预测中。根据之前的研究，U-STFM模型更适应前后图像中的景观变化（Huang＆Zhang，2014; H.K. Zhang et al。，2015）。因此，预测中显示的纹理是在图像之前或之后已经出现的纹理。那些仅出现在目标日期（2016年3月10日）但未被MODIS数据捕获的纹理无法通过U-STFM模型预测。用MODIS和Landsat 8 Rrs数据进行的预测区域岛附近的详细比较如图7所示。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image132.jpg" alt="A picture containing tree, photo, showing Description generated with very high confidence"/></p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image134.jpg" alt="img"/></p> <p>图 5 2016年3月10日，使用U-STFM图像融合模型（分割区域&gt; 10000）在研究区域的蓝色波段进行24种不同的Rrs预测。 每个预测都使用“第一日期 – 预测日期- 第二日期”日期命名。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image136.jpg" alt="A close up of a map Description generated with high confidence"/></p> <p>图 6 2016年3月10日，蓝色波段的U-STFM（分割区域&gt; 10000）与原始MODIS Rrs 469和Landsat 8 Rrs 482nm的预测相比较。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image138.jpg" alt="A close up of a map Description generated with high confidence"/></p> <p>图 7 2016年3月10日，局部海湾区域在蓝色波段的U-STFM预测与原始MODIS Rrs 469和Landsat 8 Rrs 482nm相比。</p> <p>同样，2016年3月10日，绿色波段U-STFM的时间序列预测也与MODIS Rrs555 nm和地面实况Landsat 8 Rrs 561 nm进行了比较。这些结果如图8和图9所示。以类似的方式，如对蓝色带中的预测所做的那样，可以通过U-STFM模型很好地预测由海湾区域中的局部水流引起的详细纹理。仅在2016年3月10日的Landsat数据中出现并且未被MODIS数据捕获的纹理不容易预测。其原因在于，在U-STFM模型中，MODIS数据是目标日期唯一有效的观测值。预测中显示的纹理来自目标日期之前和之后拍摄的Landsat图像中的纹理以及目标日期的MODIS图像。如果这些图像不包含详细纹理，那么这些纹理（仅在2016年3月10日由Landsat数据捕获）无法通过图像融合模型预测。图9显示了预测与MODIS和Landsat 8数据的详细子区域比较。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image140.jpg" alt="A close up of a map Description generated with high confidence"/></p> <p>图 8 2016年3月10日，绿色波段的U-STFM预测与原始MODIS Rrs 555nm和Landsat 8 Rrs 561 nm相比。</p> <p>。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image142.jpg" alt="img"/></p> <p>图 9在绿色带中的U-STFM预测中的湾区的子区域。 与2016年3月10日的原始MODIS Rrs 555nm和Landsat 8 Rrs 561相比。</p> <p>如图10（a）所示，来自蓝带中24个U-STFM预测的中值的位置随机分布在研究区域上。这意味着24个预测中没有一个案例支配最终输出。换句话说，每个案例都可以看作是最终产出的等价贡献。</p> <p>通常，数据对越接近目标日期，预测就越准确。如图10（c）和图10（d）所示，X轴是每个“之前 - 之后 - 之后”组中第一个和最后一个日期之间的天数。数字越小，图像之前和之后越接近目标日期。与Landsat Rrs产品相比，Y轴是预测的RMSE。总体而言，随着天数的增加，RMSE略有增加，这证实了日常距目标日期越近的常识，预测就越准确。由于天数较少，预测的不确定性较小。这可以在图10（c）中所示的较低RMSE波动中看出，并且表明更接近的数据对将导致更稳定的预测。</p> <p>考虑到图10（c-d）中没有显着的增加模式，RMSE在可接受的范围内增加（在蓝色波段中从约0.015到0.027）。这表明随着天数的增加，总体准确性不会显着降低。在绿带的预测中可以找到类似的结果，如图10（d）所示。为了填补数据空白并获得多个预测的好处，中位数统计值被认为是组合所有这些预测的适当方式。图10（b）显示了与Landsat Rrs 482相比，蓝带中预测的绝对误差的空间分布。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image144.jpg" alt="img"/></p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image146.jpg" alt="A screenshot of a cell phone Description generated with very high confidence"/></p> <p>图 10（a）蓝色波段24个U-STFM_M预测的中值位置; （b）2016年3月10日，与Landsat 8 Rrs 482nm相比，U-STFM_M中位数的绝对误差分布。（cd）RMSE通过每个“第一日期 – 预测日期- 第二日期”日期之前和之后日期之间的天数 组。 数字越小，图像之前和之后越接近目标日期。</p> <p>U-STFM模型的Rrs预测的30m比例的1：1图与蓝色和绿色波段的Landsat 8 Rrs数据相比如图11所示。观察和预测之间显示出强烈的线性相关性。 在蓝色和绿色波段中，R平方分别为0.868和0.881，RMSE为0.00177和0.00202（表2）。 这表明来自U-STFM模型的预测类似于具有空间细节的地面实况Landsat数据。 这些Rrs预测可以进一步用于在近海地区附近产生高空间分辨率的叶绿素a浓度。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image148.jpg" alt="img"/></p> <p>图 11 2016年3月10日蓝色和绿色波段的U-STFM模型的1：1预测图。</p> <p>在表3中，预测和原始MODIS数据在2016年3月10日与NASA Landsat Rrs观测数据进行了定量比较。与原始MODIS Rrs数据相比，预测具有更低的RMSE，更低的平均绝对差异（AAD）和更低的平均值 相对差异（ARD），因为预测捕获更多具有更高空间分辨率的空间细节。</p> <p>Table 3. Prediction accuracy assessment of predicted blue and green bands on Mar 10th 2016 in the U-STFM model compared to NASA Landsat Rrs observations</p> <table> <thead> <tr> <th><strong>Band</strong></th> <th><strong>RMSE</strong></th> <th><strong>CC</strong></th> <th><strong>AAD</strong></th> <th><strong>ARD (%)</strong></th> <th><strong>R-Square</strong></th> </tr> </thead> <tbody> <tr> <td>Predicted Blue</td> <td>0.00177</td> <td>0.920</td> <td>0.00143</td> <td>11.5%</td> <td>0.868</td> </tr> <tr> <td>Predicted Green</td> <td>0.00202</td> <td>0.930</td> <td>0.00159</td> <td>8.02%</td> <td>0.881</td> </tr> <tr> <td>Original MODIS Blue (Rrs 469nm) †</td> <td>0.00367</td> <td>0.932</td> <td>0.00346</td> <td>26.7%</td> <td>0.883</td> </tr> <tr> <td>Original MODIS Green (Rrs 555nm) †</td> <td>0.00439</td> <td>0.938</td> <td>0.00405</td> <td>18.7%</td> <td>0.892</td> </tr> </tbody> </table> <p>† resampled to 30m scale by nearest neighbor interpolation for comparison.</p> <p>在理想条件下，MODIS和OLI衍生的Landsat产品之间的Rrs应该是一致的。根据Pahlevan等人的说法。 （2017年），OLI衍生的Landsat Rrs产品在蓝色带中比VIIRS和MODIS Aqua更亮（平均约10％）。产品在绿色带中最为一致（Pahlevan等，2017）。</p> <p>一些因素可以显着降低这种一致性，例如从上午10:30到下午2点的水运动，由Rrs建模引起的残差和从上午10:30到下午2:00的大气条件变化。</p> <p>表3显示了在其他可测试日期的遥感反射率的预测准确度评估。它清楚地表明，原始的MODIS遥感反射率数据与Landsat 8 Rrs具有良好的相关性（表3中标有*），R平方高于0.7。换句话说，由上午10:30到下午2点的水运动引起的反射率差异可以忽略不计，U-STFM预测的较高空间分辨率反射率具有较低的RMSE和较高的ARD。这意味着U-STFM预测蓝色和绿色波段的遥感反射捕捉了近海地区海表水色空间分布的细节。</p> <p>表4还显示，当原始MODIS和Landsat 8数据之间出现较低的R平方时，与2013年11月29日的情况一样; 2014年8月12日; 2014年9月13日; 2015年12月5日，MODIS与Landsat Rrs之间的一致性被打破。在这些情况下，Landsat数据不能被视为基础事实，因为很难判断预测误差是来自U-STFM模型还是MODIS和Landsat数据之间的差异。然而，该结果证实了U-STFM模型与原始MODIS数据高度相关的预测。当MODIS用Landsat 8数据显示高或低R平方时，预测显示类似的R平方值，反之亦然。</p> <p>Table 4. Prediction accuracy assessment of predicted blue and green bands on other target dates compared to NASA Landsat 8 Rrs observations</p> <table> <thead> <tr> <th>The target date</th> <th>Band</th> <th>RMSE</th> <th>CC</th> <th>ADD</th> <th>ARD (%)</th> <th>R-Square†</th> </tr> </thead> <tbody> <tr> <td>2013 Nov 29th</td> <td>Predicted Blue</td> <td>0.00167</td> <td>0.616</td> <td>0.00134</td> <td>10.4%</td> <td>0.372</td> </tr> <tr> <td>Predicted Green</td> <td>0.00166</td> <td>0.777</td> <td>0.00130</td> <td>7.00%</td> <td>0.622</td> <td> </td> </tr> <tr> <td>Original MODIS Blue (Rrs 469nm)</td> <td>0.00258</td> <td>0.587</td> <td>0.00211</td> <td>15.3%</td> <td>0.306</td> <td> </td> </tr> <tr> <td>Original MODIS Green (Rrs 555nm)</td> <td>0.00272</td> <td>0.797</td> <td>0.00235</td> <td>11.9%</td> <td>0.657</td> <td> </td> </tr> <tr> <td>2014 Aug 12nd</td> <td>Predicted Blue</td> <td>0.00302</td> <td>0.587</td> <td>0.00216</td> <td>80.5%</td> <td>0.393</td> </tr> <tr> <td>Predicted Green</td> <td>0.00385</td> <td>0.715</td> <td>0.00268</td> <td>38.7%</td> <td>0.562</td> <td> </td> </tr> <tr> <td>Original MODIS Blue (Rrs 469nm)</td> <td>0.00261</td> <td>0.595</td> <td>0.00186</td> <td>68.0%</td> <td>0.401</td> <td> </td> </tr> <tr> <td>Original MODIS Green (Rrs 555nm)</td> <td>0.00372</td> <td>0.710</td> <td>0.00254</td> <td>36.1%</td> <td>0.555</td> <td> </td> </tr> <tr> <td>2014 Sep 13rd</td> <td>Predicted Blue</td> <td>0.00225</td> <td>0.706</td> <td>0.00179</td> <td>26.7%</td> <td>0.518</td> </tr> <tr> <td>Predicted Green</td> <td>0.00206</td> <td>0.822</td> <td>0.00163</td> <td>14.5%</td> <td>0.695</td> <td> </td> </tr> <tr> <td>Original MODIS Blue (Rrs 469nm)</td> <td>0.00196</td> <td>0.753</td> <td>0.00157</td> <td>19.8%</td> <td>0.591</td> <td> </td> </tr> <tr> <td>Original MODIS Green (Rrs 555nm)</td> <td>0.00227</td> <td>0.825</td> <td>0.00177</td> <td>13.5%</td> <td>0.696</td> <td> </td> </tr> <tr> <td>2015 Jan 19th</td> <td>Predicted Blue</td> <td>0.00162</td> <td>0.945</td> <td>0.00122</td> <td>8.63%</td> <td>*0.903</td> </tr> <tr> <td>Predicted Green</td> <td>0.00194</td> <td>0.945</td> <td>0.00149</td> <td>7.52%</td> <td>*0.904</td> <td> </td> </tr> <tr> <td>Original MODIS Blue (Rrs 469nm)</td> <td>0.00372</td> <td>0.944</td> <td>0.00350</td> <td>23.6%</td> <td>*0.901</td> <td> </td> </tr> <tr> <td>Original MODIS Green (Rrs 555nm)</td> <td>0.00391</td> <td>0.950</td> <td>0.00351</td> <td>16.7%</td> <td>*0.915</td> <td> </td> </tr> <tr> <td>2015 Oct 2nd</td> <td>Predicted Blue</td> <td>0.00140</td> <td>0.912</td> <td>0.00104</td> <td>11.8%</td> <td>*0.850</td> </tr> <tr> <td>Predicted Green</td> <td>0.00150</td> <td>0.945</td> <td>0.00111</td> <td>7.29%</td> <td>*0.906</td> <td> </td> </tr> <tr> <td>Original MODIS Blue (Rrs 469nm)</td> <td>0.00246</td> <td>0.926</td> <td>0.00214</td> <td>20.4%</td> <td>*0.878</td> <td> </td> </tr> <tr> <td>Original MODIS Green (Rrs 555nm)</td> <td>0.00282</td> <td>0.947</td> <td>0.00239</td> <td>14.2%</td> <td>*0.911</td> <td> </td> </tr> <tr> <td>2015 Dec 5th</td> <td>Predicted Blue</td> <td>0.00315</td> <td>0.0285</td> <td>0.00240</td> <td>15.4%</td> <td>0.000745</td> </tr> <tr> <td>Predicted Green</td> <td>0.00348</td> <td>0.369</td> <td>0.00258</td> <td>11.3%</td> <td>0.148</td> <td> </td> </tr> <tr> <td>Original MODIS Blue (Rrs 469nm)</td> <td>0.00318</td> <td>0.0412</td> <td>0.00261</td> <td>15.3%</td> <td>0.000987</td> <td> </td> </tr> <tr> <td>Original MODIS Green (Rrs 555nm)</td> <td>0.00392</td> <td>0.376</td> <td>0.00334</td> <td>13.5%</td> <td>0.169</td> <td> </td> </tr> <tr> <td>2016 Jan 6th</td> <td>Predicted Blue</td> <td>0.00211</td> <td>0.850</td> <td>0.00163</td> <td>9.37%</td> <td>*0.748</td> </tr> <tr> <td>Predicted Green</td> <td>0.00158</td> <td>0.948</td> <td>0.00120</td> <td>4.66%</td> <td>*0.911</td> <td> </td> </tr> <tr> <td>Original MODIS Blue (Rrs 469nm)</td> <td>0.00436</td> <td>0.921</td> <td>0.00404</td> <td>21.5%</td> <td>*0.860</td> <td> </td> </tr> <tr> <td>Original MODIS Green (Rrs 555nm)</td> <td>0.00493</td> <td>0.971</td> <td>0.00467</td> <td>16.8%</td> <td>*0.952</td> <td> </td> </tr> <tr> <td>2016 Mar 10th</td> <td>Predicted Blue</td> <td>0.00177</td> <td>0.920</td> <td>0.00143</td> <td>11.5%</td> <td>*0.868</td> </tr> <tr> <td>Predicted Green</td> <td>0.00202</td> <td>0.930</td> <td>0.00159</td> <td>8.02%</td> <td>*0.881</td> <td> </td> </tr> <tr> <td>Original MODIS Blue (Rrs 469nm)</td> <td>0.00367</td> <td>0.932</td> <td>0.00346</td> <td>26.7%</td> <td>*0.883</td> <td> </td> </tr> <tr> <td>Original MODIS Green (Rrs 555nm)</td> <td>0.00439</td> <td>0.938</td> <td>0.00405</td> <td>18.7%</td> <td>*0.892</td> <td> </td> </tr> <tr> <td>2016 Mar 26th</td> <td>Predicted Blue</td> <td>0.00186</td> <td>0.815</td> <td>0.00129</td> <td>19.4%</td> <td>*0.736</td> </tr> <tr> <td>Predicted Green</td> <td>0.00196</td> <td>0.907</td> <td>0.00150</td> <td>8.10%</td> <td>*0.844</td> <td> </td> </tr> <tr> <td>Original MODIS Blue (Rrs 469nm)</td> <td>0.00348</td> <td>0.858</td> <td>0.00318</td> <td>28.9%</td> <td>*0.794</td> <td> </td> </tr> <tr> <td>Original MODIS Green (Rrs 555nm)</td> <td>0.00396</td> <td>0.922</td> <td>0.00357</td> <td>16.6%</td> <td>*0.870</td> <td> </td> </tr> <tr> <td>2016 Dec 23rd</td> <td>Predicted Blue</td> <td>0.00322</td> <td>0.848</td> <td>0.00270</td> <td>14.0%</td> <td>*0.772</td> </tr> <tr> <td>Predicted Green</td> <td>0.00261</td> <td>0.940</td> <td>0.00215</td> <td>7.66%</td> <td>*0.898</td> <td> </td> </tr> <tr> <td>Original MODIS Blue (Rrs 469nm)</td> <td>0.00585</td> <td>0.895</td> <td>0.00556</td> <td>28.0%</td> <td>*0.843</td> <td> </td> </tr> <tr> <td>Original MODIS Green (Rrs 555nm)</td> <td>0.00649</td> <td>0.961</td> <td>0.00616</td> <td>20.9%</td> <td>*0.940</td> <td> </td> </tr> </tbody> </table> <p>† R-Square: comparing to Landsat 8 remote-sensing reflectance observation on the target date. Marked with (*) when R-square larger than 0.7.</p> <h4 id="2-u-stfm-模型和-starfm-已及estarfm模型进行比较"><strong>2.</strong> <strong>U-STFM</strong> <strong>模型和 STARFM</strong> <strong>已及ESTARFM</strong><strong>模型进行比较</strong></h4> <p>Huang和Zhang（2014）基于物候和土地覆盖变化的模拟和实际数据集，展示了U-STFM模型与STARFM和ESTARFM模型的性能比较。在本节中，我们还想了解U-STFM模型在近海水域Rrs预测中与STARFM和ESTARFM相比的表现。</p> <p>分割区域的数量是U-STFM模型中的基本参数。如引言中所述，分割区域越小（区域数越大），近海水的空间异质性越好。然而，较小的分割区域将导致线性非混合方程中的不一致解，这将导致最终输出中的“硬边界”或不合理的预测。</p> <p>在下面的比较中，我们提出了U-STFM模型的两个结果。一个是对大量分割区域（超过10,000个区域）的预测，在4.1节中以U-STFM_M表示。另一种是对较少数量的分割区域（少于1,000个区域）的预测，称为U-STFM_L。区域的最佳数量可能因不同的研究区域而异。</p> <p>2016年3月10日STARFM，ESTARFM，U-STFM_M和U-STFM_L的性能比较如图12（a） - （f）和图13（a） - （f）所示，蓝色和绿色带分别。这些结果是根据24个不同的“之前 - 之后 - 之后”日期组计算的，使用NASA Landsat Rrs观测结果作为基本事实。我们可以看到，U-STFM模型的性能优于STARFM，具有较低的RMSE，ADD和ARD以及较高的CC和R-Squared。一个可能的原因可能是U-STFM中的时间比率解混过程更适合于捕获特征变化并且受不同数据组所涉及的不确定性的影响较小。其次，U-STFM和ESTARFM的性能相似，但U-STFM模型存在更好的稳定性，箱形图偏差较小。这些结果表明，U-STFM的预测更稳定，并且受不同“之前 - 之后 - 之后”日期组的不确定性的影响较小。</p> <p>与STARFM相比，U-STFM在处理长时间间隔时表现更好，如下图12（g）和图13（g）所示。当天数增加时，U-STFM的RMSE低于STARFM。与ESTARFM相比，当天数超过500时，U-STFM的性能稍好一些。应该注意的是，图像融合模型不会产生纹理。输出的详细纹理来自目标日期之前或之后的Landsat图像。融合处理可以被视为找到将这两个图像与适当的权重组合的方式。任何融合模型的要求是使一个Landsat图像保持接近目标日期。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image150.jpg" alt="A screenshot of a cell phone Description generated with very high confidence"/></p> <p>图 12 2016年3月10日，蓝色光谱段中STARFM，ESTARFM，U-STFM_M（分割区域数&gt; 10000）和U-STFM_L（分割区域数&lt;1000）的比较。（a）RMSE; （b）相关系数; （c）ADD; （d）ARD; （f）与NASA Landsat Rrs观测值的R-平方线性回归; （g）不同模型不同天数间隔下的RMSE比较。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image152.jpg" alt="A screenshot of a social media post Description generated with very high confidence"/></p> <p>图 13 2016年3月10日，绿色光谱段中STARFM，ESTARFM，U-STFM_M（分割区域数&gt; 10000）和U-STFM_L（分割区域数&lt;1000）的比较。（a）RMSE; （b）相关系数; （c）ADD; （d）ARD; （f）与NASA Landsat Rrs观测值的R-平方线性回归; （g）不同模型不同天数间隔下的RMSE比较。</p> <p>在计算2016年3月10日的24 U-STFM，STARFM和ESTARFM预测的中值后，这三个模型的中值图像看起来相似，尤其是在U-STFM_L和ESTARFM之间，如图4和图5所示。对此的一个原因是中值处理增加了预测的稳定性并减小了这三个模型之间的差异。与图6-9（c）中Landsat Rrs的STARFM中值图像相比，U-STFM_L和ESTARFM中海湾区域附近图像的纹理更自然，更平滑。</p> <p>我们还注意到，U-STFM模型中的图像分割处理可以在预测中留下一些清晰的图像分割“边界”。当分割多边形在观察期间很好地表示水变化时，这些边界通过提供更清晰的纹理来帮助识别变化区域，如图13的U-STFM_L所示。然而，当分割区域的数量增加时，硬边界更加可观察。中值计算可以显着减少这些硬边界，但是当分割多边形太小时，这个小区域中的大多数预测都是不合理的。这些“硬边界”可以在中值处理之后保留，这导致在图6（b）和图8（b）中的U-STFM_M的预测中在海外区域中示出的“网格点”。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image154.jpg" alt="A close up of a map Description generated with high confidence"/></p> <p>图 14 2016年3月10日，蓝色波段中，STARFM的中值，U-STFM_L（分割区域的数量&lt;1000）中值和ESTARFM模型之间的比较。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image156.jpg" alt="A close up of a map Description generated with very high confidence"/></p> <p>图 15图14中的局部区域</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image158.jpg" alt="A picture containing text Description generated with very high confidence"/></p> <p>图 16 2016年3月10日，绿色波段中，STARFM的中值，U-STFM_L（分割区域的数量&lt;1000）中值和ESTARFM模型之间的比较。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image160.jpg" alt="A picture containing tree Description generated with very high confidence"/></p> <p>图 17 图16中的局部区域</p> <h4 id="3-modis叶绿素产品空间插补结果"><strong>3.</strong> <strong>MODIS</strong><strong>叶绿素产品空间插补结果</strong></h4> <p>NASA MODIS 1km海表水色产品已被用作回归模型中的因变量。使用ArcMap中的平均聚合工具将来自U-STFM_M模型的预测的30米蓝色和绿色条带放大到1km，其已被用作该回归模型中的独立变量。从U-STFM_M而不是U-STFM_L选择预测的原因是我们要将U-STFM_M视为U-STFM模型的最差情形。如果我们能够从最坏的情况中获得合理的输出，优化的U-STFM模型将只有更好的结果。</p> <p>如2.2节所述，NASA的OC2M-HI回归模型用于建立log10（叶绿素-a）和log10（蓝/绿）之间的相关性。 2016年3月10日1km空间分辨率下log10（蓝色/绿色）和log10（MODIS CHL）之间的相关性如图18所示.R平方显示这两个变量之间存在很强的相关性，其中85％的变化由回归函数。这是基于这种关系在不同尺度上是通用的假设，并且在粗略空间分辨率下建立的关系可以在精细空间分辨率下应用。本研究中使用的最终回归函数是：</p> <table> <thead> <tr> <th> </th> <th><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image162.gif" alt="img"/></th> <th>(12)</th> </tr> </thead> <tbody> <tr> <td> </td> <td><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image164.gif" alt="img"/></td> <td> </td> </tr> </tbody> </table> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image166.gif" alt="img"/></p> <p>图 18 2016年3月10日1km空间分辨率的log10(Blue/Green)和log10（MODIS CHL）之间的相关性。</p> <p>log10(blue/green)和log10(MODIS CHL)之间的相关性在不同日期有所不同。 表5显示了不同日期的这些相关性。 R平方从2016年3月26日的0.542到2015年1月19日的0.91不等。这个结果有两个可能的原因。 首先，log10（蓝色/绿色）对蓝色和绿色的变化高度敏感，特别是当反射率值在蓝色和绿色波段接近0时。 大气条件的微小差异可能导致log10（蓝色/绿色）的巨大差异，这将降低与MODIS叶绿素-a产物的相关性。 其次，由于MODIS像素中的实际聚合过程比平均过程复杂得多，因此从U-STFM从30m到1km升级预测的Rrs数据的平均聚合处理可能涉及额外的不确定性。</p> <p>Table 5. The correlation between log10(Blue/Green) and log10(MODIS CHL) at 1km spatial resolution on other target dates</p> <table> <thead> <tr> <th> </th> <th><strong>2013 Nov 29th</strong></th> <th><strong>2014 Aug 12nd</strong></th> <th><strong>2014 Sep 13rd</strong></th> <th><strong>2015 Jan 19th</strong></th> <th><strong>2015 Oct 2nd</strong></th> <th><strong>2015 Dec 5th</strong></th> <th><strong>2016 Jan 6th</strong></th> <th><strong>2016 Mar 10th</strong></th> <th><strong>2016 Mar 26th</strong></th> <th><strong>2016 Dec 23rd</strong></th> </tr> </thead> <tbody> <tr> <td><strong>R-Square</strong></td> <td>0.545</td> <td>0.557</td> <td>0.760</td> <td>0.910</td> <td>0.706</td> <td>0.889</td> <td>0.701</td> <td>0.850</td> <td>0.542</td> <td>0.615</td> </tr> <tr> <td><strong>RMSE</strong><strong>†</strong></td> <td>0.496</td> <td>0.771</td> <td>0.532</td> <td>0.681</td> <td>0.5757</td> <td>0.100</td> <td>0.391</td> <td>0.742</td> <td>0.371</td> <td>0.420</td> </tr> </tbody> </table> <p><strong>†</strong> RMSE: (mg/m^3).</p> <p>Landsat 8叶绿素-a产物用作MODIS Chl和U-STFM叶绿素-a预测之间比较的参考。本研究中从Landsat-8中回收的叶绿素-a由美国宇航局海洋生物处理小组创建的SeaWiFS数据分析系统（SeaDAS）生成。通过Landsat 8在切萨皮克湾检索到的Rrs和叶绿素a浓度与MODIS，SeaWiFS和原位历史叶绿素a测量结果的比较显示出相对较好的一致性（Concha＆Schott，2016; Franz，Bailey，Kuring，＆Werdell， 2015年）。</p> <p>这项研究的主要目的是找到一种适当的方法来改善近海水域的细致质地并保持准确性，与原始的MODIS叶绿素-a产品相比。逻辑是通过使用Landsat-8叶绿素产品作为参考，如果最终产量的RMSE与原始MODIS叶绿素产品的RMSE相似或更好，则原始MODIS产品的准确性得以保持。此外，如果输出显示近海水域附近更详细的空间变化，则近海水域附近的详细纹理得到改善。</p> <p>2016年3月10日对30m叶绿素a浓度的最终预测显示在图19b中。与原始MODIS数据（图19a）相比，最终预测在海岸区域附近具有更详细的纹理。同时，MODIS数据中显示的基本模式仍然在最终预测中。两个原因可能导致预测（图19b）和Landsat 8 Chl产品（图19c）之间的差异：MODIS和Landsat数据之间观察时间的差异，最重要的是叶绿素a检索和</p> <p>MODIS和Landsat数据中使用的大气校正算法不同，这可能会导致MODIS和Landsat Chl产品之间的差异。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image168.jpg" alt="img"/></p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image170.jpg" alt="img"/></p> <p>图 19 2016年3月10日最终预测30m规模的叶绿素a浓度。（a） - （c）整个研究区域的概况。 （d） - （f）岛屿附近的次区域。</p> <p>使用局部标准偏差（9×9窗口）来定量评估图像中包含的局部信息。具有较高纹理的较高空间分辨率图像将显示较大的局部标准偏差值，反之亦然。</p> <p>为了公平比较，通过插值工具将原始MODIS Chl数据重新采样到30m。用9×9移动窗口计算局部标准偏差。大于1的值被视为异常值，并从统计信息中删除，这通常在搜索窗口穿过图像边缘时发生。还删除值0以避免低估局部标准偏差的平均值和中值，尤其是在MODIS 30m重采样数据中。</p> <p>如图20中的直方图所示，尽管去除了0值，但MODIS Chl产品中的大部分局部标准偏差仍然接近0，平均值为0.0636，中值为1.69E-07。与MODIS相比，最终的Chl预测恢复了更多的局部纹理细节，平均值等于0.262并且中值等于0.218。这些结果表明，来自U-STFM模型的最终预测改善了每个像素中的纹理细节。</p> <p>表6给出了U-STFM Ch1和MODIS Ch1的局部标准偏差和RMSE的细节。与Landsat Chl相比，MODIS Chl和U-STFM Chl的RMSE非常相似，分别为2.69和2.39。这表明U-STFM模型保持了原始MODIS Chl的准确性。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image172.jpg" alt="img"/></p> <p>图 20 2016年3月10日当地标准偏差与9X9窗口的直方图：（a）MODIS叶绿素a浓度，（b）U-STFM模型的叶绿素a浓度，以及（c）Landsat 8叶绿素a浓度</p> <p>Table 6 RMSE and local standard deviation of upscaled chlorophyll-a concentration from U-STFM compared to original MODIS Chl and Landsat 8 Chl products.</p> <table> <thead> <tr> <th>ID</th> <th>RMSE compare to Landsat †</th> <th>Local standard deviation ††</th> <th> </th> <th> </th> <th> </th> </tr> </thead> <tbody> <tr> <td>Min</td> <td>Mean</td> <td>Median</td> <td>Max</td> <td> </td> <td> </td> </tr> <tr> <td>USTFM CHL</td> <td>2.39</td> <td>0.0154</td> <td>0.262</td> <td>0.218</td> <td>0.999</td> </tr> <tr> <td>MODIS CHL</td> <td>2.69</td> <td>5.96E-08</td> <td>0.0636</td> <td>1.69E-07</td> <td>0.999</td> </tr> <tr> <td>Reference: Landsat CHL</td> <td> </td> <td>0.0555</td> <td>0.225</td> <td>0.185</td> <td>0.999</td> </tr> </tbody> </table> <p><strong>†</strong> RMSE: compare to reference NASA Landsat 8 chlorophyll-a concentration (mg/m^3).</p> <p><strong>††</strong> Calculated with 9*9 moving window.</p> <p>表7显示了不同日期之间的类似结果。 总的来说，RMSE在U-STFM Chl和MODIS Chl之间是相似的。 有时，U-STFM模型的结果具有较低的RMSE。 如果不这样做，那是因为RMSE值很容易受到异常值的影响。 总的来说，这两个RMSE的差异很小。 这表明回归模型的最终预测基本上与原始的NASA MODIS Chl产品相似。 然而，局部标准偏差一致地表明U-STFM Chl预测具有比原始NASA MODIS Chl产品更高的局部纹理细节。</p> <p>Table 7. RMSE and local standard deviation of upscaled chlorophyll-a concentration from U-STFM compared to original MODIS Chl and Landsat 8 Chl products.</p> <table> <thead> <tr> <th>The target date</th> <th>ID</th> <th>RMSE compare to Landsat †</th> <th>Local standard deviation ††</th> <th> </th> <th> </th> <th> </th> </tr> </thead> <tbody> <tr> <td>Min</td> <td>Mean</td> <td>Median</td> <td>Max</td> <td> </td> <td> </td> <td> </td> </tr> <tr> <td>2013 Nov 29th</td> <td>U-STFM CHL</td> <td>1.08</td> <td>0.006</td> <td>0.140</td> <td>0.099</td> <td>0.999</td> </tr> <tr> <td>MODIS CHL</td> <td>1.22</td> <td>4.21E-08</td> <td>0.035</td> <td>8.43E-08</td> <td>0.995</td> <td> </td> </tr> <tr> <td>Reference: Landsat CHL</td> <td> </td> <td>0.075</td> <td>0.177</td> <td>0.162</td> <td>0.999</td> <td> </td> </tr> <tr> <td>2014 Aug 12nd</td> <td>USTFM</td> <td>4.08</td> <td>0.0127</td> <td>0.235</td> <td>0.215</td> <td>0.997</td> </tr> <tr> <td>MODIS</td> <td>4.10</td> <td>5.96E-08</td> <td>0.112</td> <td>1.46E-07</td> <td>0.999</td> <td> </td> </tr> <tr> <td>Reference: Landsat CHL</td> <td> </td> <td>0.0942</td> <td>0.474</td> <td>0.413</td> <td>0.999</td> <td> </td> </tr> <tr> <td>2014 Sep 13rd</td> <td>USTFM</td> <td>1.99</td> <td>0.0117</td> <td>0.175</td> <td>0.137</td> <td>0.999</td> </tr> <tr> <td>MODIS</td> <td>1.88</td> <td>4.21E-08</td> <td>0.0272</td> <td>8.43E-08</td> <td>0.997</td> <td> </td> </tr> <tr> <td>Reference: Landsat CHL</td> <td> </td> <td>0.0590</td> <td>0.289</td> <td>0.209</td> <td>1</td> <td> </td> </tr> <tr> <td>2015 Jan 19th</td> <td>USTFM</td> <td>2.81</td> <td>0.0244</td> <td>0.267</td> <td>0.181</td> <td>0.999</td> </tr> <tr> <td>MODIS</td> <td>2.90</td> <td>4.21E-08</td> <td>0.0411</td> <td>1.19E-07</td> <td>0.999</td> <td> </td> </tr> <tr> <td>Reference: Landsat CHL</td> <td> </td> <td>0.0442</td> <td>0.119</td> <td>0.0986</td> <td>0.999</td> <td> </td> </tr> <tr> <td>2015 Oct 2nd</td> <td>USTFM</td> <td>1.48</td> <td>0.00301</td> <td>0.107</td> <td>0.0572</td> <td>0.999</td> </tr> <tr> <td>MODIS</td> <td>1.37</td> <td>4.21E-08</td> <td>0.0291</td> <td>1.03E-07</td> <td>0.999</td> <td> </td> </tr> <tr> <td>Reference: Landsat CHL</td> <td> </td> <td>0.0686</td> <td>0.235</td> <td>0.194</td> <td>1</td> <td> </td> </tr> <tr> <td>2015 Dec 5th</td> <td>USTFM</td> <td>0.977</td> <td>0.0023</td> <td>0.123</td> <td>0.0832</td> <td>0.999</td> </tr> <tr> <td>MODIS</td> <td>0.958</td> <td>4.21E-08</td> <td>0.0399</td> <td>8.43E-08</td> <td>0.993</td> <td> </td> </tr> <tr> <td>Reference: Landsat CHL</td> <td> </td> <td>0.0737</td> <td>0.206</td> <td>0.180</td> <td>0.999</td> <td> </td> </tr> <tr> <td>2016 Jan 6th</td> <td>USTFM</td> <td>1.37</td> <td>3.79E-30</td> <td>0.0827</td> <td>0.0534</td> <td>0.999</td> </tr> <tr> <td>MODIS</td> <td>1.44</td> <td>5.96E-08</td> <td>0.0382</td> <td>1.19E-07</td> <td>0.998</td> <td> </td> </tr> <tr> <td>Reference: Landsat CHL</td> <td> </td> <td>0.0517</td> <td>0.151</td> <td>0.138</td> <td>0.999</td> <td> </td> </tr> <tr> <td>2016 Mar 10th</td> <td>USTFM</td> <td>2.39</td> <td>0.0154</td> <td>0.262</td> <td>0.218</td> <td>0.999</td> </tr> <tr> <td>MODIS</td> <td>2.69</td> <td>5.96E-08</td> <td>0.0636</td> <td>1.69E-07</td> <td>0.999</td> <td> </td> </tr> <tr> <td>Reference: Landsat CHL</td> <td> </td> <td>0.0555</td> <td>0.225</td> <td>0.185</td> <td>0.999</td> <td> </td> </tr> <tr> <td>2016 Mar 26th</td> <td>USTFM</td> <td>1.31</td> <td>0.00692</td> <td>0.126</td> <td>0.112</td> <td>0.906</td> </tr> <tr> <td>MODIS</td> <td>1.43</td> <td>4.21E-08</td> <td>0.0263</td> <td>8.43E-08</td> <td>0.997</td> <td> </td> </tr> <tr> <td>Reference: Landsat CHL</td> <td> </td> <td>0.0451</td> <td>0.117</td> <td>0.104</td> <td>0.999</td> <td> </td> </tr> <tr> <td>2016 Dec 23rd</td> <td>USTFM</td> <td>1.75</td> <td>0.0291</td> <td>0.121</td> <td>0.107</td> <td>0.999</td> </tr> <tr> <td>MODIS</td> <td>2.00</td> <td>5.96E-08</td> <td>0.0368</td> <td>1.46E-07</td> <td>0.998</td> <td> </td> </tr> <tr> <td>Reference: Landsat CHL</td> <td> </td> <td>0.0512</td> <td>0.149</td> <td>0.140</td> <td>0.999</td> <td> </td> </tr> </tbody> </table> <p><strong>†</strong> RMSE: compare to reference NASA Landsat 8 chlorophyll-a concentration (mg/m^3).</p> <p><strong>††</strong> Calculated with 9*9 moving window.</p> <h4 id="4-深圳香港海域的实验结果"><strong>4.</strong> <strong>深圳香港海域的实验结果</strong></h4> <p>为了验证我们的方法，我们考虑了另一个研究区域，该区域位于南中国海附近。在这方面，每月的浮标资料由香港环境保护署（https://cd.epic.epd.gov.hk/EPICRIVER/marine/）分享，可用于验证我们的最终叶绿素-a产品。研究区域2如图4所示。</p> <p>蓝色和绿色波段的Rrs预测如图21所示。左列是蓝色波段的比较，右侧是绿色波段。可以对研究区域1进行类似的结论：与MODIS Rrs产品相比，U-STFM模型的预测改善了细节纹理，整体Rrs分布模式更类似于Landsat 8。</p> <p>我们还注意到，与Landsat 8相比，预测Rrs中的详细纹理图案存在一些差异。如前所述，其原因在于图像融合模型不会创建纹理。输出的详细纹理来自Landsat图像的“之前”或“之后”。融合处理可以被视为找到将这两个图像与适当的权重组合的方式。 U-STFM模型中的权重函数来自MODIS时间序列提供的变化率信息。因此，无法很好地预测未在“之前”或“之后”Landsat图像中捕获的图案。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image174.jpg" alt="A picture containing text Description generated with very high confidence"/></p> <p>图 21 2016年11月14日，在研究区域2中，与原始MODIS Rrs和Landsat 8 Rrs相比，蓝色（a-c）和绿色（d-f）带中的U-STFM的Rrs预测。</p> <p>与图22中蓝色和绿色波段的Landsat 8 Rrs数据相比，U-STFM模型的Rrs预测结果如图22所示。观察和预测之间显示出强烈的线性相关性，R平方为0.8521和0.8857。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image176.jpg" alt="A close up of a map Description generated with very high confidence"/></p> <p>图 22 2016年11月14日，研究区域2中蓝色和绿色波段的U-STFM模型预测的1：1图。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image178.jpg" alt="A close up of a map Description generated with very high confidence"/></p> <p>图 23 2016年11月14日，研究区域2中1km空间分辨率的log10（蓝/绿）和log10（MODIS CHL）之间的相关性。</p> <p>与研究区域1相同，NASA的OC2M-HI回归模型也应用于研究区域2，以建立1km规模的log10（叶绿素-a）和log10（蓝/绿）之间的相关性，如图23所示。 最终的叶绿素-a预测如图24所示，子区域如图25所示。 与原始MODIS数据相比，可以得出与研究区域1相同的结论：最终预测在海岸附近具有更详细的纹理。 同时，MODIS数据中显示的基本模式仍然在最终预测中。 与研究区域1相似，预测与Landsat 8叶绿素a产品之间的纹理差异仍然存在，因为图像缩小的基本问题是不适当的。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image180.jpg" alt="img"/></p> <p>图 24 U-STFM的最终叶绿素a浓度预测与Landsat 8和初始MODIS叶绿素a产品相比</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image182.jpg" alt="img"/></p> <p>图 25 图24的局部区域</p> <p>U-STFM与Landsat 8和MODIS叶绿素产物的叶绿素-a预测的1：1比较如图26所示。 总体而言，U-STFM的预测与Landsat 8和MODIS叶绿素产物相关，R平方分别为0.797和0.772。 与高叶绿素a浓度相比，较强的相关性显示低叶绿素-a浓度为0.5至2 mg / m3。 由于尺度差异，较高的变异主要表现在高叶绿素a浓度区域，特别是与MODIS相比。 与Landsat 8产品相比，图26（a）中的小偏差显示了对U-STFM预测的轻微低估。 这种总体偏差的原因可能与MODIS和Landsat传感器之间的频谱响应差异有关。</p> <p><img src="file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image184.jpg" alt="A close up of a map Description generated with very high confidence"/></p> <p>图 26 用Landsat 8和MODIS叶绿素a产品进行U-STFM预测的1：1图</p> <p>表8比较了U-STFM预测，Landsat 8和MODIS产品与原位数据。 在这6个浮标中，RMSE显示Landsat 8和U-STFM具有相似的准确度，分别为0.557和0.503 mg /立方米，并且优于最初的MODIS叶绿素-a产品。</p> <p>Table 8 Comparison of in-situ observations of Hong Kong buoys</p> <table> <thead> <tr> <th>ID</th> <th>Date</th> <th>Name</th> <th>Longitude</th> <th>Latitude</th> <th>In situ observation (mg/m3)</th> <th>U-STFM CHL (mg/m3)</th> <th>Landsat8 CHL (mg/m3)</th> <th>MODIS CHL (mg/m3)</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>11/24/2016</td> <td>MM16</td> <td>114.443</td> <td>22.453</td> <td>2.1</td> <td>2.392</td> <td>1.343</td> <td>2.905</td> </tr> <tr> <td>1</td> <td>11/24/2016</td> <td>MM15</td> <td>114.457</td> <td>22.373</td> <td>1.5</td> <td>2.025</td> <td>1.548</td> <td>1.876</td> </tr> <tr> <td>2</td> <td>11/24/2016</td> <td>MM14</td> <td>114.457</td> <td>22.303</td> <td>1.7</td> <td>1.661</td> <td>1.511</td> <td>1.818</td> </tr> <tr> <td>3</td> <td>11/24/2016</td> <td>MM13</td> <td>114.462</td> <td>22.216</td> <td>1.1</td> <td>1.628</td> <td>1.034</td> <td>1.663</td> </tr> <tr> <td>4</td> <td>11/24/2016</td> <td>MM8</td> <td>114.334</td> <td>22.196</td> <td>1.9</td> <td>1.497</td> <td>1.266</td> <td>1.646</td> </tr> <tr> <td>5</td> <td>11/21/2016</td> <td>SM18</td> <td>114.084</td> <td>22.143</td> <td>0.9</td> <td>1.745</td> <td>1.820</td> <td>2.026</td> </tr> <tr> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td>RMSE</td> <td>0.503</td> <td>0.557</td> <td>0.639</td> </tr> </tbody> </table> <h3 id="329-小节">3.2.9 小节</h3> <p>叶绿素浓度在近海水域附近迅速变化。在本章节中，我们实验了一种方法，将MODIS 1km叶绿素-a产品缩小到30m，以更好地了解近海地区叶绿素a的空间变化。为了实现这一目标，使用到了两种不同的相关性。首先，使用相同位置的不同时间序列观测值之间的相关性来提供详细的图像纹理，以帮助我们预测电磁波谱中蓝色和绿色区域附近的30m遥感反射率。其次，使用1KM规模的MODIS叶绿素a产物与升高的蓝/绿遥感反射率之间的相关性来预测30m水平的高度详细的叶绿素-a产物。选择U-STFM时空融合模型来捕获第一相关性。 NASA OC2M-HI模型用于捕获叶绿素a浓度与遥感反射交叉尺度之间的相关性。</p> <p>选择唐山曹妃甸港附近的一个研究区来测试这种方法。使用Landsat 8 Rrs 482nm和Rrs 561nm作为地面实况数据来评估U-STFM图像融合模型的预测。 2016年3月10日数据的结果显示预测与真实数据之间存在强烈的线性关系，蓝色和绿色波段的R平方分别为0.868和0.881。与MODIS数据相比，预测的带在近海水域附近显示出更加细致的纹理，可以提供有关近海水域附近叶绿素浓度分布的更多信息。其他九个日期的结果也得出了类似的结论。</p> <p>在1km规模的log10（蓝色/绿色）和log10（MODIS CHL）之间保持良好的相关性。正如2016年3月10日的R平方结果显示，大约85％的变化可以通过OC2M-HI回归模型建模，RMSE为0.742。本文还评估了对其他九个目标日期的预测以及类似的结论。根据观察条件，R平方在不同日期变化，从0.54-0.91变化。通过该回归预测30m尺度的叶绿素-a浓度，从U-STFM模型预测30m遥感反射率。与Landsat 8叶绿素-a产品相比，RMSE和局部标准偏差表明，30m规模的最终叶绿素-a浓度改善了近海水域附近的细致质地，并且与原始的MODIS叶绿素-a产品相比保持了准确性。</p> <p>香港附近的另一个研究区域也被选中来测试这种方法。每月的浮标数据由香港环境保护署（https://cd.epic.epd.gov.hk/EPICRIVER/marine/）分享，数据可用于验证我们的最终叶绿素-a产品。类似的结果显示在研究区域2中，Rrs预测与真实数据之间具有强线性关系（蓝色和绿色波段的R平方分别为0.8521和0.8857）。对于这六个浮标，RMSE显示Landsat 8和U-STFM具有相似的准确度，分别为0.557和0.503 mg /立方公尺，并且优于初始MODIS 1km叶绿素a产品。</p> <p>总的来说，在这项研究中，我们使用时间序列的相关性和不同尺度的相关性来推断近海地区附近叶绿素a浓度的空间变化。图像缩小问题通常是不适合的，只能根据先前的知识来推断，但是通过本文中的方法，可以预测30m叶绿素a浓度产品可以帮助我们更好地了解近海水域的更深层物理机制。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[layout: post title: 基于时空混合的MODIS产品降尺度模型-以海表叶绿素为例 date: 2018-02-03 21:01:00 description: 海表叶绿素时空融合 tags: 时空融合 categories: 时空融合算法研发 thumbnail: /assets/img/postImages/2016-02-03-图10.png — 原文链接 https://doi.org/10.1016/j.jag.2018.06.004 海岸带卫星遥感监测数据空间插补和尺度转换技术 海表水色是理解动态海洋生物发展过程的重要因素（Esaias等，1998）。 借助于MODIS Tarra和Aqua卫星的高时间重访频率（每天两次），NASA的MODIS海洋水色产品在过去几十年中被广泛用于海洋动态和全球环境变化的监测（Dasgupta，Singh和Kafatos ，2009; Esaias等，1998; McClain，2009）。 近海水域的水质状况反映了人类与当地环境之间的相互作用，是海洋科学中常见并且重要的一个关键领域（Cherukuru等，2016）。 然而，考虑到MODIS数据的低空间分辨率（1km），使用NASA MODIS海洋色产品难以捕获近海水域的详细信息。 因此，在这些区域获得高空间和时间分辨率数据，从而了解近海环境中生物过程，是当前海洋遥感的迫切要求（Esaias等，1998; McClain，2009）。 在过去的十年中，在计算机视觉和遥感领域，人们一直致力于如何提高低影像观测的空间分辨率（Yang，Wright，Huang，＆Ma，2010; Yue，Shen，Li，Yuan ，＆Zhang，2016）。目前主要的方法有两大类，第一类方法为：图像超分辨率技术，第二类方法为：时空数据融合。 在图像超分辨率领域，其基本假设是：如果这些图像遵循与用于创建低的相同的重采样过程，低空间分辨率图像中的缺失细节可以从其他高空间分辨率图像中学习或重建（Fernandez-Beltran，Latorre-Carmona，＆Pla，2016; Raul Zurita-Milla，Clevers，＆Schaepman，2008）。在这些方法中，关键步骤是准确预测点扩散函数（PSF），它代表形成低分辨率像素的混合过程（Yue et al。，2016）。其中典型的案例是基于图像重建（RE）技术创建PSF，例如迭代反投影（IBP）和PSF反卷积。这些技术提取某些物理特性和特征，以提供有关低空间分辨率图像的更详细信息，并使用常规插值结果对该信息进行聚类，以获得最终的超分辨率图像（Fisher＆Mustard，2004; Miskin＆MacKay，2000; Takeda， Farsiu，＆Milanfar，2007）。这一类方法建立再大量图像样本时，例如在卷积神经网络（CNN）（Dong，Loy，＆He，2016），稀疏编码（Yang等人， ，2010），贝叶斯网络（Lu＆Qin，2014），基于内核的方法（Takeda等，2007），以及基于SVM的方法（H. Zhang＆Huang，2013）。然而，在实践中，低分辨率遥感图像的实际混合过程可能太复杂而不能被基于有限样本的一个通用PSF模型来进行捕获。此外，当尺度比例变大时，这些方法的准确性迅速降低。大多数超分辨率算法的降尺度比为2比4.相反，MODIS和Landsat数据之间的尺度比例为1km / 30m=33.3。由于这种巨大的尺度差异，将这些方法应用在MODIS数据从1km缩小到30m时，最终的结果往往表现的非常不理想。 为了避免构建PSF和通过样本来预测图像的具体细节，时空数据融合技术通过遵循某些规则将精细图像合并到粗糙图像来获得更高的空间分辨率纹理细节。当没有精细的空间分辨率数据可用时，时间序列数据被用作辅助数据在同一位置提供与之对应的细节（B. Chen，Huang，＆Xu，2015）。这些时空数据融合技术基本基于两个假设：时间信息的尺度不变性和空间信息的时间恒定性（H.K. Zhang，Huang，Zhang，Cao＆Yu，2015）。与超分辨率方法相比，时间序列图像融合技术不能直接从粗略数据预测高分辨率细节。相反，它通过对应的算法，结合了在同一位置的时间序列高空间分辨率图像，来提供图像中的细节。目前基于这些技术已经建立了许多应用，例如田间尺度的作物进展（F. Gao等，2017），NDVI时间序列（B. Zhang等，2016），空间和时间表面反射率变化（Emelyanova） ，McVicar，Van Niel，Li和van Dijk，2013），初级生产力总值（Singh，2011），植被季节动态变化（R. Zurita-Milla，Kaiser，Clevers，Schneider，＆Schaepman，2009），森林干扰（Hilker）等人，2009年）和季节性湿地监测（Mizuochi等，2017）。据我们所知，这些时空数据融合技术尚未在海表水色产品上进行数据降尺度的尝试。 基于分离的时空降尺度融合模型（U-STFM）被选取，作为本研究中的时空数据融合的核心技术。原因在于它更适应下垫面的变化（Huang＆Zhang，2014） ）。 U-STFM通过将时间序列的变化率与混合像素的线性分解模型相结合，为快速变化的景观中的时间序列图像融合提供了一种新的处理结构。这种方法已经在土地覆盖变化应用中得到了很好的测试，例如MODIS地表反射率降尺度，并证明了其有效性（Huang＆Zhang，2014）。本章节所遇到的问题是如何使用这个模型来面对海表水色产品的降尺度问题。 当应用U-STFM降低MODIS海表水色叶绿素a浓度产品时，需要解决两个问题。首先，U-STFM模型要求高空间分辨率数据和低空间分辨率数据在时间序列中变化率保持一致。然而，在水色遥感中，在大气校正过程和及使用不同模型对MODIS和Landsat产品处理得到海洋表面叶绿素-a浓度产物的过程中被破坏掉了（Pahlevan，Sarkar，＆Franz，2016）。其次，在U-STFM中，必须减小分割区域的尺寸以获得每个分割区域的更准确的变化率，以便在最终输出中提供更详细的信息。然而，较小的区域可能导致线性非混合方程中得到不一致解，这将导致最终输出中的数据缺口或不合理的预测。 基于U-STFM模型的水色遥感数据插补和重构 U-STFM模型对精细和粗略空间分辨率时间序列数据上的像素或区域需要相同的变化率。由于MODIS和Landsat叶绿素-a产品的变化率的一致性可以被不同的叶绿素a反演模型破坏（Pahlevan等，2016），因此很难直接应用U-STFM对 MODIS和Landsat叶绿素-a产品进行空间降尺度。然而，不同于加工后的产品，初始MODIS和Landsat Rrs产品可以保持变化率的一致性，因为两者遵循具有类似的大气校正过程（Pahlevan等，2017）。这项研究通过首先用时间序列MODIS和Landsat数据预测被测时间的Rrs数据，其次通过以找出预测的反射率数据与MODIS 1km叶绿素-a产品之间的相关性，通过回归来预测最终的高空间分辨率的叶绿素a浓度产品。 在应用U-STFM模型来预测遥感反射率时，面临的第二个问题是分割区域的大小与线性非混合方程的稳定解之间的权衡。分割区域越小，近海叶绿素a的空间异质性越好。然而，较小的分割将导致线性非混合方程中的不一致解，这将导致可观察到的硬分割边界或最终输出中的不合理预测。为了克服数据缺口或不合理的异常值，解决方案是在具有相同目标日期的时间序列数据中多次应用U-STFM模型来估计最可能的预测。最终的结果取所有预测的中值。通过这种方式和，云盖引起的数据缺失也可以填补。图9显示了基本工作流程。整体处理可归纳为以下三个步骤： 1）预处理：按时间序列准备匹配的MODIS和Landsat遥感反射对数据; 2）时空数据融合：使用U-STFM根据匹配的MODIS和Landsat遥感反射对获得的变化率，预测目标日期的高空间分辨率Rrs; 3）回归：建立U-STFM（30m）和MODIS叶绿素-a产物（1km）预测的Rrs之间的回归模型，并预测最终的高空间分辨率叶绿素a数据（30m）。 数据的预处理 在本章节的实例中，我们采用的原始数据是MODIS Rrs 469和Rrs 555，以及Landsat 8 TOA反射率数据中的第2和第3波段。MODIS Rrs 469和Rrs 555来自NASA MODIS每日海表水色2级产品数据，可直接用作 U-STFM的输入参数。 但是，Landsat TOA反射率数据需要在使用前处理为Rrs数据。 在这项研究中，NASA的SeaDAS软件中的L2gen模型被用来完成这项处理，该模型是由NASA的海洋生物处理组（OBPG）（https://seadas.gsfc.nasa.gov/）研发创建，用于通过选择适当的大气校正算法来生成Rrs数据。 Franz，Bailey，Kuring和Werdell（2015）描述了该模型在SeaDAS中应用于Landsat 8开发的大气校正中的实现过程。 此外该模型对MODIS和Landsat Rrs数据应用相同的陆地和云掩模（Concha＆Schott，2016）。 本研究使用了三个主要数据集。其中一个是2013年至2017年的Landsat 8 TOA反射率，可以从USGS Earth Explorer网站（https://earthexplorer.usgs.gov/）下载。 MODIS Rrs和叶绿素-a产品从NASA Ocean Color网站（https://oceancolor.gsfc.nasa.gov/）下载（NASA戈达德太空飞行中心，海洋生态实验室，2014）。 MODIS的重访频率是每天，Landsat 8是16天。由于云层覆盖和遥感反射的质量，大多数近海地区都被云罩掩盖。这导致仅有12个匹配日期，其中有效数据可用作U-STFM模型中的输入。数据的细节显示在表1中.Landsat 8 Rrs 482nm和Rrs 561nm在SeaDAS 7.3.1中用L2gen模型计算。 Landsat的Rrs和MODIS数据都被地理参考到相同的地理框架，以最小化两个传感器之间的几何重合失调。 Landsat 8叶绿素-a产品也在SeaDAS 7.3.1中计算，以L2gen模型作为参考数据，与最终缩小的MODIS叶绿素-a数据进行比较。在L2gen模型中，用于叶绿素a检索的标准NASA算法是三波段经验Rrs带比算法（OC3），其转换为清水中的经验带差算法（OCI）。对于Landsat 8，使用NASA生物光学海洋算法数据集（NOMAD）调整经验系数，以调整相对于传感器的中心波长的差异。这些经验系数可以在NASA海表水色网页（https://oceancolor.gsfc.nasa.gov/atbd/chlor_a/）上找到。 SeaDAS中的叶绿素-a算法使用443,482和561 nm波段作为波段比（Franz，Bailey，Kuring，＆Werdell，2014）。 使用U-STFM时空融合模型进行更高分辨率的遥感反射预测 待预测的目标日期的MODIS数据，以及目标日期之前和之后的至少两个匹配的MODIS和Landsat观测值，需要作为U-STFM模型的输入数据，来预测目标日期的高空间分辨率Landsat数据。 在本节中，以避免对读者造成不必要的混淆，方程的表达与Huang和Zhang 2014年的论文保持一致。 本节简要介绍U-STFM模型。 详细解释可以在Huang和Zhang的论文中找到（Huang＆Zhang，2014），U-STFM的主要步骤如图2所示。 为了预测MODIS像素中更详细的信息，最常见的技术是线性分离技术（Burette，Meroni和Colombo 2008; Zurita-Milla等，2009），线性分离假设低分辨率像素中的反射率可以用在该低空间分辨率像素内的端部成员的平均反射率的线性组合表示。 U-STFM的工作流程如图10所示。 图 10 U-STFM 模型处理流程图 3.2.5 回归模型建立预测光谱和MODIS叶绿素产品的关系 U-STFM模型的输出是电磁波谱的蓝色和绿色区域中的Rrs（30m），具有详细的纹理信息。 接下来，需要适当的回归模型来将反射率数据转换为每日叶绿素-a浓度产物。 该回归的整体工作流程如图11所示。 对于具有相同目标日期的不同三日期对，U-STFM模型被多次应用以避免不稳定的解混解决方案。 结果，在同一天，预测了几个遥感反射率。 这些预测的中值用于每个像素。 选择中位数统计量的原因是线性非混合过程的不稳定解决方案要么没有解决方案要么给出大值，这可以被认为是多个预测的异常值。 同时，该程序还可以填补MODIS观测中由云层和坏像素引起的数据缺口。 图11 MODIS叶绿素产品空间降尺度流程图 电磁波谱的蓝色区域（450-495nm）和绿色区域（495-570nm）的Rrs与叶绿素-a浓度高度相关，这是由于叶绿素-a在这些区域的强烈吸收和反射(Hu, et al., 2012; Morel, Maritorena, 2001; Werdell, Bailey, 2005)。目前用于MODIS的默认叶绿素算法基于几种OCx形成的算法，其系数使用来自NASA生物光学海洋算法数据集（NOMAD）版本2的原位数据导出（https://oceancolor.gsfc.nasa.gov/后处理/ R2009 / ocv6 /）。在该研究中，OC2M-HI带比回归模型（方程10）用于建立蓝带，绿带和叶绿素-a浓度之间的相关性（O’Reilly等，2000）。由于MODIS叶绿素a产品的原始分辨率为1km，所以通过使用ArcMap中的平均聚合方法将U-STFM遥感反射率从30m扩展到1km，首先建立了1km规模的相关性（ESRI，https：// www .esri.com / EN-US /家）。 3.2.6 实验验证方案 两个测试已应用于降尺度过程的两个主要步骤。 一种是检查是否正确预测了高空间分辨率（30 m）的遥感反射率。 第二是测试最终的高分辨率叶绿素产品是否与原始的MODIS叶绿素-a产品一致。 1. 高空间分辨率Rrs数据测试 Landsat 8蓝色和绿色的遥感反射被用作该测试中的地面实测数据，使用SeaDAS l2gen模型与Landsat 8 TOA数据在与观察MODIS数据相同的日期进行处理。 应该注意的是，Landsat 8的当地观测时间早于上午10:30，比MODIS Aqua数据提前4小时，因此如果原始MODIS数据也是如此，预测的准确性低可能是由于此期间的水运动造成的。 显示Landsat数据的准确度低。 使用预测数据和观察数据之间的平均绝对差（AAD），平均相对差（ARD），相关系数（CC）和均方根误差（RMSE）来评估U-STFM图像融合模型的性能。 2. 最终预测结果与原始MODIS数据产品一致性分析 本文的主要目的是在近海地区附近的MODIS 1km叶绿素产品中生产更高空间分辨率的日叶绿素a产品。这种最终的高分辨率叶绿素产品是否与最初的MODIS 1km叶绿素一致 - 需要测试具有相似精度的产品。 在同一天测试的Landsat 8叶绿素-a产品用作参考数据，以比较最终的较高空间分辨率叶绿素-a产物和原始MODIS叶绿素-a产物。计算了两个RMSE。一个是最终叶绿素-a产品和参考数据之间的RMSE。另一个是原始MODIS产品和参考数据之间的RMSE。如果这两种RMSE保持相似，则意味着最终的叶绿素a产品与最初的MODIS 1km叶绿素a产品一致。 使用局部标准偏差（9×9窗口）来定量评估图像中包含的局部信息。具有较高纹理的较高空间分辨率图像将显示较大的局部标准偏差值，反之亦然。 3.2.7 实例研究区域 渤海湾是形成渤海湾的三个海湾之一，是中国东北第二大渤海湾。海河和其他15条河流流入渤海湾。因此，整个华北平原的径流集中在渤海湾，海湾是一个受到严重污染的水体（X. Chen et al。，2010）。渤海湾环绕着几个主要港口：天津港，唐山曹妃甸港，京唐港和黄骅港，使海湾成为一条拥挤的水道。渤海周边近海地区是中国人口密度最大，工业化程度最高的三个地区之一（X. Gao＆Chen，2012）。根据中国国家海洋局的报告，渤海遭受工业废弃物，农业，土壤侵蚀，商业废弃物和污水造成的严重水污染。海岸和港口附近的化学需氧量（COD）和溶解氧（DO）仍然很高，而且随着海湾地区的经济增长而增加（PEMSEA和BSEMP，2005）。因此，高空间分辨率的海洋色产品对于该领域的环境评估至关重要。 研究区域1选自位于中国渤海湾东北部的唐山曹妃甸港附近的海域。它是一个约1638 Km2的区域，具有高人类活动（118.402°E-118.842°E和38.805°W-39.189°W）。港口活动和河流污水在该地区产生高浓度的叶绿素和重金属。图4显示了唐山曹妃甸港及其附近海域的面积。 本章第二个研究区在深圳香港海域，该区域人类活动频繁，海面环境复杂，岛屿众多，海表纹理丰富。同时该区域有相应的 实测浮标数据，可以对最终产品的精度提供验证。 图 4 研究区域1：渤海湾海域，研究区域2：深圳香港海域 本研究使用了三个主要数据集。其中一个是2013年至2017年的Landsat 8 TOA反射率，可以从USGS Earth Explorer网站（https://earthexplorer.usgs.gov/）下载。 MODIS Rrs和叶绿素-a产品从NASA Ocean Color网站（https://oceancolor.gsfc.nasa.gov/）下载（NASA戈达德太空飞行中心，海洋生态实验室，2014）。 MODIS的重访频率是每天，Landsat 8是16天。由于云层覆盖和遥感反射的质量，大多数近海地区都被云罩掩盖。这导致仅有12个匹配日期，其中有效数据可用作U-STFM模型中的输入。数据的细节显示在表1中.Landsat 8 Rrs 482nm和Rrs 561nm在SeaDAS 7.3.1中用L2gen模型计算。 Landsat的Rrs和MODIS数据都被地理参考到相同的地理框架，以最小化两个传感器之间的几何重合失调。 Landsat 8叶绿素-a产品也在SeaDAS 7.3.1中计算，以L2gen模型作为参考数据，与最终缩小的MODIS叶绿素-a数据进行比较。在L2gen模型中，用于叶绿素a检索的标准NASA算法是三波段经验Rrs带比算法（OC3），其转换为清水中的经验带差算法（OCI）。对于Landsat 8，使用NASA生物光学海洋算法数据集（NOMAD）调整经验系数，以调整相对于传感器的中心波长的差异。这些经验系数可以在NASA海表水色网页（https://oceancolor.gsfc.nasa.gov/atbd/chlor_a/）上找到。 SeaDAS中的叶绿素-a算法使用443,482和561 nm波段作为波段比（Franz，Bailey，Kuring，＆Werdell，2014）。 Table 1 Data list of Landsat 8 and MODIS Aqua Ocean Color Level 2 products used in study area 1 Date Landsat 8 TOA and MODIS Aqua Ocean Color Data names Bands in use 2013 Sep 26th LC81220332013269LGN00.tar.gz Landsat 8: Band 2 and Band 3 MODIS: Rrs 469nm, Rrs 555nm and chlorophyll-a product were used in this study. A2013269053000.L2_LAC_OC.nc     2013 Nov 29th LC81220332013333LGN00.tar.gz   A2013333053000.L2_LAC_OC.nc     2014 Aug 12nd LC81220332014224LGN00.tar.gz   A2014224053000.L2_LAC_OC.nc     2014 Sep 13rd LC81220332014256LGN00.tar.gz   A2014256053000.L2_LAC_OC.nc     2015 Jan 19th LC81220332015019LGN00.tar.gz   A2015019053000.L2_LAC_OC.nc     2015 Oct 2nd LC81220332015275LGN00.tar.gz   A2015275053000.L2_LAC_OC.nc     2015 Dec 5th LC81220332015339LGN00.tar.gz   A2015339053000.L2_LAC_OC.nc     2016 Jan 6th LC81220332016006LGN00.tar.gz   A2016006053000.L2_LAC_OC.nc     2016 Mar 10th LC81220332016070LGN00.tar.gz   A2016070053000.L2_LAC_OC.nc     2016 Mar 26th LC81220332016086LGN00.tar.gz   A2016086053000.L2_LAC_OC.nc     2016 Dec 23rd LC81220332016358LGN00.tar.gz   A2016358053000.L2_LAC_OC.nc     2017 Feb 25th LC81220332017056LGN00.tar.gz   A2017056053000.L2_LAC_OC.nc     Table 2 Data list of Landsat 8 and MODIS Aqua Ocean Color Level 2 products in study area 2 Date Landsat 8 TOA And MODIS Aqua Ocean Color Data names Bands in use 2014 Nov.25 LC08_L1TP_121045_20141125_20170417_01_T1.tar.gz A2014329052000.L2_LAC_OC.nc Landsat 8: Band2 and Band 3 MODIS: Rrs 469nm, Rrs 555nm and chlorophyll-a product were used in this study. 2016 Nov.14 LC08_L1TP_121045_20161114_20170318_01_T1.tar.gz A2016319052000.L2_LAC_OC.nc   2017 Nov.1 LC08_L1TP_121045_20171101_20171109_01_T1.tar.gz A2017305052000.L2_LAC_OC.nc   3.2.8 实验结果和讨论 1. 利用U-STFM模型来对海域Rrs反射率数据进行预测 本研究收集了12对有效的MODIS和Landsat 8数据。在本节中，目标预测日期设置为2016年3月10日。其他日期的结果也会在稍后显示。由于U-STFM模型需要三对（在目标之前 - 之后的日期）进行预测，因此有24个之前的目标后案例，导致2016年3月10日的遥感反射总数预测为24个。原样如图5所示，云层和坏水像素被掩盖为黑色。有效区域受到前期目标后日期的质量的高度影响，因为只有在三个图像中的每一个中相同的像素有效时才能认为该像素对于预测是有效的。通过获得每个位置的这些图像的中值，将这24个预测合并为单个预测。 2016年3月10日在Rrs蓝带中的U-STFM的最终预测如图6（b）所示。将其与图6（a）中所示的原始MODIS粗Rrs 469数据和图6（c）中所示的地面实况Landsat 8频带2（Rrs 482nm）进行比较。与MODIS数据相比，预测显示在海湾区域附近更加详细的纹理，其中遥感反射率因人类活动和水流而变化。同时，预测保持与MODIS数据相同的基本分布模式趋势。与Landsat 8数据相比，U-STFM模型的预测已经捕获了该海湾区域中遥感反射率的空间变化的基本模式。出现在图像之前或之后的那些纹理仍保留在预测中。根据之前的研究，U-STFM模型更适应前后图像中的景观变化（Huang＆Zhang，2014; H.K. Zhang et al。，2015）。因此，预测中显示的纹理是在图像之前或之后已经出现的纹理。那些仅出现在目标日期（2016年3月10日）但未被MODIS数据捕获的纹理无法通过U-STFM模型预测。用MODIS和Landsat 8 Rrs数据进行的预测区域岛附近的详细比较如图7所示。 图 5 2016年3月10日，使用U-STFM图像融合模型（分割区域&gt; 10000）在研究区域的蓝色波段进行24种不同的Rrs预测。 每个预测都使用“第一日期 – 预测日期- 第二日期”日期命名。 图 6 2016年3月10日，蓝色波段的U-STFM（分割区域&gt; 10000）与原始MODIS Rrs 469和Landsat 8 Rrs 482nm的预测相比较。 图 7 2016年3月10日，局部海湾区域在蓝色波段的U-STFM预测与原始MODIS Rrs 469和Landsat 8 Rrs 482nm相比。 同样，2016年3月10日，绿色波段U-STFM的时间序列预测也与MODIS Rrs555 nm和地面实况Landsat 8 Rrs 561 nm进行了比较。这些结果如图8和图9所示。以类似的方式，如对蓝色带中的预测所做的那样，可以通过U-STFM模型很好地预测由海湾区域中的局部水流引起的详细纹理。仅在2016年3月10日的Landsat数据中出现并且未被MODIS数据捕获的纹理不容易预测。其原因在于，在U-STFM模型中，MODIS数据是目标日期唯一有效的观测值。预测中显示的纹理来自目标日期之前和之后拍摄的Landsat图像中的纹理以及目标日期的MODIS图像。如果这些图像不包含详细纹理，那么这些纹理（仅在2016年3月10日由Landsat数据捕获）无法通过图像融合模型预测。图9显示了预测与MODIS和Landsat 8数据的详细子区域比较。 图 8 2016年3月10日，绿色波段的U-STFM预测与原始MODIS Rrs 555nm和Landsat 8 Rrs 561 nm相比。 。 图 9在绿色带中的U-STFM预测中的湾区的子区域。 与2016年3月10日的原始MODIS Rrs 555nm和Landsat 8 Rrs 561相比。 如图10（a）所示，来自蓝带中24个U-STFM预测的中值的位置随机分布在研究区域上。这意味着24个预测中没有一个案例支配最终输出。换句话说，每个案例都可以看作是最终产出的等价贡献。 通常，数据对越接近目标日期，预测就越准确。如图10（c）和图10（d）所示，X轴是每个“之前 - 之后 - 之后”组中第一个和最后一个日期之间的天数。数字越小，图像之前和之后越接近目标日期。与Landsat Rrs产品相比，Y轴是预测的RMSE。总体而言，随着天数的增加，RMSE略有增加，这证实了日常距目标日期越近的常识，预测就越准确。由于天数较少，预测的不确定性较小。这可以在图10（c）中所示的较低RMSE波动中看出，并且表明更接近的数据对将导致更稳定的预测。 考虑到图10（c-d）中没有显着的增加模式，RMSE在可接受的范围内增加（在蓝色波段中从约0.015到0.027）。这表明随着天数的增加，总体准确性不会显着降低。在绿带的预测中可以找到类似的结果，如图10（d）所示。为了填补数据空白并获得多个预测的好处，中位数统计值被认为是组合所有这些预测的适当方式。图10（b）显示了与Landsat Rrs 482相比，蓝带中预测的绝对误差的空间分布。 图 10（a）蓝色波段24个U-STFM_M预测的中值位置; （b）2016年3月10日，与Landsat 8 Rrs 482nm相比，U-STFM_M中位数的绝对误差分布。（cd）RMSE通过每个“第一日期 – 预测日期- 第二日期”日期之前和之后日期之间的天数 组。 数字越小，图像之前和之后越接近目标日期。 U-STFM模型的Rrs预测的30m比例的1：1图与蓝色和绿色波段的Landsat 8 Rrs数据相比如图11所示。观察和预测之间显示出强烈的线性相关性。 在蓝色和绿色波段中，R平方分别为0.868和0.881，RMSE为0.00177和0.00202（表2）。 这表明来自U-STFM模型的预测类似于具有空间细节的地面实况Landsat数据。 这些Rrs预测可以进一步用于在近海地区附近产生高空间分辨率的叶绿素a浓度。 图 11 2016年3月10日蓝色和绿色波段的U-STFM模型的1：1预测图。 在表3中，预测和原始MODIS数据在2016年3月10日与NASA Landsat Rrs观测数据进行了定量比较。与原始MODIS Rrs数据相比，预测具有更低的RMSE，更低的平均绝对差异（AAD）和更低的平均值 相对差异（ARD），因为预测捕获更多具有更高空间分辨率的空间细节。 Table 3. Prediction accuracy assessment of predicted blue and green bands on Mar 10th 2016 in the U-STFM model compared to NASA Landsat Rrs observations Band RMSE CC AAD ARD (%) R-Square Predicted Blue 0.00177 0.920 0.00143 11.5% 0.868 Predicted Green 0.00202 0.930 0.00159 8.02% 0.881 Original MODIS Blue (Rrs 469nm) † 0.00367 0.932 0.00346 26.7% 0.883 Original MODIS Green (Rrs 555nm) † 0.00439 0.938 0.00405 18.7% 0.892 † resampled to 30m scale by nearest neighbor interpolation for comparison. 在理想条件下，MODIS和OLI衍生的Landsat产品之间的Rrs应该是一致的。根据Pahlevan等人的说法。 （2017年），OLI衍生的Landsat Rrs产品在蓝色带中比VIIRS和MODIS Aqua更亮（平均约10％）。产品在绿色带中最为一致（Pahlevan等，2017）。 一些因素可以显着降低这种一致性，例如从上午10:30到下午2点的水运动，由Rrs建模引起的残差和从上午10:30到下午2:00的大气条件变化。 表3显示了在其他可测试日期的遥感反射率的预测准确度评估。它清楚地表明，原始的MODIS遥感反射率数据与Landsat 8 Rrs具有良好的相关性（表3中标有*），R平方高于0.7。换句话说，由上午10:30到下午2点的水运动引起的反射率差异可以忽略不计，U-STFM预测的较高空间分辨率反射率具有较低的RMSE和较高的ARD。这意味着U-STFM预测蓝色和绿色波段的遥感反射捕捉了近海地区海表水色空间分布的细节。 表4还显示，当原始MODIS和Landsat 8数据之间出现较低的R平方时，与2013年11月29日的情况一样; 2014年8月12日; 2014年9月13日; 2015年12月5日，MODIS与Landsat Rrs之间的一致性被打破。在这些情况下，Landsat数据不能被视为基础事实，因为很难判断预测误差是来自U-STFM模型还是MODIS和Landsat数据之间的差异。然而，该结果证实了U-STFM模型与原始MODIS数据高度相关的预测。当MODIS用Landsat 8数据显示高或低R平方时，预测显示类似的R平方值，反之亦然。 Table 4. Prediction accuracy assessment of predicted blue and green bands on other target dates compared to NASA Landsat 8 Rrs observations The target date Band RMSE CC ADD ARD (%) R-Square† 2013 Nov 29th Predicted Blue 0.00167 0.616 0.00134 10.4% 0.372 Predicted Green 0.00166 0.777 0.00130 7.00% 0.622   Original MODIS Blue (Rrs 469nm) 0.00258 0.587 0.00211 15.3% 0.306   Original MODIS Green (Rrs 555nm) 0.00272 0.797 0.00235 11.9% 0.657   2014 Aug 12nd Predicted Blue 0.00302 0.587 0.00216 80.5% 0.393 Predicted Green 0.00385 0.715 0.00268 38.7% 0.562   Original MODIS Blue (Rrs 469nm) 0.00261 0.595 0.00186 68.0% 0.401   Original MODIS Green (Rrs 555nm) 0.00372 0.710 0.00254 36.1% 0.555   2014 Sep 13rd Predicted Blue 0.00225 0.706 0.00179 26.7% 0.518 Predicted Green 0.00206 0.822 0.00163 14.5% 0.695   Original MODIS Blue (Rrs 469nm) 0.00196 0.753 0.00157 19.8% 0.591   Original MODIS Green (Rrs 555nm) 0.00227 0.825 0.00177 13.5% 0.696   2015 Jan 19th Predicted Blue 0.00162 0.945 0.00122 8.63% *0.903 Predicted Green 0.00194 0.945 0.00149 7.52% *0.904   Original MODIS Blue (Rrs 469nm) 0.00372 0.944 0.00350 23.6% *0.901   Original MODIS Green (Rrs 555nm) 0.00391 0.950 0.00351 16.7% *0.915   2015 Oct 2nd Predicted Blue 0.00140 0.912 0.00104 11.8% *0.850 Predicted Green 0.00150 0.945 0.00111 7.29% *0.906   Original MODIS Blue (Rrs 469nm) 0.00246 0.926 0.00214 20.4% *0.878   Original MODIS Green (Rrs 555nm) 0.00282 0.947 0.00239 14.2% *0.911   2015 Dec 5th Predicted Blue 0.00315 0.0285 0.00240 15.4% 0.000745 Predicted Green 0.00348 0.369 0.00258 11.3% 0.148   Original MODIS Blue (Rrs 469nm) 0.00318 0.0412 0.00261 15.3% 0.000987   Original MODIS Green (Rrs 555nm) 0.00392 0.376 0.00334 13.5% 0.169   2016 Jan 6th Predicted Blue 0.00211 0.850 0.00163 9.37% *0.748 Predicted Green 0.00158 0.948 0.00120 4.66% *0.911   Original MODIS Blue (Rrs 469nm) 0.00436 0.921 0.00404 21.5% *0.860   Original MODIS Green (Rrs 555nm) 0.00493 0.971 0.00467 16.8% *0.952   2016 Mar 10th Predicted Blue 0.00177 0.920 0.00143 11.5% *0.868 Predicted Green 0.00202 0.930 0.00159 8.02% *0.881   Original MODIS Blue (Rrs 469nm) 0.00367 0.932 0.00346 26.7% *0.883   Original MODIS Green (Rrs 555nm) 0.00439 0.938 0.00405 18.7% *0.892   2016 Mar 26th Predicted Blue 0.00186 0.815 0.00129 19.4% *0.736 Predicted Green 0.00196 0.907 0.00150 8.10% *0.844   Original MODIS Blue (Rrs 469nm) 0.00348 0.858 0.00318 28.9% *0.794   Original MODIS Green (Rrs 555nm) 0.00396 0.922 0.00357 16.6% *0.870   2016 Dec 23rd Predicted Blue 0.00322 0.848 0.00270 14.0% *0.772 Predicted Green 0.00261 0.940 0.00215 7.66% *0.898   Original MODIS Blue (Rrs 469nm) 0.00585 0.895 0.00556 28.0% *0.843   Original MODIS Green (Rrs 555nm) 0.00649 0.961 0.00616 20.9% *0.940   † R-Square: comparing to Landsat 8 remote-sensing reflectance observation on the target date. Marked with (*) when R-square larger than 0.7. 2. U-STFM 模型和 STARFM 已及ESTARFM模型进行比较 Huang和Zhang（2014）基于物候和土地覆盖变化的模拟和实际数据集，展示了U-STFM模型与STARFM和ESTARFM模型的性能比较。在本节中，我们还想了解U-STFM模型在近海水域Rrs预测中与STARFM和ESTARFM相比的表现。 分割区域的数量是U-STFM模型中的基本参数。如引言中所述，分割区域越小（区域数越大），近海水的空间异质性越好。然而，较小的分割区域将导致线性非混合方程中的不一致解，这将导致最终输出中的“硬边界”或不合理的预测。 在下面的比较中，我们提出了U-STFM模型的两个结果。一个是对大量分割区域（超过10,000个区域）的预测，在4.1节中以U-STFM_M表示。另一种是对较少数量的分割区域（少于1,000个区域）的预测，称为U-STFM_L。区域的最佳数量可能因不同的研究区域而异。 2016年3月10日STARFM，ESTARFM，U-STFM_M和U-STFM_L的性能比较如图12（a） - （f）和图13（a） - （f）所示，蓝色和绿色带分别。这些结果是根据24个不同的“之前 - 之后 - 之后”日期组计算的，使用NASA Landsat Rrs观测结果作为基本事实。我们可以看到，U-STFM模型的性能优于STARFM，具有较低的RMSE，ADD和ARD以及较高的CC和R-Squared。一个可能的原因可能是U-STFM中的时间比率解混过程更适合于捕获特征变化并且受不同数据组所涉及的不确定性的影响较小。其次，U-STFM和ESTARFM的性能相似，但U-STFM模型存在更好的稳定性，箱形图偏差较小。这些结果表明，U-STFM的预测更稳定，并且受不同“之前 - 之后 - 之后”日期组的不确定性的影响较小。 与STARFM相比，U-STFM在处理长时间间隔时表现更好，如下图12（g）和图13（g）所示。当天数增加时，U-STFM的RMSE低于STARFM。与ESTARFM相比，当天数超过500时，U-STFM的性能稍好一些。应该注意的是，图像融合模型不会产生纹理。输出的详细纹理来自目标日期之前或之后的Landsat图像。融合处理可以被视为找到将这两个图像与适当的权重组合的方式。任何融合模型的要求是使一个Landsat图像保持接近目标日期。 图 12 2016年3月10日，蓝色光谱段中STARFM，ESTARFM，U-STFM_M（分割区域数&gt; 10000）和U-STFM_L（分割区域数&lt;1000）的比较。（a）RMSE; （b）相关系数; （c）ADD; （d）ARD; （f）与NASA Landsat Rrs观测值的R-平方线性回归; （g）不同模型不同天数间隔下的RMSE比较。 图 13 2016年3月10日，绿色光谱段中STARFM，ESTARFM，U-STFM_M（分割区域数&gt; 10000）和U-STFM_L（分割区域数&lt;1000）的比较。（a）RMSE; （b）相关系数; （c）ADD; （d）ARD; （f）与NASA Landsat Rrs观测值的R-平方线性回归; （g）不同模型不同天数间隔下的RMSE比较。 在计算2016年3月10日的24 U-STFM，STARFM和ESTARFM预测的中值后，这三个模型的中值图像看起来相似，尤其是在U-STFM_L和ESTARFM之间，如图4和图5所示。对此的一个原因是中值处理增加了预测的稳定性并减小了这三个模型之间的差异。与图6-9（c）中Landsat Rrs的STARFM中值图像相比，U-STFM_L和ESTARFM中海湾区域附近图像的纹理更自然，更平滑。 我们还注意到，U-STFM模型中的图像分割处理可以在预测中留下一些清晰的图像分割“边界”。当分割多边形在观察期间很好地表示水变化时，这些边界通过提供更清晰的纹理来帮助识别变化区域，如图13的U-STFM_L所示。然而，当分割区域的数量增加时，硬边界更加可观察。中值计算可以显着减少这些硬边界，但是当分割多边形太小时，这个小区域中的大多数预测都是不合理的。这些“硬边界”可以在中值处理之后保留，这导致在图6（b）和图8（b）中的U-STFM_M的预测中在海外区域中示出的“网格点”。 图 14 2016年3月10日，蓝色波段中，STARFM的中值，U-STFM_L（分割区域的数量&lt;1000）中值和ESTARFM模型之间的比较。 图 15图14中的局部区域 图 16 2016年3月10日，绿色波段中，STARFM的中值，U-STFM_L（分割区域的数量&lt;1000）中值和ESTARFM模型之间的比较。 图 17 图16中的局部区域 3. MODIS叶绿素产品空间插补结果 NASA MODIS 1km海表水色产品已被用作回归模型中的因变量。使用ArcMap中的平均聚合工具将来自U-STFM_M模型的预测的30米蓝色和绿色条带放大到1km，其已被用作该回归模型中的独立变量。从U-STFM_M而不是U-STFM_L选择预测的原因是我们要将U-STFM_M视为U-STFM模型的最差情形。如果我们能够从最坏的情况中获得合理的输出，优化的U-STFM模型将只有更好的结果。 如2.2节所述，NASA的OC2M-HI回归模型用于建立log10（叶绿素-a）和log10（蓝/绿）之间的相关性。 2016年3月10日1km空间分辨率下log10（蓝色/绿色）和log10（MODIS CHL）之间的相关性如图18所示.R平方显示这两个变量之间存在很强的相关性，其中85％的变化由回归函数。这是基于这种关系在不同尺度上是通用的假设，并且在粗略空间分辨率下建立的关系可以在精细空间分辨率下应用。本研究中使用的最终回归函数是：   (12)     图 18 2016年3月10日1km空间分辨率的log10(Blue/Green)和log10（MODIS CHL）之间的相关性。 log10(blue/green)和log10(MODIS CHL)之间的相关性在不同日期有所不同。 表5显示了不同日期的这些相关性。 R平方从2016年3月26日的0.542到2015年1月19日的0.91不等。这个结果有两个可能的原因。 首先，log10（蓝色/绿色）对蓝色和绿色的变化高度敏感，特别是当反射率值在蓝色和绿色波段接近0时。 大气条件的微小差异可能导致log10（蓝色/绿色）的巨大差异，这将降低与MODIS叶绿素-a产物的相关性。 其次，由于MODIS像素中的实际聚合过程比平均过程复杂得多，因此从U-STFM从30m到1km升级预测的Rrs数据的平均聚合处理可能涉及额外的不确定性。 Table 5. The correlation between log10(Blue/Green) and log10(MODIS CHL) at 1km spatial resolution on other target dates   2013 Nov 29th 2014 Aug 12nd 2014 Sep 13rd 2015 Jan 19th 2015 Oct 2nd 2015 Dec 5th 2016 Jan 6th 2016 Mar 10th 2016 Mar 26th 2016 Dec 23rd R-Square 0.545 0.557 0.760 0.910 0.706 0.889 0.701 0.850 0.542 0.615 RMSE† 0.496 0.771 0.532 0.681 0.5757 0.100 0.391 0.742 0.371 0.420 † RMSE: (mg/m^3). Landsat 8叶绿素-a产物用作MODIS Chl和U-STFM叶绿素-a预测之间比较的参考。本研究中从Landsat-8中回收的叶绿素-a由美国宇航局海洋生物处理小组创建的SeaWiFS数据分析系统（SeaDAS）生成。通过Landsat 8在切萨皮克湾检索到的Rrs和叶绿素a浓度与MODIS，SeaWiFS和原位历史叶绿素a测量结果的比较显示出相对较好的一致性（Concha＆Schott，2016; Franz，Bailey，Kuring，＆Werdell， 2015年）。 这项研究的主要目的是找到一种适当的方法来改善近海水域的细致质地并保持准确性，与原始的MODIS叶绿素-a产品相比。逻辑是通过使用Landsat-8叶绿素产品作为参考，如果最终产量的RMSE与原始MODIS叶绿素产品的RMSE相似或更好，则原始MODIS产品的准确性得以保持。此外，如果输出显示近海水域附近更详细的空间变化，则近海水域附近的详细纹理得到改善。 2016年3月10日对30m叶绿素a浓度的最终预测显示在图19b中。与原始MODIS数据（图19a）相比，最终预测在海岸区域附近具有更详细的纹理。同时，MODIS数据中显示的基本模式仍然在最终预测中。两个原因可能导致预测（图19b）和Landsat 8 Chl产品（图19c）之间的差异：MODIS和Landsat数据之间观察时间的差异，最重要的是叶绿素a检索和 MODIS和Landsat数据中使用的大气校正算法不同，这可能会导致MODIS和Landsat Chl产品之间的差异。 图 19 2016年3月10日最终预测30m规模的叶绿素a浓度。（a） - （c）整个研究区域的概况。 （d） - （f）岛屿附近的次区域。 使用局部标准偏差（9×9窗口）来定量评估图像中包含的局部信息。具有较高纹理的较高空间分辨率图像将显示较大的局部标准偏差值，反之亦然。 为了公平比较，通过插值工具将原始MODIS Chl数据重新采样到30m。用9×9移动窗口计算局部标准偏差。大于1的值被视为异常值，并从统计信息中删除，这通常在搜索窗口穿过图像边缘时发生。还删除值0以避免低估局部标准偏差的平均值和中值，尤其是在MODIS 30m重采样数据中。 如图20中的直方图所示，尽管去除了0值，但MODIS Chl产品中的大部分局部标准偏差仍然接近0，平均值为0.0636，中值为1.69E-07。与MODIS相比，最终的Chl预测恢复了更多的局部纹理细节，平均值等于0.262并且中值等于0.218。这些结果表明，来自U-STFM模型的最终预测改善了每个像素中的纹理细节。 表6给出了U-STFM Ch1和MODIS Ch1的局部标准偏差和RMSE的细节。与Landsat Chl相比，MODIS Chl和U-STFM Chl的RMSE非常相似，分别为2.69和2.39。这表明U-STFM模型保持了原始MODIS Chl的准确性。 图 20 2016年3月10日当地标准偏差与9X9窗口的直方图：（a）MODIS叶绿素a浓度，（b）U-STFM模型的叶绿素a浓度，以及（c）Landsat 8叶绿素a浓度 Table 6 RMSE and local standard deviation of upscaled chlorophyll-a concentration from U-STFM compared to original MODIS Chl and Landsat 8 Chl products. ID RMSE compare to Landsat † Local standard deviation ††       Min Mean Median Max     USTFM CHL 2.39 0.0154 0.262 0.218 0.999 MODIS CHL 2.69 5.96E-08 0.0636 1.69E-07 0.999 Reference: Landsat CHL   0.0555 0.225 0.185 0.999 † RMSE: compare to reference NASA Landsat 8 chlorophyll-a concentration (mg/m^3). †† Calculated with 9*9 moving window. 表7显示了不同日期之间的类似结果。 总的来说，RMSE在U-STFM Chl和MODIS Chl之间是相似的。 有时，U-STFM模型的结果具有较低的RMSE。 如果不这样做，那是因为RMSE值很容易受到异常值的影响。 总的来说，这两个RMSE的差异很小。 这表明回归模型的最终预测基本上与原始的NASA MODIS Chl产品相似。 然而，局部标准偏差一致地表明U-STFM Chl预测具有比原始NASA MODIS Chl产品更高的局部纹理细节。 Table 7. RMSE and local standard deviation of upscaled chlorophyll-a concentration from U-STFM compared to original MODIS Chl and Landsat 8 Chl products. The target date ID RMSE compare to Landsat † Local standard deviation ††       Min Mean Median Max       2013 Nov 29th U-STFM CHL 1.08 0.006 0.140 0.099 0.999 MODIS CHL 1.22 4.21E-08 0.035 8.43E-08 0.995   Reference: Landsat CHL   0.075 0.177 0.162 0.999   2014 Aug 12nd USTFM 4.08 0.0127 0.235 0.215 0.997 MODIS 4.10 5.96E-08 0.112 1.46E-07 0.999   Reference: Landsat CHL   0.0942 0.474 0.413 0.999   2014 Sep 13rd USTFM 1.99 0.0117 0.175 0.137 0.999 MODIS 1.88 4.21E-08 0.0272 8.43E-08 0.997   Reference: Landsat CHL   0.0590 0.289 0.209 1   2015 Jan 19th USTFM 2.81 0.0244 0.267 0.181 0.999 MODIS 2.90 4.21E-08 0.0411 1.19E-07 0.999   Reference: Landsat CHL   0.0442 0.119 0.0986 0.999   2015 Oct 2nd USTFM 1.48 0.00301 0.107 0.0572 0.999 MODIS 1.37 4.21E-08 0.0291 1.03E-07 0.999   Reference: Landsat CHL   0.0686 0.235 0.194 1   2015 Dec 5th USTFM 0.977 0.0023 0.123 0.0832 0.999 MODIS 0.958 4.21E-08 0.0399 8.43E-08 0.993   Reference: Landsat CHL   0.0737 0.206 0.180 0.999   2016 Jan 6th USTFM 1.37 3.79E-30 0.0827 0.0534 0.999 MODIS 1.44 5.96E-08 0.0382 1.19E-07 0.998   Reference: Landsat CHL   0.0517 0.151 0.138 0.999   2016 Mar 10th USTFM 2.39 0.0154 0.262 0.218 0.999 MODIS 2.69 5.96E-08 0.0636 1.69E-07 0.999   Reference: Landsat CHL   0.0555 0.225 0.185 0.999   2016 Mar 26th USTFM 1.31 0.00692 0.126 0.112 0.906 MODIS 1.43 4.21E-08 0.0263 8.43E-08 0.997   Reference: Landsat CHL   0.0451 0.117 0.104 0.999   2016 Dec 23rd USTFM 1.75 0.0291 0.121 0.107 0.999 MODIS 2.00 5.96E-08 0.0368 1.46E-07 0.998   Reference: Landsat CHL   0.0512 0.149 0.140 0.999   † RMSE: compare to reference NASA Landsat 8 chlorophyll-a concentration (mg/m^3). †† Calculated with 9*9 moving window. 4. 深圳香港海域的实验结果 为了验证我们的方法，我们考虑了另一个研究区域，该区域位于南中国海附近。在这方面，每月的浮标资料由香港环境保护署（https://cd.epic.epd.gov.hk/EPICRIVER/marine/）分享，可用于验证我们的最终叶绿素-a产品。研究区域2如图4所示。 蓝色和绿色波段的Rrs预测如图21所示。左列是蓝色波段的比较，右侧是绿色波段。可以对研究区域1进行类似的结论：与MODIS Rrs产品相比，U-STFM模型的预测改善了细节纹理，整体Rrs分布模式更类似于Landsat 8。 我们还注意到，与Landsat 8相比，预测Rrs中的详细纹理图案存在一些差异。如前所述，其原因在于图像融合模型不会创建纹理。输出的详细纹理来自Landsat图像的“之前”或“之后”。融合处理可以被视为找到将这两个图像与适当的权重组合的方式。 U-STFM模型中的权重函数来自MODIS时间序列提供的变化率信息。因此，无法很好地预测未在“之前”或“之后”Landsat图像中捕获的图案。 图 21 2016年11月14日，在研究区域2中，与原始MODIS Rrs和Landsat 8 Rrs相比，蓝色（a-c）和绿色（d-f）带中的U-STFM的Rrs预测。 与图22中蓝色和绿色波段的Landsat 8 Rrs数据相比，U-STFM模型的Rrs预测结果如图22所示。观察和预测之间显示出强烈的线性相关性，R平方为0.8521和0.8857。 图 22 2016年11月14日，研究区域2中蓝色和绿色波段的U-STFM模型预测的1：1图。 图 23 2016年11月14日，研究区域2中1km空间分辨率的log10（蓝/绿）和log10（MODIS CHL）之间的相关性。 与研究区域1相同，NASA的OC2M-HI回归模型也应用于研究区域2，以建立1km规模的log10（叶绿素-a）和log10（蓝/绿）之间的相关性，如图23所示。 最终的叶绿素-a预测如图24所示，子区域如图25所示。 与原始MODIS数据相比，可以得出与研究区域1相同的结论：最终预测在海岸附近具有更详细的纹理。 同时，MODIS数据中显示的基本模式仍然在最终预测中。 与研究区域1相似，预测与Landsat 8叶绿素a产品之间的纹理差异仍然存在，因为图像缩小的基本问题是不适当的。 图 24 U-STFM的最终叶绿素a浓度预测与Landsat 8和初始MODIS叶绿素a产品相比 图 25 图24的局部区域 U-STFM与Landsat 8和MODIS叶绿素产物的叶绿素-a预测的1：1比较如图26所示。 总体而言，U-STFM的预测与Landsat 8和MODIS叶绿素产物相关，R平方分别为0.797和0.772。 与高叶绿素a浓度相比，较强的相关性显示低叶绿素-a浓度为0.5至2 mg / m3。 由于尺度差异，较高的变异主要表现在高叶绿素a浓度区域，特别是与MODIS相比。 与Landsat 8产品相比，图26（a）中的小偏差显示了对U-STFM预测的轻微低估。 这种总体偏差的原因可能与MODIS和Landsat传感器之间的频谱响应差异有关。 图 26 用Landsat 8和MODIS叶绿素a产品进行U-STFM预测的1：1图 表8比较了U-STFM预测，Landsat 8和MODIS产品与原位数据。 在这6个浮标中，RMSE显示Landsat 8和U-STFM具有相似的准确度，分别为0.557和0.503 mg /立方米，并且优于最初的MODIS叶绿素-a产品。 Table 8 Comparison of in-situ observations of Hong Kong buoys ID Date Name Longitude Latitude In situ observation (mg/m3) U-STFM CHL (mg/m3) Landsat8 CHL (mg/m3) MODIS CHL (mg/m3) 0 11/24/2016 MM16 114.443 22.453 2.1 2.392 1.343 2.905 1 11/24/2016 MM15 114.457 22.373 1.5 2.025 1.548 1.876 2 11/24/2016 MM14 114.457 22.303 1.7 1.661 1.511 1.818 3 11/24/2016 MM13 114.462 22.216 1.1 1.628 1.034 1.663 4 11/24/2016 MM8 114.334 22.196 1.9 1.497 1.266 1.646 5 11/21/2016 SM18 114.084 22.143 0.9 1.745 1.820 2.026           RMSE 0.503 0.557 0.639 3.2.9 小节 叶绿素浓度在近海水域附近迅速变化。在本章节中，我们实验了一种方法，将MODIS 1km叶绿素-a产品缩小到30m，以更好地了解近海地区叶绿素a的空间变化。为了实现这一目标，使用到了两种不同的相关性。首先，使用相同位置的不同时间序列观测值之间的相关性来提供详细的图像纹理，以帮助我们预测电磁波谱中蓝色和绿色区域附近的30m遥感反射率。其次，使用1KM规模的MODIS叶绿素a产物与升高的蓝/绿遥感反射率之间的相关性来预测30m水平的高度详细的叶绿素-a产物。选择U-STFM时空融合模型来捕获第一相关性。 NASA OC2M-HI模型用于捕获叶绿素a浓度与遥感反射交叉尺度之间的相关性。 选择唐山曹妃甸港附近的一个研究区来测试这种方法。使用Landsat 8 Rrs 482nm和Rrs 561nm作为地面实况数据来评估U-STFM图像融合模型的预测。 2016年3月10日数据的结果显示预测与真实数据之间存在强烈的线性关系，蓝色和绿色波段的R平方分别为0.868和0.881。与MODIS数据相比，预测的带在近海水域附近显示出更加细致的纹理，可以提供有关近海水域附近叶绿素浓度分布的更多信息。其他九个日期的结果也得出了类似的结论。 在1km规模的log10（蓝色/绿色）和log10（MODIS CHL）之间保持良好的相关性。正如2016年3月10日的R平方结果显示，大约85％的变化可以通过OC2M-HI回归模型建模，RMSE为0.742。本文还评估了对其他九个目标日期的预测以及类似的结论。根据观察条件，R平方在不同日期变化，从0.54-0.91变化。通过该回归预测30m尺度的叶绿素-a浓度，从U-STFM模型预测30m遥感反射率。与Landsat 8叶绿素-a产品相比，RMSE和局部标准偏差表明，30m规模的最终叶绿素-a浓度改善了近海水域附近的细致质地，并且与原始的MODIS叶绿素-a产品相比保持了准确性。 香港附近的另一个研究区域也被选中来测试这种方法。每月的浮标数据由香港环境保护署（https://cd.epic.epd.gov.hk/EPICRIVER/marine/）分享，数据可用于验证我们的最终叶绿素-a产品。类似的结果显示在研究区域2中，Rrs预测与真实数据之间具有强线性关系（蓝色和绿色波段的R平方分别为0.8521和0.8857）。对于这六个浮标，RMSE显示Landsat 8和U-STFM具有相似的准确度，分别为0.557和0.503 mg /立方公尺，并且优于初始MODIS 1km叶绿素a产品。 总的来说，在这项研究中，我们使用时间序列的相关性和不同尺度的相关性来推断近海地区附近叶绿素a浓度的空间变化。图像缩小问题通常是不适合的，只能根据先前的知识来推断，但是通过本文中的方法，可以预测30m叶绿素a浓度产品可以帮助我们更好地了解近海水域的更深层物理机制。]]></summary></entry><entry><title type="html">基于对抗神经网络ISRGAN的多源遥感数据融合与超分辨模型</title><link href="https://shawnmiloguo.github.io/blog/2016/SRGAN/" rel="alternate" type="text/html" title="基于对抗神经网络ISRGAN的多源遥感数据融合与超分辨模型"/><published>2016-02-03T21:01:00+00:00</published><updated>2016-02-03T21:01:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2016/SRGAN</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2016/SRGAN/"><![CDATA[<p>为满足具体监测任务尤其是应急响应任务对时空分辨率的要求，需要对多时间、空间尺度的遥感数据进行融合。传统数据融合方法鲁棒性较低，模型无法跨区域、跨传感器应用，因此，本研究基于人工智能领域的超分辨率生成对抗网络（以下简称SRGAN），开展多尺度数据融合方法研究，提出ISRGAN影像超分辨模型。</p> <p>ISRGAN模型以超分辨率生成对抗网络SRGAN为基础，为解决SRGAN模型训练不稳定以及在跨区域和跨传感器上的迁移性不足的问题，针对性地修改了SRGAN的损失函数并对其网络结构进行了改进，使模型训练地更加稳定，在跨区域和跨传感器上有着良好的迁移能力。</p> <h1 id="原文链接">原文链接</h1> <p>Xiong, Y., Guo, S., Chen, J., Deng, X., &amp; Sun, L. (2020). Improved SRGAN for Remote Sensing Image Super-Resolution Across Locations and Sensors. Remote Sensing, 12(1263), 1–22. https://doi.org/10.3390/rs12081263</p> <h1 id="研究背景">研究背景</h1> <p>详细和准确的土地覆盖和土地利用空间变化信息是地方生态和环境研究的重要基础。对于这些任务，需要高空间分辨率图像来捕捉地球表面的时空动态变化过程 ^[1]^ 。目前获取高时空分辨率影像的方法主要有两种：1）多源影像融合模型 和2）影像超分辨率模型 。</p> <p>与图像融合模型相比，超分辨模型不需要在相近的时间内获取相同区域的高空间分辨率影像，使得这些方法在计算机视觉和遥感领域的不同场景中都具有更强的可操作性。</p> <p>图像超分辨率模型的基本假设是，如果低空间分辨率图像遵循与创建低空间分辨率图像相同的重采样过程，则可以重建或从其他高空间分辨率图像中学习到低空间分辨率图像中缺失的细节。基于这个假设，在过去的十年里，人们致力于准确地预测点扩散函数，它代表了形成低分辨率像素的混合过程。主要有三种方法：1）基于插值的方法，2）基于重构的方法，3）基于学习的方法（表 1）。</p> <p>首先，插值法是基于一定的数学策略，从相关点计算要恢复的目标点的像素值，其复杂度低，效率高。但是，得到的图像的边缘效果很明显，在插值过程中没有产生新的信息，无法恢复图像的细节。</p> <p>其次，重构法对成像过程进行建模，整合来自同一场景的不同信息，获得高质量的重构结果 。通常这些方法为了提高空间分辨率而牺牲时间分辨率，需要预先配准和大量的算力。</p> <p>第三，学习法克服了难以确定重建方法的分辨率改进倍数的限制，可以面向单一图像，这是目前超分辨率重建的主要发展方向 。在这类方法中，常用的方法有近邻嵌入法 、稀疏表示法 和深度学习法。</p> <p>表 1超分辨方法对比</p> <table> <thead> <tr> <th>方法大类</th> <th>模型</th> <th>基本思想</th> <th>优点</th> <th>缺点</th> </tr> </thead> <tbody> <tr> <td>插值法</td> <td>最近邻插值法，二次卷积法，三次卷积法</td> <td>当前像素值可以用邻近的像素表示</td> <td>复杂度低，效率高</td> <td>图像纹理细节无法预测</td> </tr> <tr> <td>重构法</td> <td>联合地图配准，PSF反卷积，稀疏回归法</td> <td>通过重建技术恢复图像物理性质和特征，使点扩散函数进一步恢复图像细节</td> <td>融合同一场景的不同信息，得到高质量重建结果</td> <td>配准需要耗费大量计算时间</td> </tr> <tr> <td>学习法</td> <td>邻域嵌入法，稀疏表达法，贝叶斯网络，SRCNN，SRGAN</td> <td>通过学习大量图像样本，创建点扩散函数</td> <td>样本数量较多时生成的图像更接近目标图像，获得更高的PSNR</td> <td>训练时间长，需要大量数据集，模型泛化能力差</td> </tr> </tbody> </table> <p>学习法通常需要高度代表性来覆盖整个总体数据变化的训练样本。在实践中，为了达到这一目的，通常需要收集大量的训练样本。但是在遥感领域，几乎不可能准备这样的训练样本集，因为遥感数据的变化不仅取决于目标的变化，还取决于不同的位置和不同的卫星传感器。由于这种限制，许多基于学习的方法都局限于某个位置和特定的传感器，导致模型跨区域和传感器的泛化能力有限。这一限制仍然给为不同区域和不同传感器训练一个超分辨率模型带来了挑战。</p> <p>近年来，随着人工智能特别是基于神经网络的深度学习方法的快速发展，深度学习对于大样本的非线性过程拟合有着明显的优势，在计算机视觉领域得到了广泛的应用。这些模型的一个优点是能够处理大样本集，同时保持良好的泛化能力。在图像超分辨率领域，2014年Dong首次提出了超分辨率的神经网络SRCNN ^[16]^ 。与传统的超分辨率图像相比，该方法取得了更高的峰值信噪比，但当图像上的采样比较高时，重建图像会过于平滑，导致细节丢失。为了克服这一不足，Ledig,<br/> C.提出了一种超分辨率生成对抗网络模型SRGAN，将原始CNN结构替换为GAN ^[17]^ 。作为深度学习领域最新的学习模型，SRGAN在捕获大样本的高维非线性特征方面显示出许多优势。然而，SRGAN模型在不同位置和不同传感器的遥感图像上的泛化能力仍然未知。</p> <p>在本研究中，验证了基于GAN的方法可以提高跨区域和传感器的泛化能力，通过一些修改，可以一次性训练，并将结果应用于不同的区域和传感器。本研究主要贡献如下：</p> <ul> <li> <p>1）在SRGAN的基础上，本文提出了ISRGAN，解决了SRGAN训练不稳定以及模型泛化能力弱的问题；</p> </li> <li> <p>2）计算模型在广东GF1数据集和新疆GF1数据集上的定量指标并进行t检验，验证了模型在跨区域上的普适性；</p> </li> <li> <p>3）计算模型在新疆GF1数据集和新疆Landsat8数据集上的定量指标并进行t检验，验证了模型在跨传感器上的普适性；</p> </li> <li> <p>4）以应用服务为目标，以遥感图像超分辨为基础，将超分辨后的遥感图像应用于土地覆盖分类和地物提取，提高分类及地物提取精度。</p> </li> </ul> <h1 id="模型跨区域和跨传感器超分辨结果分析">模型跨区域和跨传感器超分辨结果分析</h1> <p>基于广东高分1号数据集上训练的ISRGAN超分辨模型，我们分别迁移到新疆高分1号数据集、新疆Landsat8数据集上进行模型的跨区域，跨传感器测试。测试部分结果分别如图2.1.2~图2.1.4所示。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320170737-s85vdps.png" alt="image.png" class="rounded"/></p> <p>图 2.1.2在广东训练完成的ISRGAN模型在广东本地GF1数据集超分辨率测试结果（a）输入的图像；（b）超分辨图像；（c）地面真值；（d）（e）（f）分别表示超分辨图像真实图像在红、绿和蓝三波段1:1灰度图，斜率分别为1.0063，1.0032和0.9955。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320170817-bmbxu9t.png" alt="image.png" class="rounded"/></p> <p>图 2.1.3模型跨区域检验：在广东训练完成的ISRGAN模型直接迁移到新疆GF1数据集超分辨率测试结果（a）输入的图像；（b）超分辨图像；（c）地面真值；（d）（e）（f）分别表示超分辨图像真实图像在红、绿和蓝三波段1:1灰度图，斜率分别为0.9658，0.9378和0.9485。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320170844-0s7hyrz.png" alt="image.png" class="rounded"/></p> <p>图2.1.4模型跨传感器检验：将广东训练完成的ISRGAN模型在直接迁移到新疆Landsat数据集的超分辨率测试结果（a）输入的图像；（b）超分辨图像；（c）地面真值；（d）（e）（f）分别表示超分辨图像真实图像在红、绿和蓝三波段1:1灰度图，斜率分别为0.9527，0.9564和0.9760。</p> <h1 id="与传统超分辨模型对比试验">与传统超分辨模型对比试验</h1> <p>本文主要对比了超分辨领域经典方法领域嵌入法及稀疏表达法，根据相应的超分辨结果，计算其与原始图像的定量化指标，在本文中，由于同一时间同一场景下的Landsat8卫星数据和高分一号卫星数据很难获取，而且其对应的像元个数不一致，考虑到后续在验证模型在跨区域和跨传感器上的普适性上计算标准的一致性，故本文的所有定量计算的参考影像均为超分辨之前的原始影像，计算方法为将超分辨后的影像进行相应的降采样处理，再计算其与原始影像的量化指标。图2.1.5展示了本文基于ISRGAN方法和领域嵌入法、稀疏表达法及SRGAN在3个测试集中测试的部分对比结。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320171422-tfhuzi7.png" alt="image.png" class="rounded"/></p> <h1 id="结论">结论</h1> <p>本文以生成对抗网络在计算机视觉上的超分辨算法为基础，针对生成对抗网络本身在训练时存在的梯度消失和模式崩坏等问题，结合WGAN中所提出的最小化Wasserstein距离的方法，对原始超分辨网络（SRGAN）进行修改，提出了ISRGAN网络，并将其应用在遥感影像超分辨上，主要得出以下结论：</p> <p>（1）本文所提出的ISRGAN超分辨网络，将其应用在遥感影像超分辨上，所取得的效果在定量指标上要优于领域嵌入法及稀疏表达法等传统影像超分辨方法。</p> <p>（2）为了实现超分辨模型的一次训练，多次使用，我们直接将在用广东高分1影像数据训练的模型应用在新疆高分1影像数据，并对两组数据集超分辨结果的定量指标做t检验，验证了超分辨模型在跨区域上具有普适性。</p> <p>（3）为了结合国产高分1影像数据与Landsat8影像数据各自的优势，本文将在高分1数据上训练的超分辨模型直接应用在Landsat8数据，并对超分辨结果的定量指标做t检验，验证了超分辨模型在跨传感器上具有普适性。</p> <p>（4）以土地利用分类和地物提取为例，对比Landsat8影像超分辨前后的分类和提取精度，其中土地利用分类采用K-means聚类算法，地物提取使用SVM算法。结果表明，超分辨影像在分类和地物提取的目视效果及精度均有明显提高，表明遥感影像超分辨在资源开发、环境监测、灾害研究和全球变化分析等方面极具应用价值。</p>]]></content><author><name></name></author><category term="特征空间优化"/><category term="特征空间构建"/><summary type="html"><![CDATA[蒸散空间下的土壤特征空间构建]]></summary></entry><entry><title type="html">基于HRU-Net的中高分辨率地表要素提取模型</title><link href="https://shawnmiloguo.github.io/blog/2016/HRUNET/" rel="alternate" type="text/html" title="基于HRU-Net的中高分辨率地表要素提取模型"/><published>2016-02-03T21:01:00+00:00</published><updated>2016-02-03T21:01:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2016/HRUNET</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2016/HRUNET/"><![CDATA[<p>多光谱遥感中，由于同物异谱效应，采用传统分类方法（如支持向量机、随机森林）对类似耕地这样的复合要素（休耕、弃耕、轮种情况下的耕地光谱差异较大）提取精度较低。卷积神经网络（CNN）对同一类地物的特征类内差异容忍度较高，具有较强的泛化能力，在同物异谱情况下有望提高复合要素的提取精度。 </p> <p>本文从网络结构和损失函数表达两个方面入手，专注于解决原有深度卷积网络应用到遥感地物分类时存在的高分辨率信息丢失问题。本文提出的方法是在U-Net网络框架基础上，通过结合GridNet，interlinked CNNds ，HRNet等网络全程保持高分辨率信息的核心思想，改进了网络的跳跃连接结构，提出的高分辨HRU-Net网络。于此同时，在HRU-NET设置损失函数中引入深度监督的思想，进一步保留的高分辨率信息训练网络参数。本文以实验以Landsat<br/> 4-5 TM传感器为数据源，以新疆卡拉水库附件建设兵团农田为实验区，进行模型验证。该方法可以进一步推广到其他具有同物异谱地物的分类任务中，以提高精度和地物分类细节丰富度。</p> <h1 id="原文链接">原文链接</h1> <p>Xu, W., Deng, X., Guo, S., Chen, J., Sun, L., Zheng, X., Xiong, Y., Shen, Y., &amp; Wang, X. (2020). High-Resolution U-Net : Preserving Image Details for Extraction Cultivated Land. Sensors, 20(15), 4064.</p> <p>(https://www.mdpi.com/1424-8220/20/15/4064/html)</p> <h1 id="研究背景">研究背景</h1> <p>耕地作为重要的土地利用/土地覆盖类型，其数量、质量和空间分布范围关系着人类社会和经济的发展，关乎国家粮食安全问题，且与生态环境保护紧密相连。准确、快速地获取耕地信息是土地利用/土地覆盖研究领域的热点之一。遥感技术为提取耕地类型提供了更加快速、全面、准确的手段，利用遥感图像分类方法提取耕地信息，了解耕地分布、耕地类型及耕地面积等对有效管理作物种植和优化作物种植结构有重要意义。</p> <p>传统的遥感分类方法（SVM, KNN, 和RF等）用于耕地提取时的难点主要有三个方面：1）耕地严重的同物异谱现象：耕地上种植的作物类型多种多样，灌溉方式和土壤类型存在差异，同时存在未覆盖地物的休耕期耕地，导致不同耕地的光谱特征差别明显，而传统的遥感分类方法，以扩大类间差距，减少类内差距为优化目标，不能很好的适应覆盖不同地物的耕地提取要求 ^[33,34]^ 。2）传统遥感分类方法采用的有限的特征，并且这些特征往往针对具体问题进行设计，特征跨地域泛化表征性不强，在研究区内训练的方法，很难在其他区域进行直接应用 ^[35,36]^ 。3）基于统计学习的传统算法，基于样点得到对象在特征空间的分布信息，算法复杂度较高，当训练样本较大时，会出现无法训练或精度饱和等现象，不适合处理大规模的遥感图像数据。</p> <p>近年来，深度学习在遥感图像分类领域发展迅速 ^[37,38]^ ，主要采用的有图片级分类和像素级分类两种方法。1）图片级分类算法，该方法以单个图像为判别单元，每个图像只能包含一种地物类别，通过卷积神经网络对图像的整体特征进行学习。这类算法的核心是图像的识别，通过将整幅影像切割成包含单一地物的若干子影像后，分别对子影像中的地物进行识别。这种方法的优势在于能够较好的利用领域特征，从而提高准确识别地物的类别。但缺点是无法给出像素级的分类结果。因此目前这里方法大多使用在地物识别和提取的应用场景下。例如，Alshehhi等提出了一种卷积神经网络，从高分辨率遥感数据中提取道路和建筑物。Long等提出了一种高分辨率遥感图像的三步物体定位算法，模拟了Fast R-CNN的工作流程，实现地物要素的提取 ^[39]^ 。2）像素级分类算法，以每个像素为判别单元，采用的全卷积网络去掉了卷积神经网络中的全连接层，换成了1*1卷积层，来实现端到端（像素到像素）的分类方法。这种替换保留了图像内容的空间信息，解除了卷积神经网络对输入图像大小的限制，同时大大减少了模型参数量，提高了算法效率。其中具有代表性的有，Jamie Sherrah提出了一种不包括常规下采样层的FCN算法，在ISPRS数据集中实现了89.1%的总体精度 ^[40]^ 。Marmanis等人设计了一个像素级分割架构，合成FCN和反卷积网络，并将CRF应用于后处理以进行细化，在基于ISPRS Vaihingen数据集标签的人工数据集中取得了88.5%的总体精度 ^[41]^ 。Chen等人采用叠加策略对FCN的分段结果进行后处理，相比传统的FCN-8和SegNet模型具有更高的精度。</p> <p>然而，在将像素级分类算法应用到遥感影像耕地提取过程中，为了获取不同尺度区域特征，深度卷积网络往往需要将高分辨率图像转化为低分辨率图像（polling）,来提取抽象不通尺度的语义信息作为特征用于后续分类。而重采样是常用的方式之一，这个过程造成图像高分辨信息（边缘信息，梯度信息或高频噪声信号等）的丢失，使得耕地提取结果边缘模糊，细节不够丰富准确，影响最终的耕地提取精度。</p> <p>目前在全卷积网络用于像素级分类的过程中，解决高分辨率丢失问题的方法大致分为两类：1）从低分辨率表达中学习恢复高分辨率信息2）网络结构中全程保持高分辨率信息。</p> <p>第一类，从低分辨率表达中学习恢复高分辨率信息。这类方法的核心思想是移除了卷积神经网络中的全连接层，从而得到低分辨率特征图，再从低分辨率特征图中学习得到高分辨率信息估计值。例如FCN通过对低分辨率特征图进行双线性插值得到不同尺度的高分辨率特征图，再将高分辨率特征图与网络提取特征过程中得到的相应尺度的特征图进行融合，以期更好的恢复高分辨率信息。另外，采用上采样子网，如解码器，逐步恢复由下采样过程输出的低分辨率特征图的高分辨率表示，也是一种常用的方法。上采样子网可以采用与下采样过程对称的形式，其中，SegNet ^[42]^ 和DeconvNet ^[43]^ 网络通过记录下采样过程中的池化索引，然后通过对应的反池化操作来进行上采样过程 ,逐步恢复图像高分辨率信息，而U-Net ^[44]^ ，FPN网络则增加了跳跃连接过程，将下采样子网与上采样子网中相应分辨率尺度的特征图进行融合操作，进一步恢复高分辨率信息。非对称上采样过程也被广泛使用，一些研究通过采用更复杂的卷积模块来改进跳跃连接过程(C. Peng, X.,2017;Z. Zhang,2018;M. A. Islam，2017)，另外一些研究则通过堆叠多个DeconvNet/UNet/Hourglass 来不断恢复高分率信息 ^[45,46]^ 。这类方法都是通过对低分辨信息进行学习来恢复高分辨率信息，尽管采用了各种跳跃连接方式来优化得到的高分辨率信息，但从低分辨率特征图中获取高分辨率特征的本质是一个病态推算的过程，在遥感地物分类的实际应用中，很难恢复出地物原有的细节纹理。</p> <p>第二类，全程保持高分辨率信息。这类方法在整个网络过程中一直保持高分辨率信息。用来保持高分辨率信息的网络结构一般包括连接多尺度信息（从高分辨率信息到低分辨率信息）的平行结构和融合不同尺度信息的多尺度信息交换结构。代表网络有GridNet，convolutional neural fabrics，interlinked CNNds和高分辨率网络（HRNet）等。其中，较早期的两个方法，convolutional neural fabrics 和interlinked CNNs，对何时开始低分辨率并行流以及如何跨并行流交换信息缺乏谨慎设计，未取得令人满意的结果。GridNet则类似于多个U-Nets的组合，包括两个对称信息交换阶段：第一阶段仅将信息从高分辨率传递到低分辨率，第二阶段仅将信息从低分辨率传递到高分辨率，这也限制了其分割质量。HRNet设计的并行连接结构和重复的不同尺度分辨率信息的交换融合操作则更好地保留了高分辨率信息，取得了更好的结果。然而这部分模型大多应用在自然图像的像素级分类过程中，通道个数与网络深度受到限制，不利于应用到遥感多波段影像的地物分类中。</p> <p>由于卫星遥感图像成像机理和平台的不同，图像中的高分辨率特征有可能是地物的细节信号（边缘信号，纹理信号），也可能是影像的噪声信号（传感器噪声，灰土量化噪声等），如何在有效抑制噪声，尽可能的保留深度卷积网络中图像的高分辨率信号，是将卷积神经网络引入卫星遥感地物分类的重要问题。</p> <p>针对上述问题，本文从网络结构和损失函数表达两个方面入手，专注于解决原有深度卷积网络应用到遥感地物分类时存在的高分辨率信息丢失问题。本文提出的方法是在U-Net网络框架基础上，通过结合GridNet，interlinked CNNds ，HRNet等网络全程保持高分辨率信息的核心思想，改进了网络的跳跃连接结构，提出的高分辨HRU-Net网络。于此同时，在HRU-NET设置损失函数中引入深度监督的思想，进一步保留的高分辨率信息训练网络参数。本文以实验以Landsat 4-5 TM传感器为数据源，以新疆卡拉水库附件建设兵团农田为实验区，进行模型验证。该方法可以进一步推广到其他具有同物异谱地物的分类过程中，以提高精度和地物分类细节丰富度。</p> <h1 id="高分辨率u-nethru-net算法介绍">高分辨率U-Net（HRU-Net）算法介绍</h1> <p>本文提出的HRU-Net方法，保留了U-Net网络的收缩路径和扩张路径，整个网络和U-Net网络一样具有5层分辨率尺度。改进之处主要体现为两点：</p> <p>（1）采用保持高分辨率细节信息的思想，改进U-Net中跳跃连接结构。</p> <p>（2）为了更好的利用各种分辨率特征图的信息，更好的传递梯度信息来学习网络参数，设计损失函数输入时，运用了深度监督的思想。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320173848-7vym0hr.png" alt="image.png" class="rounded"/></p> <h1 id="hru-net与u-netu-net-和rf的比较">HRU-Net与U-Net，U-Net ++和RF的比较</h1> <p>本研究从三个方面比较了HRU-Net，U-Net，U-Net ++和RF的结果：（1）总体精度，（2）边缘细节的准确性，（3）类间变化的鲁棒性。</p> <p>表3.1.4和图3.1.7显示了在测试数据集上每种方法的精度评估。在这三个数据集上，HRU-Net在总体精度（Acc），Kappa系数（K）和F1-score（F1）都优于其他三个模型。</p> <p>首先，表3.1.4中的结果表明NIR和SWIR波段可以将总体精度提高1％–4％。与TM-NRG和TM-RGB数据集的结果相比，TM-All数据集的准确性最高。当将NIR添加到RF模型中时，精度提高了3.35%，这可能与模型捕获更高尺度特征（例如可能的非线性波段组合）的能力有关。但是因为深度学习模型在这个方面做得更好，所以在添加新的训练波段时，改进的效果并不明显。其次，HRU-Net在所有三个数据集中均实现了最高的提取精度。特别是在TM-All数据集上，HRU-Net的总体精度达到92.81％，与U-Net<br/> ++相比提高了1.07％，与U-Net相比提高了2.98％，与RF相比提高了16％。HRU-Net的最佳kappa系数为0.75-0.81，与U-Net<br/> ++相比增加0.01-0.02，与U-Net相比增加0.07-0.09，与RF相比增加0.33-0.50。在F1-Score中也可以发现类似的结果。</p> <p>从表3.1.4中可以看出，NIR波段和SWIR波段可以提供一些有用信息来帮助区分耕地和其他耕地，同时对于RF模型的精度提高更大（RF模型的精度提高了1％–4％）。而对于深度学习模型精度提升仅为0.4％–1％。一个可能的原因是深度学习模型具有更多的学习能力，可以提取出更深层次的特征，例如形状和梯度。另一个原因可能是在类间光谱变化较大的情况下，NIR和SWIR波段虽然可以有效地将植被和非植被像素区分开，但是对于耕地和非耕地却不太有效，因为耕地在不同时期可以有植被覆盖和无植被覆盖。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320174014-9n4bjbe.png" alt="image.png" class="rounded"/></p> <p>图3.1.7为这三个模型在TM-All数据集上的混淆矩阵。结果表明，HRU-Net模型的召回率和总体精度都是最高的。与U-Net ++，U-Net和RF相比，HRU-Net中的类型1和类型2错误也保持最低。</p> <p>表3.1.5是HRU-Net在50％，60％和70％训练集下的总体精度。正如本研究预期的那样，训练集越小，准确性将越低，但是即使在50％的训练样本，HRU-Net中的准确性也比其他两个模型下降得慢，性能要好。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320174039-m40d837.png" alt="image.png" class="rounded"/></p> <p>表3.1.6是HRU-Net，U-Net ++和U-Net训练期间的时间消耗。RF被排除在外，因为它是由CPU而不是GPU训练的；因此，它无法与其他三种基于GPU的算法相提并论。HRU-Net与原始的U-Net相比，由于通过添加更复杂的跳跃连接而涉及了更多的模型参数使得训练时间增加了约2.6倍。与U-Net ++相比，两个网络在级别相同时，参数数量相似，两者消耗的时间也相似。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320174101-kwokrwd.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.1.7 Landsat TM-All数据集的测试数据集上的HRU-Net，U-Net ++，U-Net和RF模型的混淆矩阵。</p> <h1 id="边缘细节的准确性">边缘细节的准确性</h1> <p>如图3.1.8所示，通过目视解译来评估边缘细节的准确性。与U-Net ++和U-Net相比，HRU-Net的结果具有更清晰的边缘和更丰富的细节。具体来说，与U-Net<br/> ++相比，输出中保留了更详细的边界信息，同时HRU-Net的边缘比原始U-Net的边缘准确得多，而RF的输出图中，边缘不准确，并且没有农作物覆盖的农田由于类间变化RF无法正确检测。</p> <p>图3.1.9显示不同模型的类内变化的鲁棒性。在图3.1.8中，绘制了测试数据集中每个图块的总体精度。如图3.1.9（a）所示，RF模型变化最高，因为其拟合不同谱段的泛化能力最差。图3.1.9（b）显示了HRU-Net，U-Net++，以及U-Net的变化情况，在图3.1.9（b）中，HRU-Net的变化与U-Net<br/> ++相似，但是，它在所有三个数据集中总体精度都是最高的。这表明HRU-Net在解决类内变化问题的有效性。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320174159-vph0nlp.png" alt="image.png" class="rounded"/></p> <p>图3.1.8 HRU-Net，U-Net和随机森林模型在三个数据集的输出图对比</p> <p><img src="/SIAT-GeoScience/assets/image-20220320174235-dyug82k.png" alt="image.png" class="rounded"/></p> <p><img src="/SIAT-GeoScience/assets/image-20220320174256-878bcuw.png" alt="image.png" class="rounded"/></p> <p>图3.1.9测试数据集上的总体精度分布的箱线图（868个图块）。(a)RF和深度学习算法之间的比较；(b)HRU-Net，U-Net ++和U-Net之间的比较。</p> <h1 id="结论">结论</h1> <p>本文提出的HRU-Net网络，主要是为了解决两个问题：</p> <p>（1）传统方法进行耕地提取时的同物异谱问题，这使得耕地提取时，未覆盖植被的休耕期耕地很难被提取，提取精度很低。</p> <p>（2）利用深度学习进行耕地提取时高分辨率信息丢失的问题，这不仅导致了耕地提取结果边缘模糊，细节丢失，也使得深度学习网络对于遥感图像的光谱、纹理等信息利用不充分，无法发挥遥感影像多波段、信息丰富的优势，影响最终的耕地提取精度。</p> <p>针对以上两个问题，HR-UNet在全卷积网络U-Net的基础上，保留了U-Net网络的对称编解码结构，进行了以下两方面的改进：</p> <p>（1）根据在全卷积网络中全程保持高分辨率信息的思想，改进了U-Net网络的跳跃连接结构。</p> <p>（2）为了更好的利用保留的高分辨率信息训练网络参数，在设置损失函数时采用了深度监督的思想。</p> <p>在由Landsat影像不同波段数据组成的三个数据集TMall，TMnrg和TMrgb中，使用HRU-Net，U-Net，UNet++ ^[47]^ 和Random Forest分别进行耕地提取实验后，验证了本文提出的HRU-Net网络基本达到预期目标，并能得出以下结论：</p> <p>（1）在耕地提取精度上，相比基于深度学习的U-Net,<br/> UNet++网络和传统方法Random Forest，在整体精度，混淆矩阵，kappa系数和F1-score四个评价指标中，均取得了更好的结果。</p> <p>（2）在三个数据集中，三个方法均在包含Landsat影像全6个波段的TMall数据集中取得了最好的结果，其中，HRU-Net方法表现最好，整体耕地精度达到90.61%，Kappa系数达到0.8。</p> <p>（3）在三个数据集中，传统Random<br/> Forest方法均未能准确识别出未覆盖地物的休耕期耕地，而HRU-Net方法能准确识别出所有类型的耕地，解决了耕地提取中的同物异谱问题。</p> <p>（4）在三个数据集中，HRU-Net模型相比U-Net模型的耕地结果图边缘更为清晰，细节更为丰富，与遥感影像中耕地的实际分布情况以及标签更为吻合，说明HRU-Net针对高分辨率信息丢失问题的改进取得了明显的效果。</p>]]></content><author><name></name></author><category term="特征空间优化"/><category term="特征空间构建"/><summary type="html"><![CDATA[蒸散空间下的土壤特征空间构建]]></summary></entry><entry><title type="html">对抗样本噪声的遥感深度学习分类网络模型</title><link href="https://shawnmiloguo.github.io/blog/2016/WLN/" rel="alternate" type="text/html" title="对抗样本噪声的遥感深度学习分类网络模型"/><published>2016-02-03T21:01:00+00:00</published><updated>2016-02-03T21:01:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2016/WLN</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2016/WLN/"><![CDATA[<p>针对样本标签噪声造成的地物提取精度不足问题，本文提出了一种抗噪声标签的卷积神经网络框架，Weight Loss Net（WLN）。WLN主要包含三部分：（1）分割子网络，用于产生图像的逐像素分类结果，可以使用其他的分割模型进行替换；（2）损失权重参数，用于对每个训练样本赋权重，对干净样本赋予高权重值，对噪声样本赋予低权重值，降低噪声样本对网络训练过程中的影响，提高网络的抗噪性能；（3）类别平衡系数，帮助网络平等地学习每一个类别，避免由于不同类别之间的不平衡导致模型过拟合。 基于上述方法在公开数据集（Inria Aerial Image Labeling Dataset,以下简称Inria）上实验进行建筑物提取，通过图像膨胀和腐蚀操作模拟四种标签噪声类型（多标注噪声，少标注噪声，错标注噪声和漏标注噪声）。本研究在训练数据集加入不同噪声率及噪声等级的训练样本，并在干净的数据集进行测试，与原U-Net网络进行比较，评估网络的抗噪性能。</p> <p>实验结果表明，当噪声增加的时候，WLN能够保持模型的性能和维持较高的精度，而U-Net模型的精度则有所下降。在噪声率及噪声等级比较低的时候，U-Net并不会受到噪声标签的影响，这是因为深度学习模型具有一定的抗噪性；当噪声率及噪声等级逐渐增加时，U-Net网络精度下降明显。在噪声不断增加的时候，我们提出的WLN可以一直保持很高的精度。这一结果表明，本文提出的抗噪声标签的卷积网络框架可以降低噪声训练标签对分隔模型的影响。</p> <h1 id="原文链接">原文链接</h1> <p>Lin, C., Guo, S., Chen, J., Sun, L., Zheng, X., Yang, Y., &amp; Xiong, Y. (2021). Deep Learning Network Intensification for Preventing Noisy-Labeled Samples for Remote Sensing Classification. Remote Sensing, 13(1689), 1–19.</p> <h1 id="研究背景">研究背景</h1> <p>深度学习方法性能好坏取决于两个因素，训练数据量的大小以及标签标注的准确性。相比于数据量小的问题，标签标注噪声问题更难解决。遥感数据集中标签噪声普遍存在。一是因为遥感图像土地类型复杂，需要有一定专业知识才能够对其进行准确标注 。二是因为多个专家同时对同一副遥感图像进行标注，每个专家之间的标注结果不一致 。三是低成本的自动化标注或者缺乏专业知识的人员进行标注，标注的结果往往可靠性较差。标签噪声通过影响网络的损失值，使得网络参数往错误的方向更新，降低了网络的分类性能。因此深度学习中的标签噪声问题处理方法主要分为两类，一类是针对标签，一类是针对损失值。针对标签进行处理的方法有两种实现形式，一种是对训练数据进行筛选，一种是计算转移矩阵。样本筛选，这类方法的主要思想是从一个有噪声的训练数据集中选择干净的样本进行网络训练。最初，MALACH E等人认为噪声样本会对网络进行错误的更新，即使网络能够预测到正确的样本，也会由于噪声标签使得此时调整好的网络往错误的方向更新，因此提出将何时更新与怎么更新进行分离，使用两个卷积神经网络，只有当两个网络预测结果不一致的时候才进行参数更新。之后，ARPIT D等人发现在网络训练过程中，网络倾向于先学习干净的样本，再慢慢拟合噪声样本及困难样本。因此，许多研究采用小损失选择准则，将一定数量的小损失训练样本作为干净样本。HUANG J等人就是基于这一准则，通过多次的循环从欠拟合到过拟合的过程，根据样本的loss曲线，把loss高的样本作为噪声样本剔除，保留小损失样本 。JIANG L等人介绍了一种协助学习的模式，网络分为两个部分，教师网络和学生网络，基于小损失样本选择准则，教师网络向学生网络筛选出正确的样本，学生网络根据教师网络提供的样本进行网络训练。HAN B等人认为一个网络对于标签噪声的学习中错误会不断累加，多个网络具有不同的学习能力，可以过滤不同类型的噪声标签带来的错误，因此采用了两个CNN网络，每个CNN网络都选择一定数量的小损失样本，并将其反馈给另一个网络进行训练。这类方法可以通过简单地排除不可靠的样本，有效地避免噪声标签对网络的影响。但是这类方法的关键在于能否设计有效的样本选择策略，如果选择策略不好，可能排除大量有用的样本。</p> <p>第二种实现形式是计算噪声转移矩阵，该矩阵定义了一个类别变换到另一个类别的概率，通过计算噪声转移矩阵，将噪声标签纠正为干净标签。CHEN X等人在网络末尾添加一层线性层作为噪声适应层，估计标签标注类别被翻转为其他类的概率，之后推断出真实的标签，进行网络参数更新。XIAO T等人提出的网络分为三个部分，分类子网络和噪声子网络以及噪声适应层，分类子网络可以得到分类的概率，噪声子网络可以得到标签为某一类噪声的概率，噪声适应层将两个子网络的输出作为输入推断出真实标签的概率。网络分为两阶段训练，首先采用干净的样本对分类子网络和噪声子网络做预训练，之后再用带噪声标签的数据集进行训练，推断出真实的标签，更新网络模型，提高网络性能。SUKHBAATAR S等人同样采用两阶段训练，首先使用简单易分辨的图像对网络进行预训练，之后再使用含噪声标签的数据集对网络最后一层噪声适应层进行微调。这类方法很大程度上依赖对于噪声分布的准确假设，而在实际中，这种分布很难准确估计出来。</p> <p>第二类方法主要是针对损失值进行处理，有两种实现形式，一种是修改网络的损失函数，一种是对损失值进行赋权重。修改网络损失函数的方法基本思路是设计一个鲁棒性的损失函数，即使训练数据中含有噪声标签，也可以使得计算出来的损失值不受噪声数据的影响。MANWANI N等人提出对于二值分类情况下，神经网络的损失函数对标签噪声有天然的鲁棒性。GHOSH A等人对这一理论推导至多分类的情况，并且对比了MAE,MSE,CCE损失函数对标签噪声的鲁棒性，证明了MAE损失函数对噪声具有更强的鲁棒性。ZHANG Z等人在前者的基础上发现MAE在复杂数据集中对噪声标签的鲁棒性表现不佳，文章对MAE进行修改，结合CCE，提出GCE损失函数。受KL散度对称性的启发，WANG Y等人提出对称性的交叉熵损失函数，用对噪声鲁棒的反交叉熵损失函数对交叉熵损失函数进行增强，解决交叉熵损失函数在有噪声标签数据集中的学习不足和过拟合现象。设计鲁棒性的损失函数虽然可以提高网络的抗噪性能，但是网络仍然会受到标签噪声的影响，并且只在简单的情况下执行得比较好，例如容易分别的类或者类别数量少的情况，同时损失函数的修改会增加训练收敛的时间。</p> <p>第二种实现形式是对损失值赋权重，基本思路是对所有训练样本损失值分配权重，并在训练过程中迭代更新这些权重。LIU 等人证明了通过对训练样本进行重要性加权，可以使得标签噪声训练下的分类器达到无噪声分类器的性能。REN M等人使用元学习范式基于梯度方向调整训练样本的损失权重。首先获取一个干净标签的数据集作为验证集，每一轮网络训练后在验证集上进行验证，计算验证集的损失值，之后由验证集的损失值得到训练样本的权重并对网络进行参数更新。SHU J等人也采用了类似的方法，但不是隐式计算权重，而是使用多层感知机估计权重值。XUE C等人不但通过网络迭代区分干净样本和噪声样本，同时根据噪声水平对样本进行加权提取出噪声样本和困难样本中的有用信息。这类方法的有效性主要取决于样本权重调整方案是否能够正确地提高干净标签样本的损失权重值，降低噪声标签样本的损失权重值。此外，如今的标签噪声处理方法大部分是针对于场景识别任务，对于遥感图像分类中标签噪声的处理研究很少，上述方法只适用于场景识别任务，不适用于遥感图像分类任务。</p> <p>在本文中，我们提出了一种适用于遥感图像分类中标签噪声处理的通用网络框架，Weight LossNet（WLN）。WLN对标签噪声的处理思路主要采用了上面提到的对损失值赋权重。其中对样本权重的调整方案结合注意力机制，通过注意力机制网络得出每个样本的重要性，提高重要样本的损失权重值，降低非重要样本的损失权重值，避免标签噪声对模型的影响。之后在遥感图像公开数据集Inria Aerial Image Labeling Dataset上进行实验，并与原始的分类网络方法进行对比。本文的主要贡献总结如下：（1）研究卷积神经网络对于四种常见的标签噪声类型(不足标签、冗余标签、缺失标签、错误标签)的鲁棒性。（2）提出一种适用于遥感图像分类中标签噪声处理的通用网络框架，该算法在不同噪声类型水平下都能保持较高的精度和较好的泛化性能。</p> <h1 id="数据源及覆盖区域">数据源及覆盖区域</h1> <p>在本文的研究中，采用Inria Aerial Image Labeling Dataset（以下简称为Inria数据集）。该数据集解决了遥感领域最重要的问题之一：航空图像的像素级自动标注。Inria数据集图像分辨率为30cm,标签标注两类信息，建筑类别和非建筑类别。同时这些图像覆盖了不同的城市地区，不但有建筑物稠密的大城市还有建筑物稀少的小镇。</p> <p>Inria训练数据集包含180副5000*5000大小的图像，覆盖Austin, Chicago, Kitsap County, Western Tyrol, and Vienna这5个地区，总面积为405平方公里。标签由180张单通道的图像组成，其中255表示建筑类别，0表示非建筑类别，具体图像如图3.5.1所示。由于此数据集是用于比赛，无法获取到测试集的标签，因此本研究中将原训练集按照8:1:1的比例分为训练集，验证集和测试集三部分，三者相互独立，互不重叠。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320180501-00sj5ku.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.5.1从左到右分别为Austin，Chicago，Kitsap County，Western Tyrol和Vienna的图像及对应的标签图</p> <h1 id="实验噪声设置">实验噪声设置</h1> <p>标签噪声定义为实例与标注的所属类别不相对应，即标注错误。在像素级遥感土地覆被标注中，有四种常见的标签噪声，1）多标注噪声，即标签面积大于实际面积；2）少标注噪声，即标签面积小于实际面积；3）错标注噪声，即将对象标注为错误的类别，4）漏标注噪声，即对象的整个标签缺失。</p> <p>为了模拟标签噪声，我们采用不同的卷积核对标签进行图像膨胀和腐蚀操作。如图3.5.2所示，第一行表示图像膨胀处理，模拟多标注噪声（如图3.5.2的c，d所示，分别对实际标签进行卷积核为9<em>9，17</em>17的图像膨胀操作）。当卷积核大小增加到25*25时，标签中包含很多错误的像素，可以认为是错标注噪声样本（如e所示）。同理，采用图像腐蚀操作模拟少标注噪声（如图3.5.2的f,g）和漏标注标签样本（h）。为了明确多标注和少标注噪声不同的误差，在本研究中，我们设置了三个噪声等级，我们将卷积核为9的噪声表示Noise level 1，卷积核为17表示Noise level 2，卷积核为25表示Noise level 3。本研究设置了5个数据集样本噪声率，以测试网络在不同错误样本数量下的表现。我们从训练集中随机选取0%、25%、35%、45%和50%的噪声样本对训练数据集进行噪声处理。具体噪声标签图像如图3.5.2所示。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320180701-kbf1dgb.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.5.2四种噪声标签的图像</p> <p>图3.5.2第一列从左到右分别是原图，干净标签图，Noise level1的多标注噪声标签图，Noise level 2的多标注噪声标签图，Noise level 3的错标注噪声标签图；第二列从左到右分别为原图，干净标签图，Noiselevel 1的少标注噪声标签图，Noise level 2的少标注噪声标签图，Noise level 3的漏标注噪声标签图。</p> <h1 id="wln-网络结构">WLN 网络结构</h1> <p><img src="/SIAT-GeoScience/assets/image-20220320180814-c8vmves.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.5.3 WLN的网络结构图</p> <p>WLN网络包含两个子网络，分割子网络和注意力子网络，其中分割子网络由分割模型组成，用于产生分割结果并与标签计算得到损失值，注意力子网络由CNN模型和注意力模块组成，用于计算训练样本的损失权重值。为了解决当腐蚀噪声中标签类别严重失衡而引起注意力子网络无法对训练样本赋予正确损失权重的问题，我们通过标签计算类别平衡系数进行类别平衡，最后将损失值，损失权重值，类别平衡系数三者结合，作为最终的损失值，对分割子网络和注意力子网络进行反向传播更新参数。</p> <p>WLN网络的分割子网络采用的是U-Net分割模型，也可以替换成其他的分割模型。注意力机制子网络实现形式采用的是SE模块，SE模块是胡杰及其团队于2017年提出的一种卷积神经网络结构，如图3.5.4所示。SE模块的提出是为了考虑特征图中通道之间的关系，并为每个通道提供不同的权重。它通过学习自动获取每个特征通道的重要性，然后根据每个通道的重要性加强有用的特征，而抑制对当前任务无用的特征。squeeze和excitation是SE模块中的两个关键操作。这两个操作可以帮助SE模型捕获通道侧的依赖性，并大大减少参数和计算的数量。</p> <h1 id="实验结果及分析">实验结果及分析</h1> <p>本节按照上一章介绍的参数设置进行模型训练得到对应的WLN模型和U-Net模型，在相同的测试集中对两个模型进行评价，本文从定量提取精度和定性地物提取细节两个角度，按照上节所述的评价指标对地物提取结果进行评价。同时，在讨论部分对引进的两个参数，损失权重值和类别平衡系数的有效性进行分析。</p> <p>下面我们分别比较WLN和U-Net对于腐蚀和膨胀噪声类型的测试集提取精度结果。</p> <p>（1）膨胀噪声</p> <p>我们分别使用不同噪声率及不同噪声等级的膨胀噪声标签训练集对WLN网络和U-Net网络进行训练，并在干净的标签测试集上进行测试。表3.5.1和图3.5.8显示了两种方法在测试集的提取精度结果。从精度曲线图上可以看出，在干净的数据集中，U-Net和WLN都可以保持很高的精度。随着噪声率的不断增加，网络精度并不是立马下降。在Noise level 1下， U-Net方法仍能保持较高的精度，这可能是因为卷积神经网络具有特定的抗噪声能力。但是，当噪声率在50%时，U-Net的精度明显下降，在Noise level 2时，OA下降4.4%，MIOU下降7.7%，Kappa下降2.0%；在Noise level 3时，OA下降12.7%，MIOU下降20.7%，Kappa下降13.8%。相比之下，WLN在噪声率增加的情况下仍能保持较高的精度，噪声率在50%时，在Noise level 2时，OA下降1.2%，MIOU下降2.1%，Kappa下降1.1%；在Noise level 3时，OA下降0.2%，MIOU下降0.3%，Kappa下降0.8%。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320181106-xhrl4z3.png" alt="image.png" class="rounded"/></p> <p>（2）腐蚀噪声</p> <p>我们分别使用不同噪声率及不同噪声等级的腐蚀噪声标签训练集对WLN网络和U-Net网络进行训练，并在干净的标签测试集上进行测试。表3.5.2和图3.5.9显示了两种方法在测试集的提取精度结果。从精度曲线上可以看出，网络在腐蚀噪声中的精度变化与膨胀噪声中的精度变化相似。U-Net网络在噪声率以及噪声等级低的时候，由于自身的抗噪能力，可以避免噪声的影响。随着噪声率的增加（在Noiselevel 3，噪声率为50%时），U-Net方法在测试集上的OA精度在这个过程下降了8.4%，MIOU下降了24.2%，Kappa系数下降了43.3%，变化幅度较大。而WLN稳定性更好，OA在这个过程只变化了1.5%，MIOU变化了4.7%，Kappa系数变化了0.5%。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320181202-2xgkaeh.png" alt="image.png" class="rounded"/></p> <h1 id="提取细节比较">提取细节比较</h1> <p>这一小节我们通过目视解译的方式来评估WLN和U-Net模型在膨胀和腐蚀标签噪声下地物提取细节。</p> <p>（1）膨胀噪声</p> <p>图3.5.10是膨胀噪声类型下在噪声率为50%不同噪声等级下两种方法的提取结果。第一行和第二行是Noiselevel 1提取结果，第三行和第四行是Noise level 2的提取结果，第五行和第六行是Noise level 3的提取结果。从图中可以看出，在噪声级别比较低的时候，如Noiselevel 1，WLN和U-Net的提取结果相似，但是U-Net由于受到膨胀噪声的影响会将一些非建筑物的像素点分类为建筑物，如图中红框所示。当噪声级别比较高的时候，如Noiselevel 3，U-Net受膨胀噪声影响比较大，对于建筑物只能提取出大概的轮廓，会将建筑物中的街道也标记为建筑物，而WLN方法对于噪声的影响较小，可以很好的识别建筑物及建筑物之间的界限。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320181325-5bh6lsj.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.5.10膨胀噪声类型下U-Net和WLN的提取结果图</p> <p>（2）腐蚀噪声</p> <p>图3.5.11是腐蚀噪声类型下在噪声率为50%不同噪声级别两种方法的提取结果。第一行和第二行是Noise level 1提取结果，第三行和第四行是Noise level 2的提取结果，第五行和第六行是Noise<br/> level 3的提取结果。从图中可以看出，在噪声级别比较低时，如Noise level 1，WLN和U-Net的提取结果相对较完整，但是U-Net由于受到腐蚀噪声的影响，会将一些建筑物像素点分类为非建筑物，如图中红框所示，随着噪声级别的增加，这种影响会越来越大，如在Noise level 3中，U-Net基本已经无法对建筑物进行分类，而WLN即使在高噪声级别下依旧可以得到很好的分类结果。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320181435-8ifzmqa.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.5.11腐蚀噪声类型下U-Net和WLN的提取结果图</p> <h1 id="结论">结论</h1> <p>训练标签的错误通常很难被识别和纠正，尤其是在跨时间和地点的遥感数据集中。在本文中，我们提出了一种通用的抗噪声网络框架WLN，基于对每个训练样本进行加权损失的思想，将错误样本对遥感图像分类的影响降到最低。该框架由两个网络组成，即分割子网络和注意力子网络。分段子网络对图像逐个像素进行分类，并计算输出结果与标签，得到训练过程中的初始损失。注意力子网络生成批量样本的权重损失，并与类别平衡系数相结合，防止每个训练样本的类不平衡。这三部分结合得到最终的损失，并对两个子网络进行反推，更新网络参数。</p> <p>通过膨胀和腐蚀处理模拟四种标签噪声(不足标签、冗余标签、缺失标签、错误标签)来测试网络的抗噪声能力。在评估了所提出的WLN与原U-Net模型在Inria航空图像标签数据集中提取建筑物的性能后，我们发现：</p> <p>(1)当噪声率和噪声水平较低时，卷积神经网络几乎不受标签噪声的影响，这可能是由于网络特有的抗噪声能力。当训练集的标签噪声率超过一定阈值后，卷积神经网络的准确率就会明显下降。</p> <p>(2)对于四种标签噪声，如果数据集的样本噪声率和噪声水平逐渐增加，我们提出的方法WLN可以保持较高的精度，并优于原方法。</p> <p>(3)如果我们让网络选择哪些样本是必不可少的，就会发现局部最优问题。这种现象可能具有普遍性，可以通过加入类别平衡系数来调整类标签的不平衡性来缓解。这个问题将在以后的工作中进一步研究。</p>]]></content><author><name></name></author><category term="特征空间优化"/><category term="特征空间构建"/><summary type="html"><![CDATA[蒸散空间下的土壤特征空间构建]]></summary></entry><entry><title type="html">基于光学微波特征融合的新疆典型经济作物提取</title><link href="https://shawnmiloguo.github.io/blog/2016/SAR-OPT/" rel="alternate" type="text/html" title="基于光学微波特征融合的新疆典型经济作物提取"/><published>2016-02-03T21:01:00+00:00</published><updated>2016-02-03T21:01:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2016/SAR-OPT</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2016/SAR-OPT/"><![CDATA[<p>针对异物同谱效应造成的作物提取精度不足问题，本研究提出了一种集成光学和微波特征的方法，通过特征融合提高作物提取精度。本研究基于Sentinel-1合成孔径雷达影像和Sentinel-2多光谱数据，对新疆巴州地区的典型绿洲农业区进行作物分类制图。为提高雷达数据提取特征的质量，采用SHP-DSI方法，对时间序列Sentinel-1数据的后向散射强度进行相干斑抑制，并对相干系数进行精确估计和去偏。此外，首次在研究中提取了合成孔径雷达干涉（InSAR）产品用于作物分类，包括干涉相干系数，主从影像后向散射强度比和从SAR时间序列的振幅色离散度指数等。为探索红边特征在绿洲作物类型识别中的作用，本研究提取了Sentinel-2的3个红边波段并导出了11个红边指数，结合常规的多光谱特征，与雷达特征进行集成，以提高作物分类的精度。 为了处理高维特征，获取SAR和光学特征的最优组合，本研究提出了一种半自动化的特征筛选流程，基于随机森林算法的特征重要性排序以及递归特征增量（Recursive Feature Increment，RFI）算法对所有特征进行筛选，以达到最高的作物分类精度。本研究发现Sentinel-2的红边特征将作物分类精度提高了3.06%。在对比实验中本研究证实了时间序列Sentinel-1和Sentienl-2的特征融合在作物分类中可实现最高精度。</p> <h1 id="原文链接">原文链接</h1> <p>Sun, L., Chen, J., Guo, S., Deng, X., &amp; Han, Y. (2020). Integration of Time Series Sentinel-1 and Sentinel-2 Imagery for Crop Type Mapping over Oasis Agricultural Areas. Remote Sensing, 12(158), 1–27.</p> <h1 id="研究背景">研究背景</h1> <p>新疆是我国西北干旱半干旱地带的主要农业区。由于气候干燥，新疆的农业生产几乎完全依靠灌溉，导致水资源匮乏问题更加严重。新疆地区是我国棉花的主要产区，种植面积大，棉花品质较好，是国内棉花供给的重要支柱。2017年，新疆棉花种植面积占全国比重超过60%；棉花产量占全国比重超过70%。此外，棉花种植和其他农作物相比，需要大量的水源进行浇灌，加快了土地荒漠化的速度。新疆一些地区历经数次农业结构调整，实行“退白扩红”战略，大量种植辣椒和番茄，因此种植结构更加复杂，需要更加及时和精确的农作物种类分布制图。农作物种类分布是进行水资源和环境承载力估计所需的重要信息。在我国西北干旱半干旱地区，农业是支柱产业而生态环境相对较为脆弱，因此更为重要。随着空间技术的发展，遥感技术以已被应用到大范围的农作物种植面积、长势监测中，具有宏观、准确、及时等优点，监测结果可为国家农业生产管理、粮食政策制定提供重要参考依据。</p> <p>近年来，遥感技术被广泛应用于农作物种植面积监测及作物分类中。原来主要使用的是光学遥感影像，利用不同种类作物之间的物候期差异，通过植被指数的时间变化来进行某种作物的提取。有些研究采用MODIS植被指数时间序列进行作物分类，但是由于分辨率太低，不适用于地块尺寸小、异构性强的小农种植系统 。对于地块破碎、异构性强的种植区，中、高分辨率影像（30米以内）是更为合适的选择。此前也有不少研究采用Landsat NDVI时间序列进行作物提取、分类，但是由于Landsat重访周期较长，在作物生长关键期受频繁的云雨天气影响无法获取完整、连续的光学数据，严重影响监测的有效性 。Sentinel-2卫星的发射为遥感监测提供了较高时空分辨率的光学数据，重访周期为10天，分辨率达到10米，在小农种植系统的农作物种植面积、长势监测、作物分类等应用中具有较大的潜力 。但是，由于光学数据本身的特点，受云的影响，Sentinel-2在作物关键生长期的数据连续性仍然不能保证 。此外，对于具有相似物候周期的作物类型，只依靠光谱信息不足以进行区分。</p> <p>星载合成孔径雷达（SAR）遥感具有全天时、全天候、覆盖范围广、穿透能力强的特点，能够反映植被的结构特征与介电特性，已越来越多地用于遥感作物分类。Silva等在巴西热带半干旱地区采用L波段机载SAR影像研究了单/双/全极化SAR后向散射强度进行作物分类的潜力，发现增加极化通道可大幅度提高作物分类的精度 。还有研究表明，对于单极化和双极化SAR，使用多时相数据可以提高作物分类的准确性，其中采用交叉极化的后向散射系数其分类精度优于其他极化模式。随着Sentinel-1 A和B卫星的发射，可免费获取的SAR数据量显著增加，该数据具有双极化模式，双星6天单轨12天的重访周期和20米的空间分辨率，这对于中高分辨率的作物分类是目前较为理想的SAR数据源。然而，受SAR成像系统固有的相干斑噪声影响，单独采用SAR影像进行棉花提取的精度较低 。现有技术对SAR数据后向散射强度的相干斑抑制效果不理想，由于采用本地规则窗口进行滤波，没有考虑周边像素的统计特性，在抑制噪声的同时极易模糊强散射体与周边低相干区域。此外，大部分研究只关注雷达后向散射强度，没有对SAR影像的其他特征在作物分类中的作用进行评估。</p> <p>可见光遥感影像受云的影响难以得到长时间序列影像，SAR影像具有全天时、全天候工作的优点，可提供长时间序列数据弥补这一不足，且光谱和SAR影像由于传感器和成像机理的不同，在地物解译方面有互补作用 。如何结合光学数据和SAR数据进行综合处理，对作物种类进行精确分类和提取，成为研究的热点。</p> <p>本研究提出了一种集成Sentinel-1合成孔径雷达影像和Sentinel-1多光谱数据的方法，对新疆巴州地区的典型绿洲农业区进行作物分类制图。为提高雷达数据提取特征的质量，本研究采用SHP-DSI方法，对时间序列Sentinel-1数据的后向散射强度进行相干斑抑制，并对相干系数进行精确估计和去偏。此外，首次在研究中提取了合成孔径雷达干涉（InSAR）产品用于作物分类，包括干涉相干系数，主从影像后向散射强度比和从SAR时间序列的振幅色离散度指数等。为探索红边特征在绿洲作物类型识别中的作用，本研究提取了Sentinel-2的3个红边波段并导出了11个红边指数，结合常规的多光谱特征，与雷达特征进行集成，以提高作物分类的精度。为了处理高维特征，获取SAR和光学特征的最优组合，本研究提出了一种半自动化的特征筛选流程，基于随机森林算法的特征重要性排序以及递归特征增量（Recursive Feature Increment，RFI）算法对所有特征进行筛选，以达到最高的作物分类精度。本研究发现Sentinel-2的红边特征将作物分类精度提高了3.06%。在对比实验中本研究证实了时间序列Sentinel-1和Sentienl-2的特征融合在作物分类中可实现最高精度。</p> <h1 id="模型方法介绍">模型方法介绍</h1> <p>本研究中使用的工作流程如图 3.6.2所示。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320222619-dzamxcu.png" alt="image.png" class="rounded"/></p> <p>图 3.6.2实验流程</p> <ol> <li><strong>基于Sentinel-1数据提取SAR和InSAR</strong><strong>特征</strong> 对时间序列Sentinel-1 IW SLC数据进行预处理，包括精配准、镶嵌、裁剪。为提高SAR和InSAR特征的信噪比，基于Gamma置信区间判别从时序SAR数据中提取统计同质像元（SHP），并采用SHP-DSI算法进行相干斑滤波，在此基础上提取SAR和InSAR特征。</li> <li><strong>**基于Sentinel-2</strong>**数据提取多光谱特征<br/> 对多时相Sentinel-2数据进行预处理，采用sen2cor软件将L1C级Top of Atmosphere (TOA)产品转换为L2A级产品表面反射率(surface reflectance)，提取10米、20米分辨率的所有谱段（包括B2, B3, B4, B5 B6, B7, B8, B8A, B11, B12）；并计算植被指数、水体指数、红边指数等</li> <li><strong>雷达和光学特征融合</strong><br/> 基于随机森林（Random Forest，RF）算法对所有特征进行重要性排序，在此基础上采用递归特征增加（Recursive Feature Increment，RFI）方法选取最优特征组合，进行土地覆盖分类，获取农田掩膜；在农田掩膜范围内，进行作物分类，得到作物分类制图。</li> </ol> <h1 id="试验结果">试验结果</h1> <p>采用基于统计同质像素（SHP）的SHP-DSI 算法对SAR影像进行相干斑抑制和相干系数估计，结果如下：</p> <p><img src="/SIAT-GeoScience/assets/image-20220320223206-ge364cs.png" alt="image.png" class="rounded"/></p> <p>图3.6.3 SAR后向散射强度图 (a)原始强度图； (b) Refined Lee算法滤波后强度图；(c) SHP-DSI算法滤波后强度图</p> <p><img src="/SIAT-GeoScience/assets/image-20220320223248-jnsulrj.png" alt="image.png" class="rounded"/></p> <p>图3.6.4干涉相干系数 (a) 常规7*7滑窗估计的干涉相干系数;(b) SHP-DSI 算法估计的干涉相干系数</p> <p><a href="">表</a>3.6.6采用不同方法处理后的SAR&amp;InSAR特征进行作物分类的精度</p> <table> <thead> <tr> <th> </th> <th>Mean OA</th> <th>Kappa Coefficient</th> <th>F1-score chili</th> <th>F1-score corn</th> <th>F1-score cotton</th> <th>F1-score pear</th> <th>F1-score tomato</th> </tr> </thead> <tbody> <tr> <td>Original</td> <td>60.20%</td> <td>0.48</td> <td>0.55</td> <td>0.33</td> <td>0.67</td> <td>0.72</td> <td>0.58</td> </tr> <tr> <td>Refined Lee</td> <td>73.21%</td> <td>0.65</td> <td>0.66</td> <td>0.52</td> <td>0.80</td> <td>0.83</td> <td>0.74</td> </tr> <tr> <td>SHP DSI</td> <td>79.46%</td> <td>0.73</td> <td>0.75</td> <td>0.60</td> <td>0.88</td> <td>0.86</td> <td>0.77</td> </tr> </tbody> </table> <p>从表3.6.6中可以看到，采用SHP-DSI算法较原始数据和常规Refined Lee算法滤波后提取的SAR和InSAR特征在作物分类制图中显著提高了精度，无论是总体精度（OA）、Kappa系数，还是每一个作物种类的F1-sore都有显著提高。采用随机森林算法进行一级类分类以提取农田，并采用分层交叉验证（K=10份）方法对总体精度和农田提取精度进行验证，结果如下：</p> <p><img src="/SIAT-GeoScience/assets/image-20220320223402-iu5ftzt.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.6.5(a) 土地覆盖分类结果；(b) 农田掩膜</p> <p><img src="/SIAT-GeoScience/assets/image-20220320223423-v17caoc.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.6.6雷达和光学特征集成获取的作物种类制图</p> <p>对比只使用SAR特征，只使用光学特征，以及SAR和光学特征的最优组合分别进行作物分类制图，精度对比如下：</p> <p><a href="">表 </a>3.6.9分别采用Sentinel-1、Sentinel-2常规多光谱特征、Sentinel-2包括红边特征在内的所有光学特征、Sentinel-1&amp;2集成特征的作物分类制图精度对比</p> <table> <thead> <tr> <th> </th> <th>Number of features</th> <th>Mean OA</th> <th>Kappa Coefficient</th> </tr> </thead> <tbody> <tr> <td>Sentinel-1</td> <td>133</td> <td>79.46%</td> <td>0.73</td> </tr> <tr> <td>Sentinel-2 without red-edge features</td> <td>58</td> <td>82.37%</td> <td>0.77</td> </tr> <tr> <td>Sentinel-2</td> <td>104</td> <td>85.43%</td> <td>0.81</td> </tr> <tr> <td>Sentinel-1 &amp; Sentinel-2</td> <td>113</td> <td>86.98%</td> <td>0.83</td> </tr> </tbody> </table> <p>表3.6.9说明，Sentinel-2的红边特征对比常规多光谱特征，将作物分类的OA提高了3.06%,Kappa系数提高了0.04；Sentinel-1雷达和Sentinel-2光学特征融合后，总体精度(OA)和Kappa系数比单独使用雷达或光学特征都有显著提高。</p> <p>对比分别采用Sentinel-1、Sentinel-2常规多光谱特征、Sentinel-2包括红边特征在内的所有光学特征、Sentinel-1&amp;2集成特征的每种作物类别的提取精度如图3.6.7所示。</p> <p><img src="/SIAT-GeoScience/assets/image-20220320223515-7sruzy2.png" alt="image.png" class="rounded"/></p> <p><a href="">图</a>3.6.7不同特征组合下不同种类作物的提取精度对比</p> <p>从图3.6.7中本研究可以发现，对于辣椒和玉米，红边特征对提取精度的提高较显著；对于棉花和香梨，只采用Sentinel-1雷达特征时，各自的提取精度已经很高，Sentinel-2多光谱特征的加入又进一步提高了提取精度；对于番茄的提取，采用雷达特征、常规多光谱特征、红边特征的提取精度是一样的，雷达和光学特征的集成才显著提高了提取精度。查看每种作物的提取精度对比，共同点是，采用Sentinel-1&amp;2集成特征时，辣椒、玉米、棉花、香梨、番茄每种作物的提取F1-score都是几个特征组合中最高的。</p> <h1 id="结论">结论</h1> <p>本研究通过西北某小农区的案例研究，提出了一种协同利用 Sentinel-1 和 Sentinel-2 特征进行绿洲作物类型测绘的方法。首先，引入了 SHP DSI 算法，对 SAR 强度进行去斑处理，准确估计干涉测量相干性，提高 SAR 特征的质量。研究表明，在仅使用 SAR 特征的情况下，使用 SHP DSI 方法可使作物分类精度提高 6.25%。从多时态的 Sentinel-1 和 Sentinel-2 图像中得到了多种 SAR 特征和光学特征，包括几种 InSAR 产品和红边光谱波段和指数。其次，根据随机森林分类器的换元重要性，提出了一种递归特征增量特征选择方法，得到 Sentinel-1和 Sentinel-2 特征的最优组合，用于农田提取和作物类型分类。最后，生成了作物分布图，总体精度为 83.22%， kappa 系数为 0.77。对 SAR 和光学特征的贡献进行了深入探讨。在所有 Sentinel-1 特征中,VH 强度所占比例最大,说明 VH 偏振对植被变化的敏感性较好。同时，还注意到 InSAR 的一些产品，如 VH 振幅色散、主从强度比、 4 月上旬的 VV相干性等，揭示了某些作物类型的良好分离性。至于 Sentinel-2 特征，我们证明了在绿洲作物类型测绘中使用红边光谱波段和指数的优点。与仅使用传统光学特征相比，红边特征的加入使作物分类 OA提高了 1.84%。这证明了 Sentinel-2 数据的优越性，因为光谱分辨率的提高。对使用 4 种特征组合的绿洲作物分类性能进行了比较。结果表明， SAR 和光学特征的集成取得了最佳性能。我们认为，时间序列 S1 和 S2 图像的集成具有优势，由于数据的免费、充分和开放政策，可以在绝大多数地区进一步探索用于作物状况监测。</p>]]></content><author><name></name></author><category term="特征空间优化"/><category term="特征空间构建"/><summary type="html"><![CDATA[蒸散空间下的土壤特征空间构建]]></summary></entry><entry><title type="html">快速评估监督学习中常用遥感分类算法的时间效率</title><link href="https://shawnmiloguo.github.io/blog/2016/FPTC/" rel="alternate" type="text/html" title="快速评估监督学习中常用遥感分类算法的时间效率"/><published>2016-02-03T21:01:00+00:00</published><updated>2016-02-03T21:01:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2016/FPTC</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2016/FPTC/"><![CDATA[<p>本文的提出了全参数时间复杂度(Full parameter time complexity，以下简称FPTC)，它考虑了所有可能耗时的参数。同时，我们定义了一个系数$\omega$来模拟不同分类器在不同平台之间的物理差异。<br/> 在下面的章节中，我们将根据FPTC在本文中的定义，具体推导以下几个算法的FPTC，其中包括：$k$NN ($k$-nearest neighbors) , LR (logistic regression) , CART (classification and regression tree) , RF (random forest)和 SVM (support vector machine) 。为了检验FPTC和相应的系数$\omega$的有效性，我们选择了新疆维吾尔自治区和Sentinel-2A数据集作为案例研究。<br/> 本文将首先阐述FPTC的定义，然后推导常用几个算法的FPTC，随后在具体的数据集中，验证我们提出的FPTC的有效性，同时进一步研究相关参数的影响。</p> <h1 id="原文链接">原文链接</h1> <p>Zheng, X., Jia, J., Guo, S., Chen, J., Sun, L., Xiong, Y., &amp; Xu, W. (2021). Full Parameter Time Complexity (FPTC): A Method to Evaluate the Running Time of Machine Learning Classifiers for Land Use/Land Cover Classification. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 14, 2222–2235. https://doi.org/10.1109/JSTARS.2021.3050166</p> <h1 id="算法时间估算的基本理论">算法时间估算的基本理论</h1> <p>对自然灾害和风险的评估是从公众到政府应急管理人员等各种行为者决策过程的基础。迅速量化损失和预期的未来损失通常是了解当前情况的第一步。遥感影像的土地利用/土地覆盖 (Land use/land cover, 以下简称LULC) 产品可以为这一目的提供第一手信息 。由于这一决策过程通常是紧迫的，在有限的时间和资源下选择合适的分类算法来实现这一目标可能是具有挑战性的引用。除了分类精度之外，算法的实际时间消耗是运行任务之前需要仔细评估的另一个方面 （Donoho2012,Huang2017,Khatami2016）。在没有准确预测时间消耗的情况下，在这些紧急情况下选择LULC分类算法可能是盲目的和主观的。</p> <p>通常，估计分类任务的时间消耗的方法可以分为两类：(1) 基于采样数据的方法和；(2) 基于时间复杂度的方法。第一类包括基于运行程序和启动对采样数据集的时间计算功能进行估计。这方法是假定样本和整个数据集之间的实际运行时间可以通过线性或非线性关系来简化。虽然这些方法被用于各种研究，但是它们的缺点是：(1) 这种线性或非线性关系高度依赖于硬件，不能在不同的计算环境中推广；(2) 算法的不同参数 (操作参数和隐藏参数) 的影响被视为一个黑匣子。同时，这些参数对运行时间的影响尚不清楚。第二类涉及基于时间复杂性分析的评估。常用的渐近时间复杂度就属于这一类，通常称为传统时间复杂度 (Traditional time complexity，以下简称TTC)。TTC是输入大小(例如，样本数量)的函数，它衡量在单位操作迭代(例如，加法或乘法)下，随着输入大小的增加，计算复杂度的变化。假定每个单元操作的时间具有相同的值，因此可以估计迭代次数与运行时间成比例。在计算TTC的过程中，忽略了许多低阶细节。例如，当我们计算函数 $f\left(n\right)=an^2+bn+c$ 的TTC时(<br/> 其中$n$ 代表了输入规模)，我们只关心$n$的最高次项，即 $f\left(n\right)=n^2$ 。$O(n^2)$ 表示了这个函数的时间复杂度的最上界。 TTC的目的是在理论级别捕获随着数据大小的增加而加速的运行时间 $({N})$。然而， 这很难用于运行时间的准确预测，特别是在遥感LULC分类任务中，时间消耗不仅与数据大小$({N})$有关，还与其他参数有关（例如，波段数或者SVM中支持向量的个数）。 如何考虑这些参数的影响来预测总体时间消耗仍然是一个挑战。</p> <p>事实上，在不考虑不同平台(如CPU和GPU)之间的物理差异的情况下，分类算法的时间消耗会受到：(1) 数据大小; (2) 类的数量；(3) 波段/特征的数量; (4) 算法的迭代结构; (5) 算法的操作参数(如随机森林中的树的数量)和 (6) 算法的隐藏参数(如支持向量的数量)的影响。所有这些组件都通过未知机制以不同的方式影响算法的实际时间消耗。确定如何量化每个部分的贡献是预测实际时间的关键。</p> <h1 id="基于fptc进行时间估算的基础理论与常见算法fptc的推导">基于FPTC进行时间估算的基础理论与常见算法FPTC的推导</h1> <p>FPTC 包含了两个部分：一部分为 $F(n,m,v,\boldsymbol{\theta}’)$，这个部分与算法息息相关，可以根据对特定分类器的结构分析得出。这个部分是关于 $n,m,v$ 和 $\boldsymbol{\theta}’$的函数。其中，$n$ 为样本量大小， $m$ 为类别数， $v$ 为波段数， $\boldsymbol{\theta}’$ 代表与算法相关的参数合集。值得注意的是不同算法的 $\boldsymbol{\theta}’$ 可能是不一样的。举个例子， $k$NN 的 $\boldsymbol{\theta}’$ 可能包含了最近邻数 $u$, 而SVM的$\boldsymbol{\theta}’$可能包含了迭代次数$Q$和支持向量个数$k$。第二个部分是参数$\omega $, 它是反映计算环境因素的物理相关部分对运行时间的影响, 例如CPU/GPU或者RAM的速度。因此，系数 $\omega $与运行平台息息相关。通常，在数据集的一小部分上进行预实验可以帮助我们评估特定分类器的这个系数。结合这两个部分，FPTC的定义如下：</p> \[t^*= F(n,m,v,\boldsymbol{\theta}')\] \[t'= \omega \times t^*\] <p>$t’\ $表示真实的运行时间， $\omega$ 表示系数， $\ t^*\ $是通过分析算法结构儿预估的时间。在下一节中，我们将推导出遥感领域中五种经典和常用的分类器的FPTC算法相关部分。我们按以下顺序推导出所选算法的FPTC： $k$NN，LR，CART，RF和 SVM。</p> <h1 id="knn的fptc推导">$k$NN的FPTC推导</h1> <p>$k$NN分类器是一个懒惰的学习器，这意味着建立模型的时间成本很低，但对测试样本进行分类的时间成本相对较高。为了计算测试样本的时间复杂度，我们将$k$NN分类器的FPTC分解为两部分来说明。首先，计算训练样本$\textbf{x}^{(e)}$ 和测试数据之间的距离的FPTC为$F(v)$。当训练集有$n$个样本时，FPTC为$F(vn)$。其次，算法需要从训练集中选择距离最小的$u$个训练样本。这是经典的最优搜索问题，最优FPTC为$F(nv+\ n{log}<em>2u)$。因此，$k$NN分类器的总FPTC为$F(nv+n{log}_2u)$。考虑到相应的系数${\omega}</em>{knn}$，$k$NN分类器的FPTC与实际运行时间$t’_{kNN}$关联如下：</p> \[t'_{kNN}=\omega_{kNN} \times t^*_{kNN} = \omega_{kNN} \times F(nv+nlog_2u)\] <p><img src="/SIAT-GeoScience/assets/image-20220321144323-mk87iku.png" alt="image.png" class="rounded"/></p> <p>KNN分类器的FPTC推导过程示意图。</p> <h1 id="lr的fptc推导">LR的FPTC推导</h1> <p>多分类LR分类器将其后验概率由Sigmoid变换替换为Softmax变换来执行多分类任务的。LR通常将L2范数作为正则化项加入到损失函数中，以提高LR分类器的稳定性和鲁棒性。根据我们的推导，具有L2范数和Softmax后验概率的LR的损失函数采用以下形式：</p> \[J(\boldsymbol{\theta}) = -\frac{1}{n} \cdot\sum_{i=1}^n\sum^m_{j=1}1\left\{y^{(i)}=j\right\}\cdot log\frac{exp(\boldsymbol{\theta}^T_j \textbf{x}^{(i)})}{\sum^m_{l=1}exp(\boldsymbol{\theta}^T_l\textbf{x}^{(i)})}+\frac{a}{2}\cdot\parallel\boldsymbol{\theta}\parallel^2_2\] <p>其中，$\boldsymbol{\theta }$是 $v\times m$ 的矩阵, $\boldsymbol{\theta }$ 中的元素是LR中的参数, ${\theta }_{pj}$ 是要素图层$p$中$j$类别的权重，$\alpha$的大小影响正则化强度。</p> <p>LR分类器的目标是最小化损失函数时得到$\boldsymbol{\theta}$的最优值。随机平均梯度(stochastic average gradient, SAG) 是优化LR分类器的常用策略。SAG算法是对随机梯度下降算法(stochastic gradient descent，SGD)的一种改进。根据我们的推导，具有L2范数和Softmax变换的LR分类器中的参数 \(\boldsymbol{\theta}_j^T = \left\{\theta_{1j},\theta_{2j},\theta_{3j},......,\theta_{vj}\right\}\) 是根据公式5-7进行更新。</p> \[\boldsymbol{\theta}^{r+1}_j= \boldsymbol{\theta}^{r}_{j} -\frac{\lambda}{n} \sum^n_{i=1}z^r_i\] \[\textbf{z}^r_i= \begin{cases} \nabla_{\boldsymbol{\theta_{j}}}J(\boldsymbol{\theta})&amp; if \ i=i_r\\ z_i^r &amp; otherwise \end{cases}\] \[\nabla_{\boldsymbol{\theta_{j}}} J(\boldsymbol{\theta})= \textbf{x}^{(i)}(1\left\{y^{(i)}=j\right\})- \frac{exp(\boldsymbol{\theta}^T_j \textbf{x}^{(i)})}{\sum^m_{l=1}exp(\boldsymbol{\theta}^T_l\textbf{x}^{(i)})} +\alpha\boldsymbol{\theta}_j\] <p>其中， $\lambda$ 是学习率，$i_r\ $ 是从${1,\ 2,\ 3,\dots ,\ n}$ 中随机选出的第 $r$次迭代.</p> <p>对于每次迭代，(公式5)-(公式7)便更新一次。因此，损失函数便根据(公式7)计算了一次。同时，具有$v$元素的$\boldsymbol{\theta_j}$便根据(公式6)更新了一次。基于上述分析，每次迭代的FPTC为$F(mvn)$。在多分类的LR中，假设对每个类别进行$q$次迭代后收敛（$q$为SAG过程中迭代次数），则总FPTC为$F(Qmvn)$。在这种情况下，$m$类别的FPTC为写为$F(Qm^2vn)$。最后，LR的FPTC与实际运行时间$t’_{LR}$关联如下，推导LR的FPTC的关键步骤如图所示：</p> \[t'_{LR}=\omega_{LR} \times t^*_{LR}=\omega_{LR}\times F(Qm^2vn)\] <p><img src="/SIAT-GeoScience/assets/image-20220321144853-se7lutf.png" alt="image.png" class="rounded"/></p> <p>LR多分类器的FPTC推导过程示意图。</p> <h1 id="fptc的验证与精度评价">FPTC的验证与精度评价</h1> <p>为了验证FPTC的准确性，我们采用了三种评估方法：1)、用1：1的曲线图将实际运行时间与FPTC进行比较；2)、利用FPTC估计运行时间，并计算估计运行时间与观测运行时间之间的均方根误差(Root Mean Squared Error, RMSE)；3)、比较FPTC和TTC在不同特征选择下的实际运行时间。</p> <p><img src="/SIAT-GeoScience/assets/image-20220321144946-ypvxaof.png" alt="image.png" class="rounded"/></p> <p>我们从训练数据集中随机选择子训练样本，并构造子训练样本集。对这些样本进行分类，并记录真实的运行时间。如图所示，FPTC与实际运行时间之间的线性关系表明了FPTC的有效性。5个分类器的R平方值均大于0.99($k$NN：0.991，LR：0.997，CART：0.999，RF：1.000，SVM：0.999)，表明FPTC的算法部分与实际运行时间之间存在极强的线性关系({p} $&lt;$ 0.001)。</p> <p>每一个算法的参数 $\omega$ 可以从各自相关性曲线的斜率中获得。</p> <p>无论训练数据的大小如何，都可以基于两个可用的数据集粗略地估计斜率。这意味着可以通过在总数据集的两个小部分下预先运行算法来获得此值。由于系数$\omega$表示FPTC的物理部分，因此仅当算法应用于不同的计算环境时，该值才会改变。</p> <p><img src="/SIAT-GeoScience/assets/image-20220321145116-updnpcw.png" alt="image.png" class="rounded"/></p> <p>TTC(左列)和FPTC(中列)与实际运行时间(右列)的比较。</p> <p>此外，FPTC还可以通过不同的参数反映运行时间的变化。当n个训练样本由低到高变化，且其他影响参数保持不变时，支持向量机的FPTC最容易受到这种变化的影响，其次是RF、CART、kNN和LR。如果n从1变为128，则LR的FPTC增加128倍，kNN增加128倍多，CART和RF增加896倍，SVM增加16,384倍以上。当分类数m由低变高且其他影响参数保持不变时，支持向量机和LR的FPTC最容易受到这种变化的影响，其次是CART和RF，而kNN则不受影响。例如，如果m从两个类变为200个类，则SVM和LR的FPTC增加10,000倍，CART和RF的FPTC增加100倍。当特征数或波段数v由低变高且其他影响参数不变时，SVM、LR、CART和RF的时间复杂度在多项式时间内变化，而kNN的时间复杂度受影响较小。<br/> 其次，为了进一步说明FPTC和TTC的差异，我们分析了在不同波段(v=3, 4, 5,…,10)和不同样本大小(n=10, 20, 30,…,100,000)的所有组合下，FPTC和TTC的变化趋势，并与实际运行时间趋势进行了比较。在图9中，TTC、FPTC和实际运行时间的值以红色到绿色从低到高映射。结果表明，TTC对v的变化没有反应，而FPTC能更好地反映v的变化。<br/> 正如我们所看到的，在不同的带宽和数据大小下，FPTC显示出与实际运行时间相似的模式。TTC的模式是不同的，因为TTC忽略了不同特征/波段的影响。</p> <h1 id="总结">总结</h1> <p>在自然灾害应急响应中，准确的时间预测有助于应急管理者在有限的时间和资源下选择分类算法。在本研究中，我们提出了FPTC和系数$\omega$来估计每个分类器的运行时间。通过研究分类器程序的总体结构及其数学原理，推导出五种常见分类器($k$NN、LR、CART、RF和SVM)的FPTC。根据实际运行时间与FPTC之间的关系，建立了线性回归模型，并由线性回归得到了系数$\omega $。然后，我们准确地预测了每个分类器的运行时间，并筛选出合适的分类器。研究结果可概括如下：</p> <ul> <li> <p>提出了一种定量评估机器学习分类器时间效率的方法–FPTC。我们推导了五种通用分类器的FPTC。结果表明$k$NN 的FPTC 是 $F(nv+\ n{log}_2u)$, LR的FPTC是 $F(Qm^2vn)$, CART的FPTC是 $F((m+1)nv{log}_2n)$), RF是FPTC是 $F(s(m+1)nv{log}_2n)$, SVM的FPTC是 $F(m^2Qv\ (n+k))$.</p> </li> <li> <p>在我们的研究中，FPTC与运行时间之间存在很强的线性关系 (${R}^2$ $\geq 0.991$, $\ p\le 0.001$)。 这种线性关系验证了FPTC推导过程的正确性。每种算法的修正系数都可以从强线性回归中得到。</p> </li> <li> <p>每个分类器的运行时间用FPTC中的系数$\omega$来估计。研究表明，实际运行时间与估计运行时间之间的平均均方根误差为3.34s，说明了用FPTC预测算法运行时间的可行性和准确性。</p> </li> <li> <p>研究表明，支持向量机的训练参数$Q$与样本数有显著的线性相关关系($R^2=1.00$), 而LR的$Q$是稳定的，不随$n$的变化而变化。根据上述规则，支持向量机的总FPTC被修正为$F(m^2vn^2)$，LR的总FPTC被修正为$F(m^2vn)$。更新的FPTC不受程序是否提前运行的影响。</p> </li> </ul> <p>未来的研究中，我们计划为算法推导出更多的FPTC值。对于紧急任务，可以快速筛选出精度高、FPTC低的合适算法，帮助应急管理人员根据可获得的遥感数据量，快速做出应对自然灾害的决策。</p>]]></content><author><name></name></author><category term="特征空间优化"/><category term="特征空间构建"/><summary type="html"><![CDATA[蒸散空间下的土壤特征空间构建]]></summary></entry><entry><title type="html">使用级联多级检测器的多分辨率遥感图像的高质量目标检测</title><link href="https://shawnmiloguo.github.io/blog/2016/HQODMRSI-CMD/" rel="alternate" type="text/html" title="使用级联多级检测器的多分辨率遥感图像的高质量目标检测"/><published>2016-02-03T21:01:00+00:00</published><updated>2016-02-03T21:01:00+00:00</updated><id>https://shawnmiloguo.github.io/blog/2016/HQODMRSI-CMD</id><content type="html" xml:base="https://shawnmiloguo.github.io/blog/2016/HQODMRSI-CMD/"><![CDATA[<p>基于深度学习的物体检测器在精度和自动化程度方面大大改善了遥感图像中最先进的物体检测。然而，物体尺度的巨大变化使得在多分辨率的遥感图像中很难实现高质量的检测，而质量是由训练中使用的交叉联合（IoU）阈值定义的。此外，跨多分辨率图像的正负样本之间的不平衡也使检测精度恶化。最近，人们发现，基于级联的区域卷积神经网络（R-CNN）通过引入级联的三级结构，使用逐步提高的IoU阈值，有可能实现更高的检测质量。然而，当加入第四级时，级联R-CNN的性能下降了。我们调查了原因，发现ROI特征和分类器之间的不匹配可能是造成性能下降的原因。在此，我们提出了一个级联R-CNN++结构来解决这个问题，并将三段式结构扩展到多段式结构，供一般使用。具体来说，对于级联分类，我们提出了一种新的分类器和兴趣区域（RoI）特征的集合策略，以提高推理时的分类精度。在定位方面，我们修改了边界盒回归器的损失函数，以获得零附近更高的灵敏度。在DOTA数据集上的实验表明，Cascade R-CNN++在精度和检测质量方面优于Cascade R-CNN。我们对多分辨率遥感图像进行了进一步分析，以验证模型在不同物体尺度上的可迁移性。</p> <h1 id="原文链接">原文链接</h1> <p><a href="https://www.mdpi.com/2072-4292/14/9/2091">https://www.mdpi.com/2072-4292/14/9/2091</a></p> <h1 id="背景及科学问题">背景及科学问题</h1> <p>遥感图像中的物体检测在一些民用和军事应用中发挥着重要作用，如城市规划、地理信息系统更新和搜救行动。与传统方法（基于模板匹配的方法[1,2]、基于知识的方法[3,4]等）相比，基于深度学习的方法通过将人工特征设计的负担迁移到底层学习系统，从原始数据中自动提取特征，使其具有更强大的特征表示能力，以提取更高语义水平的特征图。凭借这一优势，基于深度学习的检测方法在计算机视觉和遥感界都取得了巨大成功[5,6]。</p> <p>与自然场景图像不同，遥感图像在不同的观测条件下具有更大的尺度变化和更多的特征复杂性，这就要求物体检测器具有更高的泛化能力。最近，基于DNN的检测方法从计算机视觉领域被引入到遥感领域，并在多类物体检测上取得了优异的成绩。遥感图像深度学习物体检测的许多基本问题得到了解决，如缺乏足够的训练样本[7,8]，小物体检测的性能差[9,10,11]，以及卫星图像中物体的旋转特性[12,13]。撰写于2020年的全面回顾可以在文章[5]中找到。</p> <p>尽管如此，多分辨率遥感图像中物体尺度的巨大变化仍然给物体检测器带来巨大挑战。最近，一些研究从不同方面探讨了解决这一问题的可能性，可以归纳为三类。(1) 不同层次的特征融合：在这一类别中，许多融合模型都是为了提取多尺度的特征层次，以提高模型在小物体和大物体上的性能。有代表性的研究包括跨尺度特征融合（CSFF）[14]、基于双特征金字塔网络（FPN）的偏振注意机制模块[15]、特征融合架构（FFA）[16]、多片特征金字塔网络[17]和Quad-FPN[18]。(2) 改进区域建议网络以生成更合适的锚点：这些模型解决了多尺度图像中锚点尺寸和物体尺寸的不匹配问题，如自适应长宽比锚点(SARA)[19]，多尺度空间注意区域建议网络[20]，以及尺寸折叠操作(SF)[21]。(3) 建立平行网络来检测不同尺度的物体：其中一个代表性的工作是多专家检测网络（MEDNet）[22]。</p> <p>上述方法主要集中在不同尺度的物体之间的特征提取和特征匹配。除此之外，正负样本的不平衡也是模型无法检测不同尺度物体的另一个原因[23]。与小物体相比，大物体更容易被识别为正样本，而且精度更高。当把由高分辨率图像预训练的模型应用于低分辨率图像时，大多数大物体会变成小物体，导致阳性样本太少，无法有效训练模型。</p> <p>在基于锚点的检测器中，通常使用一个交叉-联合（IoU）阈值来区分阳性/阴性样本，这也定义了检测质量[24]。选择一个合适的阈值是检测质量和精度之间的妥协，因为较低的IoU阈值会带来更多潜在的物体区域建议，但会有更多的噪声样本，这导致了不可靠的检测结果。然而，在训练中使用高的IoU阈值会导致阳性样本太少，从而导致模型过拟合。</p> <p>为了达到高精度，IoU阈值必须与检测器假说的质量密切相关[25]。级联R-CNN[25]，作为两阶段基于锚的检测器的扩展，使用三阶段的级联结构来解决上述问题，训练样本的IoU（即假设的质量）可以通过级联的边界盒回归来逐步提高。这种级联结构依次提高阳性训练样本的数量和质量，以减少过拟合问题。在自然场景图像的实验中，级联结构在检测不同尺度的物体时取得了更好的精度。然而，在级联R-CNN的原始结构中，级联组件的最大数量为3个。当增加第四级时，整体检测性能就会下降[25]。这就限制了级联检测器的扩展，以实现更好的检测性能。</p> <p>在本文中，我们研究了增加更多级联阶段时性能下降的原因。我们发现，在推理时，级联R-CNN中的原始集合策略在分类器和兴趣区域（RoI）向量之间引入了不匹配，降低了分类精度。</p> <p>为了克服这一局限性，我们提出了一种新的级联分类的集合策略，即采取同一阶段产生的RoI特征进行分类，而不是统一使用最后阶段的特征。最终的分类结果是通过整合所有阶段的分类器输出得到的。此外，边界盒回归[26]的损失函数被修改以提高灵敏度，使级联回归器随着阶段数的增加而进一步收敛。修改后的级联结构在本文中被表示为级联R-CNN++。</p> <p>本研究的主要贡献有以下几点。(1）我们研究了级联检测器在增加更多阶段时性能下降的原因；（2）我们提出了一种新的集合策略，以尽量减少推理时分类器和输入RoI之间的不匹配，并提高分类精度；（3）我们提出了一个修改的边界盒回归的损失函数，使边界盒回归在建立更多阶段时进一步收敛。所提出的Cascade R-CNN++方法可以在遥感数据集DOTA上实现最先进的检测性能[27,28]。它可以在大多数需要基于区域建议的方法的情况下实施。在多分辨率遥感图像的实验中，所提出的方法在检测质量和精度上都优于级联R-CNN。</p> <h1 id="研究方法介绍级联r-cnn">研究方法介绍：级联R-CNN++</h1> <p>级联R-CNN[25]使用三级级联检测器来逐步改善训练样本的IoU分布。通过级联回归，可以实现更高的物体定位精度。然而，当增加第四级时，AP、AP50、AP60、AP70和AP80的指标都会下降，只有AP90略有增加。在此，我们研究了性能下降的原因。</p> <p>在本文中，我们通过修改Cascade R-CNN来提出Cascade R-CNN++方法。首先，我们为分类器和推理时的RoI特征提出了一个新的集合策略。其次，我们提出了一个改进的损失函数，用于边界箱回归，以实现零附近的高灵敏度，这使得更多阶段的加入能够进一步收敛。图3显示了所提出的级联R-CNN++的一个五阶段的例子。区域建议的生成采用了RPN。</p> <h2 id="新的分类组合策略">新的分类组合策略</h2> <p>正如在[25]中所定义的，一个分类器被表示为一个函数h(xi)它将一个特征向量xi归入m+1个类中的一个，其中0为背景，其余每个值代表一个类。一个分类器的输出是一个m+1维向量，其最大值表示边界框中的物体所属的类别。分类器是通过最小化交叉熵损失Rcls来训练的。</p> <h2 id="边界盒回归的修正损失函数">边界盒回归的修正损失函数</h2> <p>在每个阶段，边界盒回归器被用来通过最小化真实边界盒和候选边界盒之间的偏移量来逐渐使候选提案接近真实标签位置。一个输入建议p可以通过以下方式转化为预测的真实标签框g。推导公式表示如下： <img src="/SIAT-GeoScience/assets/2022-04-27 公式.png" alt="image.png" class="rounded"/> 其中p=(px,py,pw,ph)表示输入建议的位置，g=(gx,gy,gw,gh)是预测的真实标签箱。Δ=(tx/cx,ty/cy,tw/cw,th/ch)代表距离向量，即由边界盒回归器进行的微小调整。是影响距离向量大小的权重，权重cx、cy、cw、ch最初设定为（10，10，5，5），并随着阶段的增加而逐渐增加。由于边界盒回归器对偏移向量Δ进行了微调，这些值通常是非常小的。因此，归一化被执行为Δ[25,35,36,41].对于一个图像补丁xj，级联R-CNN[25]中使用的边界盒回归的损失函数可以表示为Rloc，其中Rloc是边界盒回归的交叉熵损失，j是一个候选方案的索引，Nloc是候选提案的数量，Lloc表示S1平滑L1函数[24]。</p> <p>其中f(xj,pj)是边界盒回归函数，pj=(pjx,pjy,pjw,pjh)是第j个是第j个候选方案，有四个坐标，即中心位置（pjx,pjy)，以及盒子的宽度和高度（pjw,pjy）.gj代表预测的真实标签框，以同样的方式指定（gj=(gjx,gjy,gjw,gjh)). 此后，除非需要，我们忽略上标j为简单起见。</p> <p>为了使更多阶段的级联回归能够进一步收敛，我们改进了边界盒回归的损失函数，以实现零附近的高灵敏度。</p> <p>其中sgn是符号函数，指数4/3的条款（tk/ck）4/3，和k∈{x,y,w,h}。是为了增加非线性并保持灵敏度和损失梯度之间的权衡。输入(tx,ty,tw,th)与边界箱输出偏移量（gx-px,gy-py,gw/pw,gh/ph）绘制成图。对于不同权重的原始和修改后的损失函数ci，i∈{x,y,w,h}。不同阶段（图4和图5）。修改后的损失函数在零点附近的曲线更平滑，表明当候选边界盒和真实标签之间的偏移接近零时，回归器的步长更小（即灵敏度更高）。这一修改使得级联边界盒回归器随着阶段的增加而进一步收敛。 <img src="/SIAT-GeoScience/assets/2022-04-27 图4-图5.png" alt="image.png" class="rounded"/> <img src="/SIAT-GeoScience/assets/2022-04-27 图6.png" alt="image.png" class="rounded"/> 图6说明了在损失函数中采取不同指数值的效果。我们可以看到，较大的指数值对应于损失函数在零附近的较高灵敏度，但收敛速度较慢。指数项为4/3是灵敏度和收敛速度之间的权衡。该值是经过多次实验后选择的经验值。</p> <h1 id="试验结果">试验结果</h1> <p><img src="/SIAT-GeoScience/assets/2022-04-27 表2-表5.png" alt="image.png" class="rounded"/></p> <h2 id="阶段性的比较">阶段性的比较</h2> <p>在DOTA数据集上，我们比较了三级、四级和五级级联R-CNN++的检测性能，它们都以ResNet-50为骨干。结果见表2，其中AP表示平均精度，AP50、AP75和AP90分别表示使用0.5、0.75和0.9的IoU阈值的检测精度。APS、APM和APL分别表示小型、中型和大型物体的检测精度。</p> <p>如表2所示，整体检测精度随着阶段的增加而提高，以FPS（每秒帧数）衡量的推理速度没有明显下降。</p> <h2 id="建议修改的消融实验">建议修改的消融实验</h2> <p>通过使用ResNet-50骨干网进行消融实验，进一步分析了Cascade R-CNN++的检测性能。结果显示在表3中。采用新的集合策略和修改后的边界盒回归损失函数的级联检测器取得了最好的精度，在AP90中也有明显的改善。</p> <h2 id="与最先进的检测器的比较">与最先进的检测器的比较</h2> <p>在DOTA-v1.5数据集上，提议的Cascade R-CNN++的性能与最先进的两级/多级检测器进行了比较，详见表4。用*表示的条目使用了包括多尺度训练/推理和SoftNMS在内的增强措施，如[43,45]。</p> <p>如表4所示，与Faster R-CNN、FPN、RetinaNet和原始Cascade R-CNN相比，提议的Cascade R-CN++在所有指标上都取得了更高的精度。在AP90上的改进最为明显，其次是对中型和小型物体的检测精度（即APM和APS）。这些结果证明，所提出的方法是有效的，并且优于最先进的检测器，特别是在高质量检测方面。在实验中，我们还实现了具有多尺度训练/推理和softNMS的Cascade R-CNN++，在表4中用Cascade R-CNN++ *表示。通过这些改进，Cascade R-CNN++超过了Cascade R-CNN 4.6分。值得注意的是，最近的其他研究从不同的角度（如特征金字塔）探讨了改进措施，表明这些改进措施的累积效应可以进一步提高多阶段检测器在遥感物体检测、实例分割、关键点检测等领域的性能。</p> <p>在另一个遥感数据集NWPU VHR-10上也进行了比较（表5）。训练以0.01的学习率开始，在30 k和40 k的迭代中分别降低到0.001和0.0001，并在50 k的迭代中完成。其他实施设置与DOTA-v1.5上的实验相同。</p> <p>从表5中我们可以看出，所提出的Cascade R-CNN++在NWPU VHR-10数据集上产生了最好的性能，特别是在AP75和AP90所显示的高质量检测上。小物体的检测精度比原来的Cascade R-CNN方法提高了4.8%。</p> <h2 id="模型在多分辨率遥感图像上的可迁移性">模型在多分辨率遥感图像上的可迁移性</h2> <p>进一步的分析是为了比较所提出的模型和原来的Cascade R-CNN在多分辨率遥感图像中的可迁移性。遥感数据集DOTA-v1.5中的图像按不同的系数（如2、3和4）进行了放大。由原始分辨率图像训练的探测模型直接用于推理，以模拟用有限的数据变异性训练的探测器被用于探测不同分辨率图像中的物体的大多数情况。如前所述，DOTA-v1.5数据集包含16类物体，如飞机、船舶、储罐、大型车辆、小型车辆等。这里我们以飞机和港口的检测为例。图7（单物体）和图8（多物体）显示了在多分辨率图像上实现的物体检测性能。 <img src="/SIAT-GeoScience/assets/2022-04-27 图7" alt="image.png" class="rounded"/> <img src="/SIAT-GeoScience/assets/2022-04-27 图8" alt="image.png" class="rounded"/> 从图7可以看出，在单物体和大物体检测中，Cascade R-CNN++获得的IoUs略好于Cascade R-CNN。在多物体检测中（图8），Cascade R-CNN的性能随着升级因子的增加而迅速下降，而Cascade R-CNN++在不同分辨率的图像中表现出更好的迁移能力。特别是对于小物体的检测，如图8c,g中的白色椭圆所示，当图像被放大3倍时，Cascade R-CNN++可以检测到大部分的小物体，而Cascade R-CNN则漏掉了大部分的小物体。当图像被放大四倍时，如图8d,h，两个检测模型都漏检了一些小物体。在飞机的检测中（图8d），我们注意到Cascade R-CNN几乎漏掉了所有的小飞机，而Cascade R-CNN++仍然可以检测到几个小飞机。</p> <p>我们对DOTA-v1.5中所有测试图像上的16类物体进行了上述实验，使用了1、3/2、2、5/2、3、24/7和4的上标比例。图9显示了边界盒回归后获得的IU的博弈图。3/2的升尺度比率是指图像被升尺度2倍，降尺度3倍的情况。这与其他比率相同。 <img src="/SIAT-GeoScience/assets/2022-04-27 图9" alt="image.png" class="rounded"/> 从图9中我们可以看出，对于按不同比例放大的遥感图像，Cascade R-CNN++比Cascade R-CNN获得了更高的IoU。随着放大比例的增加，Cascade R-CNN++获得的IoU分布的改善变得更加明显。这些结果表明，在多分辨率遥感图像中，Cascade R-CNN++比Cascade R-CNN获得了更高的检测质量。</p> <h1 id="结论">结论</h1> <p>在本研究中，我们提出了Cascade R-CNN++作为一种改进的级联结构，以实现多分辨率遥感图像的高质量物体检测。新模型克服了原有级联R-CNN的扩展问题，在推理时采用了新的集合策略进行分类，从而消除了分类器和RoI特征之间的不匹配。此外，我们修改了边界盒回归的损失函数，以实现零附近更高的灵敏度，这使得随着级联阶段的增加，可以进一步收敛。使用DOTA-v1.5和NWPU VHR-10数据集验证了所提方法的有效性。级联R-CNN++可以随着阶段的增加而达到更高的精度，并且在高质量检测方面取得了明显的改善（例如AP90）。我们对检测质量进行了进一步分析，以验证模型在多分辨率遥感图像中的可迁移性。与Cascade R-CNN相比，所提出的Cascade R-CNN++在多分辨率图像中检测不同类别的物体时取得了更高的IoU值。随着图像分辨率的降低，这一趋势变得更加明显。</p> <p>由于遥感训练数据集的可变性有限，深度学习模型在多分辨率图像之间的可迁移性对于遥感物体检测至关重要。”训练一次，应用于多尺度 “是最终目标。本文提出的级联结构和损失函数可以帮助模型提高跨多分辨率图像的可迁移性。它们是独立的组成部分，可以进一步应用于另一个多阶段模型。在未来，我们将探索级联结构在其他任务中的应用，如实例分割和关键点检测。</p>]]></content><author><name></name></author><category term="特征空间优化"/><category term="特征空间构建"/><summary type="html"><![CDATA[蒸散空间下的土壤特征空间构建]]></summary></entry></feed>