<!DOCTYPE html> <html lang="cn"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 使用级联多级检测器的多分辨率遥感图像的高质量目标检测 | 郭善昕 Shanxin Guo </title> <meta name="author" content="郭善昕 Shanxin Guo"> <meta name="description" content="蒸散空间下的土壤特征空间构建"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shawnmiloguo.github.io/blog/2016/HQODMRSI-CMD/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">郭善昕</span> Shanxin Guo </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">主页 </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">博客 </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">论文 </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">项目 </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">团队 </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item active"> <a class="nav-link" href="/_pages/cv/">简历 </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <div style="display: none"> $$ \newcommand{\bone}{\mathbf{1}} \newcommand{\bbeta}{\mathbf{\beta}} \newcommand{\bdelta}{\mathbf{\delta}} \newcommand{\bepsilon}{\mathbf{\epsilon}} \newcommand{\blambda}{\mathbf{\lambda}} \newcommand{\bomega}{\mathbf{\omega}} \newcommand{\bpi}{\mathbf{\pi}} \newcommand{\bphi}{\mathbf{\phi}} \newcommand{\bvphi}{\mathbf{\varphi}} \newcommand{\bpsi}{\mathbf{\psi}} \newcommand{\bsigma}{\mathbf{\sigma}} \newcommand{\btheta}{\mathbf{\theta}} \newcommand{\btau}{\mathbf{\tau}} \newcommand{\ba}{\mathbf{a}} \newcommand{\bb}{\mathbf{b}} \newcommand{\bc}{\mathbf{c}} \newcommand{\bd}{\mathbf{d}} \newcommand{\be}{\mathbf{e}} \newcommand{\boldf}{\mathbf{f}} \newcommand{\bg}{\mathbf{g}} \newcommand{\bh}{\mathbf{h}} \newcommand{\bi}{\mathbf{i}} \newcommand{\bj}{\mathbf{j}} \newcommand{\bk}{\mathbf{k}} \newcommand{\bell}{\mathbf{\ell}} \newcommand{\bm}{\mathbf{m}} \newcommand{\bn}{\mathbf{n}} \newcommand{\bo}{\mathbf{o}} \newcommand{\bp}{\mathbf{p}} \newcommand{\bq}{\mathbf{q}} \newcommand{\br}{\mathbf{r}} \newcommand{\bs}{\mathbf{s}} \newcommand{\bt}{\mathbf{t}} \newcommand{\bu}{\mathbf{u}} \newcommand{\bv}{\mathbf{v}} \newcommand{\bw}{\mathbf{w}} \newcommand{\bx}{\mathbf{x}} \newcommand{\by}{\mathbf{y}} \newcommand{\bz}{\mathbf{z}} \newcommand{\bA}{\mathbf{A}} \newcommand{\bB}{\mathbf{B}} \newcommand{\bC}{\mathbf{C}} \newcommand{\bD}{\mathbf{D}} \newcommand{\bE}{\mathbf{E}} \newcommand{\bF}{\mathbf{F}} \newcommand{\bG}{\mathbf{G}} \newcommand{\bH}{\mathbf{H}} \newcommand{\bI}{\mathbf{I}} \newcommand{\bJ}{\mathbf{J}} \newcommand{\bK}{\mathbf{K}} \newcommand{\bL}{\mathbf{L}} \newcommand{\bM}{\mathbf{M}} \newcommand{\bN}{\mathbf{N}} \newcommand{\bP}{\mathbf{P}} \newcommand{\bQ}{\mathbf{Q}} \newcommand{\bR}{\mathbf{R}} \newcommand{\bS}{\mathbf{S}} \newcommand{\bT}{\mathbf{T}} \newcommand{\bU}{\mathbf{U}} \newcommand{\bV}{\mathbf{V}} \newcommand{\bW}{\mathbf{W}} \newcommand{\bX}{\mathbf{X}} \newcommand{\bY}{\mathbf{Y}} \newcommand{\bZ}{\mathbf{Z}} \newcommand{\bsa}{\boldsymbol{a}} \newcommand{\bsb}{\boldsymbol{b}} \newcommand{\bsc}{\boldsymbol{c}} \newcommand{\bsd}{\boldsymbol{d}} \newcommand{\bse}{\boldsymbol{e}} \newcommand{\bsoldf}{\boldsymbol{f}} \newcommand{\bsg}{\boldsymbol{g}} \newcommand{\bsh}{\boldsymbol{h}} \newcommand{\bsi}{\boldsymbol{i}} \newcommand{\bsj}{\boldsymbol{j}} \newcommand{\bsk}{\boldsymbol{k}} \newcommand{\bsell}{\boldsymbol{\ell}} \newcommand{\bsm}{\boldsymbol{m}} \newcommand{\bsn}{\boldsymbol{n}} \newcommand{\bso}{\boldsymbol{o}} \newcommand{\bsp}{\boldsymbol{p}} \newcommand{\bsq}{\boldsymbol{q}} \newcommand{\bsr}{\boldsymbol{r}} \newcommand{\bss}{\boldsymbol{s}} \newcommand{\bst}{\boldsymbol{t}} \newcommand{\bsu}{\boldsymbol{u}} \newcommand{\bsv}{\boldsymbol{v}} \newcommand{\bsw}{\boldsymbol{w}} \newcommand{\bsx}{\boldsymbol{x}} \newcommand{\bsy}{\boldsymbol{y}} \newcommand{\bsz}{\boldsymbol{z}} \newcommand{\bsA}{\boldsymbol{A}} \newcommand{\bsB}{\boldsymbol{B}} \newcommand{\bsC}{\boldsymbol{C}} \newcommand{\bsD}{\boldsymbol{D}} \newcommand{\bsE}{\boldsymbol{E}} \newcommand{\bsF}{\boldsymbol{F}} \newcommand{\bsG}{\boldsymbol{G}} \newcommand{\bsH}{\boldsymbol{H}} \newcommand{\bsI}{\boldsymbol{I}} \newcommand{\bsJ}{\boldsymbol{J}} \newcommand{\bsK}{\boldsymbol{K}} \newcommand{\bsL}{\boldsymbol{L}} \newcommand{\bsM}{\boldsymbol{M}} \newcommand{\bsN}{\boldsymbol{N}} \newcommand{\bsP}{\boldsymbol{P}} \newcommand{\bsQ}{\boldsymbol{Q}} \newcommand{\bsR}{\boldsymbol{R}} \newcommand{\bsS}{\boldsymbol{S}} \newcommand{\bsT}{\boldsymbol{T}} \newcommand{\bsU}{\boldsymbol{U}} \newcommand{\bsV}{\boldsymbol{V}} \newcommand{\bsW}{\boldsymbol{W}} \newcommand{\bsX}{\boldsymbol{X}} \newcommand{\bsY}{\boldsymbol{Y}} \newcommand{\bsZ}{\boldsymbol{Z}} \newcommand{\calA}{\mathcal{A}} \newcommand{\calB}{\mathcal{B}} \newcommand{\calC}{\mathcal{C}} \newcommand{\calD}{\mathcal{D}} \newcommand{\calE}{\mathcal{E}} \newcommand{\calF}{\mathcal{F}} \newcommand{\calG}{\mathcal{G}} \newcommand{\calH}{\mathcal{H}} \newcommand{\calI}{\mathcal{I}} \newcommand{\calJ}{\mathcal{J}} \newcommand{\calK}{\mathcal{K}} \newcommand{\calL}{\mathcal{L}} \newcommand{\calM}{\mathcal{M}} \newcommand{\calN}{\mathcal{N}} \newcommand{\calO}{\mathcal{O}} \newcommand{\calP}{\mathcal{P}} \newcommand{\calQ}{\mathcal{Q}} \newcommand{\calR}{\mathcal{R}} \newcommand{\calS}{\mathcal{S}} \newcommand{\calT}{\mathcal{T}} \newcommand{\calU}{\mathcal{U}} \newcommand{\calV}{\mathcal{V}} \newcommand{\calW}{\mathcal{W}} \newcommand{\calX}{\mathcal{X}} \newcommand{\calY}{\mathcal{Y}} \newcommand{\calZ}{\mathcal{Z}} \newcommand{\R}{\mathbb{R}} \newcommand{\C}{\mathbb{C}} \newcommand{\N}{\mathbb{N}} \newcommand{\Z}{\mathbb{Z}} \newcommand{\F}{\mathbb{F}} \newcommand{\Q}{\mathbb{Q}} \DeclareMathOperator*{\argmax}{arg\,max} \DeclareMathOperator*{\argmin}{arg\,min} \newcommand{\nnz}[1]{\mbox{nnz}(#1)} \newcommand{\dotprod}[2]{\langle #1, #2 \rangle} \newcommand{\ignore}[1]{} \let\Pr\relax \DeclareMathOperator*{\Pr}{\mathbf{Pr}} \newcommand{\E}{\mathbb{E}} \DeclareMathOperator*{\Ex}{\mathbf{E}} \DeclareMathOperator*{\Var}{\mathbf{Var}} \DeclareMathOperator*{\Cov}{\mathbf{Cov}} \DeclareMathOperator*{\stddev}{\mathbf{stddev}} \DeclareMathOperator*{\avg}{avg} \DeclareMathOperator{\poly}{poly} \DeclareMathOperator{\polylog}{polylog} \DeclareMathOperator{\size}{size} \DeclareMathOperator{\sgn}{sgn} \DeclareMathOperator{\dist}{dist} \DeclareMathOperator{\vol}{vol} \DeclareMathOperator{\spn}{span} \DeclareMathOperator{\supp}{supp} \DeclareMathOperator{\tr}{tr} \DeclareMathOperator{\Tr}{Tr} \DeclareMathOperator{\codim}{codim} \DeclareMathOperator{\diag}{diag} \newcommand{\PTIME}{\mathsf{P}} \newcommand{\LOGSPACE}{\mathsf{L}} \newcommand{\ZPP}{\mathsf{ZPP}} \newcommand{\RP}{\mathsf{RP}} \newcommand{\BPP}{\mathsf{BPP}} \newcommand{\P}{\mathsf{P}} \newcommand{\NP}{\mathsf{NP}} \newcommand{\TC}{\mathsf{TC}} \newcommand{\AC}{\mathsf{AC}} \newcommand{\SC}{\mathsf{SC}} \newcommand{\SZK}{\mathsf{SZK}} \newcommand{\AM}{\mathsf{AM}} \newcommand{\IP}{\mathsf{IP}} \newcommand{\PSPACE}{\mathsf{PSPACE}} \newcommand{\EXP}{\mathsf{EXP}} \newcommand{\MIP}{\mathsf{MIP}} \newcommand{\NEXP}{\mathsf{NEXP}} \newcommand{\BQP}{\mathsf{BQP}} \newcommand{\distP}{\mathsf{dist\textbf{P}}} \newcommand{\distNP}{\mathsf{dist\textbf{NP}}} \newcommand{\eps}{\epsilon} \newcommand{\lam}{\lambda} \newcommand{\dleta}{\delta} \newcommand{\simga}{\sigma} \newcommand{\vphi}{\varphi} \newcommand{\la}{\langle} \newcommand{\ra}{\rangle} \newcommand{\wt}[1]{\widetilde{#1}} \newcommand{\wh}[1]{\widehat{#1}} \newcommand{\ol}[1]{\overline{#1}} \newcommand{\ul}[1]{\underline{#1}} \newcommand{\ot}{\otimes} \newcommand{\zo}{\{0,1\}} \newcommand{\co}{:} %\newcommand{\co}{\colon} \newcommand{\bdry}{\partial} \newcommand{\grad}{\nabla} \newcommand{\transp}{^\intercal} \newcommand{\inv}{^{-1}} \newcommand{\symmdiff}{\triangle} \newcommand{\symdiff}{\symmdiff} \newcommand{\half}{\tfrac{1}{2}} \newcommand{\mathbbm}{\Bbb} \newcommand{\bbone}{\mathbbm 1} \newcommand{\Id}{\bbone} \newcommand{\SAT}{\mathsf{SAT}} \newcommand{\bcalG}{\boldsymbol{\calG}} \newcommand{\calbG}{\bcalG} \newcommand{\bcalX}{\boldsymbol{\calX}} \newcommand{\calbX}{\bcalX} \newcommand{\bcalY}{\boldsymbol{\calY}} \newcommand{\calbY}{\bcalY} \newcommand{\bcalZ}{\boldsymbol{\calZ}} \newcommand{\calbZ}{\bcalZ} $$ </div> <header class="post-header"> <h1 class="post-title">使用级联多级检测器的多分辨率遥感图像的高质量目标检测</h1> <p class="post-meta"> Created in February 03, 2016 </p> <p class="post-tags"> <a href="/blog/2016"> <i class="fa-solid fa-calendar fa-sm"></i> 2016 </a>   ·   <a href="/blog/tag/%E7%89%B9%E5%BE%81%E7%A9%BA%E9%97%B4%E6%9E%84%E5%BB%BA"> <i class="fa-solid fa-hashtag fa-sm"></i> 特征空间构建</a>   ·   <a href="/blog/category/%E7%89%B9%E5%BE%81%E7%A9%BA%E9%97%B4%E4%BC%98%E5%8C%96"> <i class="fa-solid fa-tag fa-sm"></i> 特征空间优化</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>基于深度学习的物体检测器在精度和自动化程度方面大大改善了遥感图像中最先进的物体检测。然而，物体尺度的巨大变化使得在多分辨率的遥感图像中很难实现高质量的检测，而质量是由训练中使用的交叉联合（IoU）阈值定义的。此外，跨多分辨率图像的正负样本之间的不平衡也使检测精度恶化。最近，人们发现，基于级联的区域卷积神经网络（R-CNN）通过引入级联的三级结构，使用逐步提高的IoU阈值，有可能实现更高的检测质量。然而，当加入第四级时，级联R-CNN的性能下降了。我们调查了原因，发现ROI特征和分类器之间的不匹配可能是造成性能下降的原因。在此，我们提出了一个级联R-CNN++结构来解决这个问题，并将三段式结构扩展到多段式结构，供一般使用。具体来说，对于级联分类，我们提出了一种新的分类器和兴趣区域（RoI）特征的集合策略，以提高推理时的分类精度。在定位方面，我们修改了边界盒回归器的损失函数，以获得零附近更高的灵敏度。在DOTA数据集上的实验表明，Cascade R-CNN++在精度和检测质量方面优于Cascade R-CNN。我们对多分辨率遥感图像进行了进一步分析，以验证模型在不同物体尺度上的可迁移性。</p> <h1 id="原文链接">原文链接</h1> <p><a href="https://www.mdpi.com/2072-4292/14/9/2091" rel="external nofollow noopener" target="_blank">https://www.mdpi.com/2072-4292/14/9/2091</a></p> <h1 id="背景及科学问题">背景及科学问题</h1> <p>遥感图像中的物体检测在一些民用和军事应用中发挥着重要作用，如城市规划、地理信息系统更新和搜救行动。与传统方法（基于模板匹配的方法[1,2]、基于知识的方法[3,4]等）相比，基于深度学习的方法通过将人工特征设计的负担迁移到底层学习系统，从原始数据中自动提取特征，使其具有更强大的特征表示能力，以提取更高语义水平的特征图。凭借这一优势，基于深度学习的检测方法在计算机视觉和遥感界都取得了巨大成功[5,6]。</p> <p>与自然场景图像不同，遥感图像在不同的观测条件下具有更大的尺度变化和更多的特征复杂性，这就要求物体检测器具有更高的泛化能力。最近，基于DNN的检测方法从计算机视觉领域被引入到遥感领域，并在多类物体检测上取得了优异的成绩。遥感图像深度学习物体检测的许多基本问题得到了解决，如缺乏足够的训练样本[7,8]，小物体检测的性能差[9,10,11]，以及卫星图像中物体的旋转特性[12,13]。撰写于2020年的全面回顾可以在文章[5]中找到。</p> <p>尽管如此，多分辨率遥感图像中物体尺度的巨大变化仍然给物体检测器带来巨大挑战。最近，一些研究从不同方面探讨了解决这一问题的可能性，可以归纳为三类。(1) 不同层次的特征融合：在这一类别中，许多融合模型都是为了提取多尺度的特征层次，以提高模型在小物体和大物体上的性能。有代表性的研究包括跨尺度特征融合（CSFF）[14]、基于双特征金字塔网络（FPN）的偏振注意机制模块[15]、特征融合架构（FFA）[16]、多片特征金字塔网络[17]和Quad-FPN[18]。(2) 改进区域建议网络以生成更合适的锚点：这些模型解决了多尺度图像中锚点尺寸和物体尺寸的不匹配问题，如自适应长宽比锚点(SARA)[19]，多尺度空间注意区域建议网络[20]，以及尺寸折叠操作(SF)[21]。(3) 建立平行网络来检测不同尺度的物体：其中一个代表性的工作是多专家检测网络（MEDNet）[22]。</p> <p>上述方法主要集中在不同尺度的物体之间的特征提取和特征匹配。除此之外，正负样本的不平衡也是模型无法检测不同尺度物体的另一个原因[23]。与小物体相比，大物体更容易被识别为正样本，而且精度更高。当把由高分辨率图像预训练的模型应用于低分辨率图像时，大多数大物体会变成小物体，导致阳性样本太少，无法有效训练模型。</p> <p>在基于锚点的检测器中，通常使用一个交叉-联合（IoU）阈值来区分阳性/阴性样本，这也定义了检测质量[24]。选择一个合适的阈值是检测质量和精度之间的妥协，因为较低的IoU阈值会带来更多潜在的物体区域建议，但会有更多的噪声样本，这导致了不可靠的检测结果。然而，在训练中使用高的IoU阈值会导致阳性样本太少，从而导致模型过拟合。</p> <p>为了达到高精度，IoU阈值必须与检测器假说的质量密切相关[25]。级联R-CNN[25]，作为两阶段基于锚的检测器的扩展，使用三阶段的级联结构来解决上述问题，训练样本的IoU（即假设的质量）可以通过级联的边界盒回归来逐步提高。这种级联结构依次提高阳性训练样本的数量和质量，以减少过拟合问题。在自然场景图像的实验中，级联结构在检测不同尺度的物体时取得了更好的精度。然而，在级联R-CNN的原始结构中，级联组件的最大数量为3个。当增加第四级时，整体检测性能就会下降[25]。这就限制了级联检测器的扩展，以实现更好的检测性能。</p> <p>在本文中，我们研究了增加更多级联阶段时性能下降的原因。我们发现，在推理时，级联R-CNN中的原始集合策略在分类器和兴趣区域（RoI）向量之间引入了不匹配，降低了分类精度。</p> <p>为了克服这一局限性，我们提出了一种新的级联分类的集合策略，即采取同一阶段产生的RoI特征进行分类，而不是统一使用最后阶段的特征。最终的分类结果是通过整合所有阶段的分类器输出得到的。此外，边界盒回归[26]的损失函数被修改以提高灵敏度，使级联回归器随着阶段数的增加而进一步收敛。修改后的级联结构在本文中被表示为级联R-CNN++。</p> <p>本研究的主要贡献有以下几点。(1）我们研究了级联检测器在增加更多阶段时性能下降的原因；（2）我们提出了一种新的集合策略，以尽量减少推理时分类器和输入RoI之间的不匹配，并提高分类精度；（3）我们提出了一个修改的边界盒回归的损失函数，使边界盒回归在建立更多阶段时进一步收敛。所提出的Cascade R-CNN++方法可以在遥感数据集DOTA上实现最先进的检测性能[27,28]。它可以在大多数需要基于区域建议的方法的情况下实施。在多分辨率遥感图像的实验中，所提出的方法在检测质量和精度上都优于级联R-CNN。</p> <h1 id="研究方法介绍级联r-cnn">研究方法介绍：级联R-CNN++</h1> <p>级联R-CNN[25]使用三级级联检测器来逐步改善训练样本的IoU分布。通过级联回归，可以实现更高的物体定位精度。然而，当增加第四级时，AP、AP50、AP60、AP70和AP80的指标都会下降，只有AP90略有增加。在此，我们研究了性能下降的原因。</p> <p>在本文中，我们通过修改Cascade R-CNN来提出Cascade R-CNN++方法。首先，我们为分类器和推理时的RoI特征提出了一个新的集合策略。其次，我们提出了一个改进的损失函数，用于边界箱回归，以实现零附近的高灵敏度，这使得更多阶段的加入能够进一步收敛。图3显示了所提出的级联R-CNN++的一个五阶段的例子。区域建议的生成采用了RPN。</p> <h2 id="新的分类组合策略">新的分类组合策略</h2> <p>正如在[25]中所定义的，一个分类器被表示为一个函数h(xi)它将一个特征向量xi归入m+1个类中的一个，其中0为背景，其余每个值代表一个类。一个分类器的输出是一个m+1维向量，其最大值表示边界框中的物体所属的类别。分类器是通过最小化交叉熵损失Rcls来训练的。</p> <h2 id="边界盒回归的修正损失函数">边界盒回归的修正损失函数</h2> <p>在每个阶段，边界盒回归器被用来通过最小化真实边界盒和候选边界盒之间的偏移量来逐渐使候选提案接近真实标签位置。一个输入建议p可以通过以下方式转化为预测的真实标签框g。推导公式表示如下： <img src="/SIAT-GeoScience/assets/2022-04-27%20%E5%85%AC%E5%BC%8F.png" alt="image.png" class="rounded"> 其中p=(px,py,pw,ph)表示输入建议的位置，g=(gx,gy,gw,gh)是预测的真实标签箱。Δ=(tx/cx,ty/cy,tw/cw,th/ch)代表距离向量，即由边界盒回归器进行的微小调整。是影响距离向量大小的权重，权重cx、cy、cw、ch最初设定为（10，10，5，5），并随着阶段的增加而逐渐增加。由于边界盒回归器对偏移向量Δ进行了微调，这些值通常是非常小的。因此，归一化被执行为Δ[25,35,36,41].对于一个图像补丁xj，级联R-CNN[25]中使用的边界盒回归的损失函数可以表示为Rloc，其中Rloc是边界盒回归的交叉熵损失，j是一个候选方案的索引，Nloc是候选提案的数量，Lloc表示S1平滑L1函数[24]。</p> <p>其中f(xj,pj)是边界盒回归函数，pj=(pjx,pjy,pjw,pjh)是第j个是第j个候选方案，有四个坐标，即中心位置（pjx,pjy)，以及盒子的宽度和高度（pjw,pjy）.gj代表预测的真实标签框，以同样的方式指定（gj=(gjx,gjy,gjw,gjh)). 此后，除非需要，我们忽略上标j为简单起见。</p> <p>为了使更多阶段的级联回归能够进一步收敛，我们改进了边界盒回归的损失函数，以实现零附近的高灵敏度。</p> <p>其中sgn是符号函数，指数4/3的条款（tk/ck）4/3，和k∈{x,y,w,h}。是为了增加非线性并保持灵敏度和损失梯度之间的权衡。输入(tx,ty,tw,th)与边界箱输出偏移量（gx-px,gy-py,gw/pw,gh/ph）绘制成图。对于不同权重的原始和修改后的损失函数ci，i∈{x,y,w,h}。不同阶段（图4和图5）。修改后的损失函数在零点附近的曲线更平滑，表明当候选边界盒和真实标签之间的偏移接近零时，回归器的步长更小（即灵敏度更高）。这一修改使得级联边界盒回归器随着阶段的增加而进一步收敛。 <img src="/SIAT-GeoScience/assets/2022-04-27%20%E5%9B%BE4-%E5%9B%BE5.png" alt="image.png" class="rounded"> <img src="/SIAT-GeoScience/assets/2022-04-27%20%E5%9B%BE6.png" alt="image.png" class="rounded"> 图6说明了在损失函数中采取不同指数值的效果。我们可以看到，较大的指数值对应于损失函数在零附近的较高灵敏度，但收敛速度较慢。指数项为4/3是灵敏度和收敛速度之间的权衡。该值是经过多次实验后选择的经验值。</p> <h1 id="试验结果">试验结果</h1> <p><img src="/SIAT-GeoScience/assets/2022-04-27%20%E8%A1%A82-%E8%A1%A85.png" alt="image.png" class="rounded"></p> <h2 id="阶段性的比较">阶段性的比较</h2> <p>在DOTA数据集上，我们比较了三级、四级和五级级联R-CNN++的检测性能，它们都以ResNet-50为骨干。结果见表2，其中AP表示平均精度，AP50、AP75和AP90分别表示使用0.5、0.75和0.9的IoU阈值的检测精度。APS、APM和APL分别表示小型、中型和大型物体的检测精度。</p> <p>如表2所示，整体检测精度随着阶段的增加而提高，以FPS（每秒帧数）衡量的推理速度没有明显下降。</p> <h2 id="建议修改的消融实验">建议修改的消融实验</h2> <p>通过使用ResNet-50骨干网进行消融实验，进一步分析了Cascade R-CNN++的检测性能。结果显示在表3中。采用新的集合策略和修改后的边界盒回归损失函数的级联检测器取得了最好的精度，在AP90中也有明显的改善。</p> <h2 id="与最先进的检测器的比较">与最先进的检测器的比较</h2> <p>在DOTA-v1.5数据集上，提议的Cascade R-CNN++的性能与最先进的两级/多级检测器进行了比较，详见表4。用*表示的条目使用了包括多尺度训练/推理和SoftNMS在内的增强措施，如[43,45]。</p> <p>如表4所示，与Faster R-CNN、FPN、RetinaNet和原始Cascade R-CNN相比，提议的Cascade R-CN++在所有指标上都取得了更高的精度。在AP90上的改进最为明显，其次是对中型和小型物体的检测精度（即APM和APS）。这些结果证明，所提出的方法是有效的，并且优于最先进的检测器，特别是在高质量检测方面。在实验中，我们还实现了具有多尺度训练/推理和softNMS的Cascade R-CNN++，在表4中用Cascade R-CNN++ *表示。通过这些改进，Cascade R-CNN++超过了Cascade R-CNN 4.6分。值得注意的是，最近的其他研究从不同的角度（如特征金字塔）探讨了改进措施，表明这些改进措施的累积效应可以进一步提高多阶段检测器在遥感物体检测、实例分割、关键点检测等领域的性能。</p> <p>在另一个遥感数据集NWPU VHR-10上也进行了比较（表5）。训练以0.01的学习率开始，在30 k和40 k的迭代中分别降低到0.001和0.0001，并在50 k的迭代中完成。其他实施设置与DOTA-v1.5上的实验相同。</p> <p>从表5中我们可以看出，所提出的Cascade R-CNN++在NWPU VHR-10数据集上产生了最好的性能，特别是在AP75和AP90所显示的高质量检测上。小物体的检测精度比原来的Cascade R-CNN方法提高了4.8%。</p> <h2 id="模型在多分辨率遥感图像上的可迁移性">模型在多分辨率遥感图像上的可迁移性</h2> <p>进一步的分析是为了比较所提出的模型和原来的Cascade R-CNN在多分辨率遥感图像中的可迁移性。遥感数据集DOTA-v1.5中的图像按不同的系数（如2、3和4）进行了放大。由原始分辨率图像训练的探测模型直接用于推理，以模拟用有限的数据变异性训练的探测器被用于探测不同分辨率图像中的物体的大多数情况。如前所述，DOTA-v1.5数据集包含16类物体，如飞机、船舶、储罐、大型车辆、小型车辆等。这里我们以飞机和港口的检测为例。图7（单物体）和图8（多物体）显示了在多分辨率图像上实现的物体检测性能。 <img src="/SIAT-GeoScience/assets/2022-04-27%20%E5%9B%BE7" alt="image.png" class="rounded"> <img src="/SIAT-GeoScience/assets/2022-04-27%20%E5%9B%BE8" alt="image.png" class="rounded"> 从图7可以看出，在单物体和大物体检测中，Cascade R-CNN++获得的IoUs略好于Cascade R-CNN。在多物体检测中（图8），Cascade R-CNN的性能随着升级因子的增加而迅速下降，而Cascade R-CNN++在不同分辨率的图像中表现出更好的迁移能力。特别是对于小物体的检测，如图8c,g中的白色椭圆所示，当图像被放大3倍时，Cascade R-CNN++可以检测到大部分的小物体，而Cascade R-CNN则漏掉了大部分的小物体。当图像被放大四倍时，如图8d,h，两个检测模型都漏检了一些小物体。在飞机的检测中（图8d），我们注意到Cascade R-CNN几乎漏掉了所有的小飞机，而Cascade R-CNN++仍然可以检测到几个小飞机。</p> <p>我们对DOTA-v1.5中所有测试图像上的16类物体进行了上述实验，使用了1、3/2、2、5/2、3、24/7和4的上标比例。图9显示了边界盒回归后获得的IU的博弈图。3/2的升尺度比率是指图像被升尺度2倍，降尺度3倍的情况。这与其他比率相同。 <img src="/SIAT-GeoScience/assets/2022-04-27%20%E5%9B%BE9" alt="image.png" class="rounded"> 从图9中我们可以看出，对于按不同比例放大的遥感图像，Cascade R-CNN++比Cascade R-CNN获得了更高的IoU。随着放大比例的增加，Cascade R-CNN++获得的IoU分布的改善变得更加明显。这些结果表明，在多分辨率遥感图像中，Cascade R-CNN++比Cascade R-CNN获得了更高的检测质量。</p> <h1 id="结论">结论</h1> <p>在本研究中，我们提出了Cascade R-CNN++作为一种改进的级联结构，以实现多分辨率遥感图像的高质量物体检测。新模型克服了原有级联R-CNN的扩展问题，在推理时采用了新的集合策略进行分类，从而消除了分类器和RoI特征之间的不匹配。此外，我们修改了边界盒回归的损失函数，以实现零附近更高的灵敏度，这使得随着级联阶段的增加，可以进一步收敛。使用DOTA-v1.5和NWPU VHR-10数据集验证了所提方法的有效性。级联R-CNN++可以随着阶段的增加而达到更高的精度，并且在高质量检测方面取得了明显的改善（例如AP90）。我们对检测质量进行了进一步分析，以验证模型在多分辨率遥感图像中的可迁移性。与Cascade R-CNN相比，所提出的Cascade R-CNN++在多分辨率图像中检测不同类别的物体时取得了更高的IoU值。随着图像分辨率的降低，这一趋势变得更加明显。</p> <p>由于遥感训练数据集的可变性有限，深度学习模型在多分辨率图像之间的可迁移性对于遥感物体检测至关重要。”训练一次，应用于多尺度 “是最终目标。本文提出的级联结构和损失函数可以帮助模型提高跨多分辨率图像的可迁移性。它们是独立的组成部分，可以进一步应用于另一个多阶段模型。在未来，我们将探索级联结构在其他任务中的应用，如实例分割和关键点检测。</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/deep-contextualized-word-representations/">Deep contextualized word representations (ELMo)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/cmu-steam-tunnels/">The CMU Steam Tunnels and Wean 9</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/HRUNET/">基于HRU-Net的中高分辨率地表要素提取模型</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 郭善昕 Shanxin Guo. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>